#!/usr/bin/perl

#{{{1--------------CONFIGURATION-----------------------
# -------TOC and INDEX behaviour------

# print TOC? 1:0
#$print_toc=1;	# default is to print

# should we keep TOC expanded? "block":"none"
#$toc_expanded="block";	# default is to unfold

# should we keep Chunks Index expanded? "block":"none"
#$ind_expanded="none";	# default is to keep folded


# should we number lines in code sections? 1 : else
#$line_numbering = 1;	# default is to number


#-------------------------------------
#---------MathML options--------------
# should we enable MathML via ASCIIMathML.js or LaTeXMathML.js library? 1:0
#$enable_ASCIIMathML = 0; #default is to disable as it slows Molly down a lot
#$enable_ASCIIMathML = 1;

# If yes, what is the full path to the lib? Remember to get the one with proper
# escapes for your work, default or modified (see documenation)
# CAN BE: (a) local "/full/path/from/root/to/ASCIIMathML_with_modified_escapes.js" or 
# (b) in current dir "ASCIIMathML_with_modified_escapes.js" or
# (c) on the web, e.g. the original site of the library (unmodified) is:
#$path_to_ASCIIMathML = "http://www1.chapman.edu/~jipsen/mathml/ASCIIMathML.js";
#$path_to_ASCIIMathML = "ASCIIMathML_with_modified_escapes.js"; # default is current dir


#-------------------------------------
#--------Document Markup lang---------

# how are doc sections marked? "dotHTML":"rawHTML"
 $weave_markup = "dotHTML"; # default is "rawHTML"


#--------------------------------------
#---------File extensions and tangling------
 
# what is the file extention to weave it? (perms must allow execution!)
# e.g. "scriptname.weave" or "scriptname.cgi" etc.
#$weave_extension = "weave";	# default is "weave"

# what is the file extention to tangle it? (perms must allow execution!)
# e.g. "scriptname.tangle",  "scriptname.pl" etc.
#$tangle_extension = "tangle";	# default is "tangle"

#When tangling, should I use the built-in tangler? 0:1
# (if 0, the "pass-through" tangling will call "notangle"
# from Ramsey's "noweb" tools, must be installed and in your path)
# use_builtin_tangler = 0; # default for now is to use external "notangle"
$use_builtin_tangler = 1; 

#--------------------------------------
#---------invocation of MOLLY.pl-------
do "MOLLY.pl";
exit;
__DATA__
#-----------------------start of script---------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------}}}1



.<. center .>. .b. Licensing ./b.
MOLLY is licensed under GNU Public License version 3. .<. /center .>.




#--------------------------------------------------
{{{1 .+h1. MOLLY MODULE ./h1.
#--------------------------------------------------

.b. What is it? ./b.

.i. Answer: ./i. Technically, this is "MOLLY.pl", a MO-dule for LI-terate programming, a
    small perl script that implements a new type of "weaver" for Literate Programming.
    This is is an attempt to combine Literate Programming (as practiced with
    "noweb" tools by Norman Ramsey) and autogenerated document folding/outlining with
    Javascript and HTML -- to escape scalability limitation of pure L.P. and enable a number
    of new source file management techniques.

.br.
#------------------------------------------------------------------
{{{2 .h2. THE CHUNK TO TANGLE BY  DEFAULT ./h2.
#------------------------------------------------------------

<<*>>=
<<MOLLY.pl module>>
@

<<*-dis>>=
<<seek-peek tangler>>
@

<<*-dis>>=
<<spacing.pl>>
@
<<*-dis>>=
<<tanglediff.test2.pl>>
@

<<*-dis>>=
<<md5 hashing from perl>>
@

<<*-dis>>=
<<check topo sort>>
@


<<*-dis>>=
<<check strings expansion>>
@

}}}2

.h2. ./h2.

#-------------------------------------------------------------------------------------
{{{2 .h2. PART I ----------- Concepts. Controlling human attention.------------ ./h2.
#--------------------------------------------------------------


.b. LP as "management of thinking" ./b. 

    If you never heard of Literate Programming, please read something like the Wikipedia
    article .a. http://en.wikipedia.org/wiki/Literate_programming ./a.
    and then something like documentation to Norman Ramsey's "noweb" tools and his old
    but excellent article  on the subject (linked from the site).
    .a. http://www.cs.tufts.edu/~nr/noweb ./a.

    .b. .i. L.P. is a technique for "management of thinking" that helps to relieve short-term memory
    of "housekeeping" tasks when creating complicated texts and "splits levels" for 'global thinking"
    and "local changing" ./i. ./b.

    The biggest problem in managing complex texts of any kind - programming simply being the most
    complicated one, where the text is not supposed contain errors at all - is in holding it all
    together in one's mind.

    Human short-term memory is surprisingly tiny, up to 7 to 9 objects simultaneously at any one
    time, psychologists tell us. Therefore, when faced with larger tasks, humans need to use a number
    of "aoivdance techniques" to dance around the limitation.

    First, we constantly switch levels. E.g. I need to change my program. I remember the general
    outline of it, so I use that to figure out where to go. On each evel I would probably remember
    details "inside" each of those larger blocks etc.

    In my experience a script or a program longer than, say 1000 to 1200 lines becomes a major
    problem unless special techniques are used to help one's attention.

    In programming, probably 90% of "chunking", i.e. division into procedures, or "objects" or
    "functions" are not needed for the machine. They are done .b. simply for the humans not
    to lose the thread of their thinking. ./b. Whithout this things would become totally 
    unmanageable.

    Here comes also the idea of "writing domain-specific languages": humans chunk lower-level
    operations into a new 'unit' or 'abstraction', then manipulate with higher-level abstractions
    over abstractions over abstractions over abstractions..

    "Literate Programming" is not a programming-specific technique that allows us to create arbitrary
    systems of abstractions .i. with phrases in a human language ./i. - "in pseudocode" - while staying
    precise in our specification opf the final product. Everyone knows that explanation with
    pseudocode are helpful - that was the way we learned of the subject of programming in the first
    place. Most if not all textbooks are written in this way.

    So L.P. .b. is an alternative to procedures and subroutines in the machine language ./b.

    For example, I can easily write and maintain na LPSource file with

<<logical switch>>=
 if (<<condition A>>) {
    <<a thousand-line-long piece of code>>}
 else { 
    <<another thousand-line-long piece of code>>}
@

    (and specify all those references elsewhere), while such code written directly would be
    unmaintainable and almost impossible to understand to a human. As a result, a human would
    .i. have to ./i. wrap his code into some subs, with inherent limitations and complications
    on their parameters and return result, built into his programming language.
    The machine would slow down its execution because internally it will maintain environment
    to switch to when returning etc.
    Isnt't it ironic that "hand-made optimisations" include "unrolling" programming constructs
    programmers introduced on the first place? The reason most probably was that otherwise
    a human mind would not be able to keep the thread, it would have lost it, while  all the
    introduced paraphenalia is totally unnecessary for the machine execution.

    Subroutines or functions are sometimes necessary. To give one example: to create a recursive
    invocation the programmer uses the built-in ability of a function to push its current state
    on the stack and then to automatically pick up where left upon returning.
    But probably 90% of all sub-dividing in programming is done just for the humans not to get
    lost in the sea of code.

    So, .ul. .i. .b. Literate Programming is a system of free-form macros in a natural human 
    language used as an alternative to programming language procedures 
    (functions) when those serve as props to limit load on human attention
    span, and totally unnecessary for machine execution in themselves ./b. ./i. ./ul.


.br.
.b. Three problems with L.P. -- unification of L.P. and folding ./b.

    Donald Knuth first was thinking of how to document his code when he created a mish-mash of
    previous attempts at similar management techniques with macros, which he called "WEB" (at
    the time when no "www-web" existed yet).
    Then he proclaimed this is the best way to write programs he knows, and repositioned it
    as "a programming paradigm", in direct competition to the "structural programming",
    introduced in the previous decade.

    Acceptance of this new method of program writing however was disappointing. I believe, there
    were and still are three factors at play, which hurt it, even though the name of L.P. creator
    ensured L.P. never fell into complete obscurity.

    .ul.
	.li. .b. First, L.P. used TeX as a formatting tool ./b., which is a sort of programming language in
	itself. Therefore, the first thing to blame L.P. for became "but I'd need to write - .i. and 
	debug! ./i. - two programs at the same time, in TeX and in my own machine language.

	Today when much, much simpler markup languages abound - "html" or even "markdown 
	html" or even "wiki" for the majority of uses that do not require typesetting complicated
	equations or graphs - this problem has long been solved.
	You do not need to "debug" basic HTML markup - any error is displayed in your browser as a
	distortion of the web page, I do not need to "debug" html when writing with my Molly script
	which uses html markup.

	./li. .li. .b. Secondly, the first generation of L.P. tools was language-specific. ./b. You could 
	do Pascal, but not Fortran. Later "C" and "Fortran" literate tools were added, but you could
	not do Lisp or Ada etc.

	Today with tools like "noweb" by Norman Ramsey this problem has long been solved. Simplified
	to its core idea Literate Programming is now totally language-independent to the degree that
	you can write books or essays with L.P. tools not even knowing how to program for the computer.

	./li. .li. .b. And the third problem is the flat file structure of Literate Source files ./b. and
	(probably that could be listed as the fourth, psychological stumbling block) the insistence
	on "producing clean documentation" or "polished essays" of one's programs other could read
	and enjoy.

	Flat files continue to limit the size of the literate source files: your mind still .i. has to
	keep internally the overall structure of your program ./i. and switch from it to doing concrete
	tasks.
	Technically a Literate Source file can include .i. many ./i. program files ( e.g. project.h,
	project.c, a makefile and a README). In reality the size is limited by your "attention horizon"
    ./li. ./ul.

    .b. I propose to solve  this last problem by combining L.P. with folding or outlining ./b. ,
    using html and javascript as the simplest and ubiquitous tools.

    The Literate Source file is written in basic HTML, or even in "markdown" or "wiki"-style markup
    notation. The script then automatically creates a document with folds at each heading line
    (i.e. "h1", "h2", ...). The file can be "weaved" from command line or produced dynamically 
    under a web  server as a CGI document.

    Folding must allow opening an arbitrary number of sections from any place in the file to create
    a sub-view of the document, a small document which is relevant to some particular sub-task.
    These sub-views must persist for the time of this particular work, i.e. the user should not
    be forced to reopen his subview over and over again. That is, I should in effect be able to read
    snippets constituting 2 pages of text relevant to my immediate task contiguously from  a 
    5MB file  and  not even notice that, as the rest is tucked out of the way.
    
    Common practice in IDEs and outlining editors is an arrangement of folding in which  a 
    programmer is allowed to see only one section at a time, not, say, 5 of them from many places,
    opened as a sort of "view". Opening only a single subsection at a time is the death of the idea
    of folding or outlining. It simply strips it of its usefulness. The human perception then becomes 
    "mosaic".
    
    .i. As an example of totally wrong presentation, ./i. which  fragments perception into poorly
    connected pieces and does not allow a reader to see the forest for the trees and see 
    documentation of GNU libavl .a. http://adtinfo.org/libavl.html/ ./a. 
    It is not humanly possible to follow the train of thought from such a presentation: one has to
    keep an internal mental map of the document .i. before ./i. reading it and inability to see more than
    one snippet puts a stop to perception: once the snippet is left, one has to rely on memory of
    previously read pieces to relate things to each other.
    Nor the split HTML, nor the flat file format provide for human-friendly perception of code
    unless it is  a small short self-contained piece.
    

    .i. A document that is based on a structure of folding subsections ./i. drastically increases
    one's attention span, allows to manage easily thousands and thousands of lines of text, and
    makes inclusion of many different types of files into what becomes one .i. Literate Source Project
    file ./i. "a cinch".

    A number of techniques becomes possible which have not been possible before in a flat file. 
    Snippets testing language constructs, doubling certain "chunks" while keeping a pointer in a
    "linker chunk" to preserve the previous working version of your program while experimenting
    with a new one (previously one would have to use version control or rename files for that), 
    making collections of loosely related documents and script, each still obtainable through
    tangling, such as a collection of system administration policies, readmes, config files and 
    many scripts -- all become easy with a folding literate source file.

    And consequently emphasis moves from the creation of usually comparatively compact programs
    exposed as a sort of polished essays (or documented for their logic in the order of thinking)
    --  to using Literate Source folding files as your "work log" or "a log of thinking" when
    developing a program, like a scientist might keep a log of his experiments.

    Clean version of documentation or program presentation might emerge from it, later, but at the
    moment of conception the most urgent task is to preserve your thinking, however "clever" or
    "stupid" that might be and unload all "houskeeping" from your mind, to stop straining to
    remember where which change must go.

    Such literate project files however do become good documentation, it seems, even without much
    further polishing, as polishing occurs naturally with developing and rewriting your program.


}}}2	    

.h2. ./h2.

#------------------------------------------------------------------------------
{{{2 .+h2. PART II ------------ HOW TO USE MOLLY.pl ------------ ./h2.
#-------------------------------------------------------


#--------------------------------------------------------
{{{3 .h3. My workflow - literate programming with Molly ./h3.
#--------------------------------------------------------

 .<. img src=eeerotate.jpg align=right hspace=5 width=200 border=2 .>.
.i. .b. A prerequisite of sorts ./b.
Use a vertically rotated screen (with an external keyboard and mouse on
a notebook) or a large  enough screen to see a vertically positioned A4
sheet of paper to obtain full advantages of outlining and folding 
Psychologically, the more we see, the more "clever" we are. Stop reading
compicated documents through a slit: with mental perception crippled, 
you'll just jump between fragments, and never truly "get" them in whole. ./i. .b. >>> ./b.

Rotation on Linux is done by running .pre. xrandr -o right|left|normal ./pre.
from an X terminal window. Most modern video cards support this.

.b. The Workflow ./b. :
.ol.
    .li. I run a web server on localhost:8000, for myself only. My
    development directory is under the web server - or is linked to
    the web server document tree.

    ./li. .li. I write my Literate Source file in a vim editor. I mark up
    the documentation section (i.e. not code) with most basic HTML tags
    (e.g. <h2>, <b>, <ul> ...). 
    The code sections live between "< < section name > > =" and "@" 
    (in the first position in the line), as is required by "noweb"
    literate programming tools. Other code sections can be referred to
    from inside code section with < <name of section referred to> >.

    ./li. .li. I view my file in a web browser, and reload the page after editing updates.
    Because I write my Literate Source with help from the MOLLY.pl script (see below how to 
    set it up), every "heading" in HTML (i.e.  h1,  h2  etc. ) automatically becomes a .b. 
    folding subsection ./b. of the document I see in the browser, and every code section is 
    automatically formatted with line numbers and a frame.

    ./li. .li. When I think ("globally"), I look at the formatted, immediately updating document
    in the browser, keeping open only the sections relevant to my thinking.
    When I edit, I refer to the line numbers, and avoid navigating "blindly" in the programming
    editor, stressing my memory. I edit "locally".
    This is what makes all the difference.

    ./li. .li. Automatically created folding documents allow me a number of techniques and
    uses impossible previously with flat "literate programming" files.

    ./li. .li. I tangle the created code either directly with a built-in Molly tangler, with
    "notangle" tools from "noweb", or by running "MyProject.tangle", which is a link to 
    "MyProject.weave", the actual main Literate Source file turned into a perl script by inclusion
    of the MOLLY.pl into it.
./ol.

See details about this setup and possible uses of it below.
}}}3

#-------------------------------------------------------------------
{{{3 .h3. SET UP a Literate Source file and project ./h3.
#--------------------------------------------------------



#--------------------------------------------------------
.h4. Prerequisites: "noweb" tools By Norman Ramsey ./h4.
#--------------------------------------------------------

    The script now has a built-in simple tangler, which can tangle arbitrary roots
    from the Literate Source file.

    However it is possible to  use a "pass-through" tangler, i.e. delegate actual
    tangling to the "notangle" utility from the "noweb" suite.

    "Noweb" set of tools has been around for more than 10 years, and is well tested.
    It is also more flexible, at least for now.
    It would be prudent to compare tangled output of Molly with that of noweb, until you
    feel sure you can trust it.

    Please obtain and install "noweb" . .b. .i. Make sure the tangler is in your path ./i. ./b.
     .a. http://www.cs.tufts.edu/~nr/noweb ./a.

    Any version will do, e.g. the one based on shell and awk. I created the MOLLY script 
    to work with the overall markup of the "noweb" tools. It means your project file(s) 
    can be directly processed with "noweb" tools. MOLLY is mostly intended as an alternative
    weaver which creates folding HTML documents on the fly.


#------------------------------
.h4. Setting up the file ./h4.
#------------------------------


    I aimed at simplifying and eliminating unnecessary steps, and wanted to automate some others.
    Therefore practical work with MOLLY.pl looks like this:

    .ol. .li. .b. .i. Your Literate Source file must be "mollified" ./i. ./b., i.e. you have
    to add an invocation of MOLLY.pl as the first lines of it. Think of it as a template. You
    will write your Literate Source text right after these initial lines.  The minimal template
    is this:

<<minimal MOLLY template>>=
    #!/full/path/to/perl
    do "/full/path/to/script/MOLLY.pl";
    exit;
    # delete first space(s) in the next line
    __DATA__
    #----------------start of the script------------

    <h1> And here I start My Project </h1>
    Your Literate Source file can be typed here

    <h2> Subsection </h2>
    level 0-9 of subsections are allowed now.

    Each subsection will be automatically created as "folding". 
    Javascript must be enabled in your browser to use this functionality
@

    The perl invocaton and the "__DATA__"  line must start .x. at the first position ./x.

    You do not need any extra perl modules  as pre-requsites, the script uses core perl.  

    Full template will also set configuration variables which adjust its behaviour.

    Save this under some name, e.g. MyProject.txt. This turns your Literate Source file into
    a perl script

    ./li. .li. .b. .i. Make it executable. ./i. ./b. 
	.pre. chmod 755 MyProject.txt ./pre.

    ./li. .li.  .b. .i. The script behaves according to its name extension ./i. ./b.
    The script will produce HTML-formatted documentation, if its name ends with "weave" 
    (default - or whatever you selected when setting configuration variables in the 
    "mollification" template). 
    Invoked under a name with file extension of "*.tangle" (default) it will "tangle",
    i.e. create machine code.
    So,  name or rename your LSFile "MyProject.weave" and create a soft link to it named
    "MyProject.tangle" (or whatever alternative you set in configuration for tangling):
    .pre.
	mv MyProject.txt MyProject.weave
	ln -s MyProject.weave MyProject.tangle ./pre.

    Now if you run MyProject.weave, it will dump HTML-formatted documentation of your work to STDOUT
	.pre. ./MyProject.weave > MyProject-formatted.foldingdocument.html ./pre.
    It you run MyProject.tangle, it will dump machine code from your Literate Source file to STDOUT.
	.pre. ./MyProject.tangle > MyProject-runnable.script.pl ./pre.
    ( Of course, tangling is independent of the language you program in )

    For example, if you develop in perl, you can run the resulting script like this:
	.pre. ./MyProject.tangle | perl [perl options here] - ./pre.

    Additionally, as the markup is the same as that of "noweb" tools. one can use them directly
    on the My.Project.weave file, with all of their flexibility and extra options.

    However the idea was to avoid running some of these commands after each change in
    the file manually and to avoid saving the weaved docs: STDOUT can be picked up by
    your local web server as CGI, and you will have an HTML-formatted and which is more
    important, .i. folding ./i. document in your browser by simply reloading the page 
    (usually with Ctrt+R or a mouse click)

    ./li. .li. Now, .b. .i.  the only other step is to run a local web server ./i. ./b. 
    on localhost, any tiny very simple httpd will do, and tell it to treat "*.weave" as
    valid cgi file extension. (Alternatively, I can set "weaving" to files that end in 
    '*.cgi" or "*.pl" etc. in the configuration part of my MOLLY template)

    One of the simplest WWW servers for such use could be "thttpd", and I will provide you with its
    minimal configuration file below.
    ./li. ./ol.



#------------------------------------------------
.h4. "Mollification" - full configuration template ./h4.
#------------------------------------------------
Should be self-explanatory, at least after reading this documentation section ;). 
May add to this section later. Uncomment to set, otherwise defaults apply.


<<full MOLLY template>>=
#!/usr/bin/perl

#-------------------------------------
# -------TOC and INDEX behaviour------

# print TOC? 1:0
#$print_toc=1;	# default is to print

# should we keep TOC expanded? "block":"none"
#$toc_expanded="block";	# default is to unfold

# should we keep Chunks Index expanded? "block":"none"
#$ind_expanded="none";	# default is to keep folded


# should we number lines in code sections? 1 : else
#$line_numbering = 1;	# default is to number


#-------------------------------------
#---------MathML options--------------

# should we enable MathML via ASCIIMathML.js or LaTeXMathML.js library? 1:0
#$enable_ASCIIMathML = 0; #default is to disable as it slows Molly down a lot
#$enable_ASCIIMathML = 1;

# If yes, what is the full path to the lib? Remember to get the one with proper
# escapes for your work, default or modified (see documenation)
# CAN BE: (a) local "/full/path/from/root/to/ASCIIMathML_with_modified_escapes.js" or 
# (b) in current dir "ASCIIMathML_with_modified_escapes.js" or
# (c) on the web, e.g. the original site of the library (unmodified) is:
#$path_to_ASCIIMathML = "http://www1.chapman.edu/~jipsen/mathml/ASCIIMathML.js";
#$path_to_ASCIIMathML = "ASCIIMathML_with_modified_escapes.js"; # default is current dir


#-------------------------------------
#--------Document Markup lang---------

# how are doc sections marked? "dotHTML":"rawHTML"
#$weave_markup = "rawHTML"; # default is "rawHTML"


#--------------------------------------
#---------File extensions setting------
 
# what is the file extention to weave it? (perms must allow execution!)
# e.g. "scriptname.weave" or "scriptname.cgi" etc.
#$weave_extension = "weave";	# default is "weave"

# what is the file extention to tangle it? (perms must allow execution!)
# e.g. "scriptname.tangle",  "scriptname.pl" etc.
#$tangle_extension = "tangle";	# default is "tangle"

#When tangling, should I use the built-in tangler? 0:1
# (if 0, the "pass-through" tangling will call "notangle"
# from Ramsey's "noweb" tools, must be installed and in your path)
# $use_builtin_tangler = 0; # default for now is to use external "notangle"


#--------------------------------------
#---------invocation of MOLLY.pl-------

# make sure to provide correct and full path to the script here
# (default is "current directory"):
do "MOLLY.pl";
exit;

# delete the space before the __DATA__ marker
 __DATA__
#---------------start of script-------------

<h1> MY PROJECT </h1>

The main idea for my new project is ..

<h2> Subsection 1 </h2>

Here I explain things that come first
................................

@

.b. "__DATA__" must start at the first position in its line ./b.

A better example can be seen in a new project template file that comes with
MOLLY distribution. Copy it to a different name and start editing.



#---------------------------------------------------
.h4. Markup of code and documentation sections ./h4.
#----------------------------------------------------

.b. First, ./b.
    .ul. .li.  code sections begin with "< <name of the section> >="
    in the first position in the line and end with "@"  in the first position
    .i. no spaces between the double angle brackets - I used spaces as escapes here ./i.
    
    ./li. .li. References to other code sections are done with "< <name of the ref sect> >"
    inside the code sections

    ./li. .li. The rest is "documentation chunks" which must be marked up with some formatting
    tags. (The default is html).

     I do not insert examples here, as the file you are reading provides them ad nauseam.

    THIS IS THE BASIC MARKUP OF THE LITERATE SOURCE FILE, as used by the 
    "noweb" tools.

    .i. .b. NOTE ./b. ./i. While Molly uses the same markup. .b. "notangle" allows to skip 
    "@" signs./b. in the first position on the line if the next chunk is also code.
    .b. Molly insists on full markup. ./b. Molly tangled examples from 'noweb' distribution 
    correctly when those were canonized to use full notation.


    ./ul.

.b. Secondly,./b. how do we format the documentation sections?

    .ul. .li. In the simplest case, with straight HTML markup (default)

    ./li. .li. If a simple subsection is added to the MOLLY.pl script to process it, in any
    markup lingo of your choice (e.g. "wiki") 
    
    Currently I provide a "dotHTML" formatting subsection as an example. It implements
    a few of the most common HTML tags but with "dots" around them, in place of angle brackets 
    "<" and ">" (which is faster, as one does not need to switch register, so is less prone 
    to typos). See below for more detailed explanations
    ./li. ./ul.
    
    .b. .i. The only difference ./i. ./b. from the truly "raw" HTML is that except in "pre" sections the MOLLY.pl script will 
    add automatic <br> tags at the end of each line of your Literate Source file.



#--------------------------------
.h4. Tangling from LSFile ./h4.
#--------------------------------

    .ol. .li. Usually only one file needs to be tangled constantly, the file the developer
    is working on.  It's easiest to do by using the "default root", which is a code chunk
    called "*". When you run 
    .pre. MyProject.tangle > source.pl ./pre. 
    MOLLY will pass the command to "notangle" from Ramsey's "noweb" tools, or tangle it
    itself if configured at the top of your project file and then it will print code
    chunks starting from the one named "*". Therefore, I drag along the default root to
    wherever I am editing now and reassigning to it the chunk I need to tangle currently.
    I usually keep the pointer subsection at the top of the Literate Source file. See 
    "THE CHUNK TO TANGLE BY DEFAULT" in the file you are reading as an example of this
    technique.

    This is the task for which MOLLY "quick tangling" is designed.

    ./li. .li. If, however, you need to tangle out non-"*" root, you have two options:

    (a) run MOLLY.pl from command line:
   .pre. MOLLY.pl -R 'root chunk name' literate_project_file ./pre.
    If chunk name is not supplied, the script will tangle from "*", the default root. 

    (b) ..or you might run N.Ramsey's "notangle" utility directly on your Lit.Source file. 
    .pre. notangle -R 'root chunk name' literate_project_file ./pre.
    This is the most flexible way, as "noweave" allows for extra pre- and post-processing.

    ./li. .li. If you need to tangle out many source files, then probably the easiest way
    to arrange it is through many invocations of Molly.pl or "notangle" in a makefile.
    Include "Makefile" subsection into your Literate Source file and create a target that
    combines several "notangle -R ... " commands in it.
    Assing default root "*" to the Makefile, then run "MyProject.tangle > Makefile" to create
    it and next run "make targetname" to tangle (and compile, run etc) many files included
    into your Literate Source project file.
    ./li. ./ol.

    .i. .b. NOTE ./b. ./i.
    that Molly uses the same markup for document and code sections as "noweb".
    Nowever .b. "notangle" allows to skip "@" signs./b. in the first position on the line if
    the next chunk is also code.
    .b. Molly insists on full markup. ./b. Molly tangled examples from 'noweb' distribution correctly
    when those were canonized to use full notation.


#------------------------------------------------
.h4. Sample minimal configuration of thttpd ./h4.
#------------------------------------------------

"THTTPD" home is .a. http://www.acme.com/software/thttpd/ ./a. 

From the distro README:
.ul. thttpd is a simple, small, portable, fast, and secure HTTP server. 
.b. Simple: ./b. It handles only the minimum necessary to implement HTTP/1.1. Well, maybe a 
little more than the minimum. 
.b. Small: ./b.  See the comparison chart. It also has a very small run-time size, since it 
does not fork and is very careful about memory allocation. 
.b. Portable: ./b.  It compiles cleanly on most any Unix-like OS, specifically including FreeBSD, 
SunOS 4, Solaris 2, BSD/OS, Linux, OSF. 
.b. Fast:  ./b.  In typical use it's about as fast as the best full-featured servers (Apache, 
NCSA, Netscape). Under extreme load it's much faster. 
.b. Secure: ./b.  It goes to great lengths to protect the web server machine against attacks and 
breakins from other sites. 

It also has one extremely useful feature (URL-traffic-based throttling) that no other server 
currently has. Plus, it supports IPv6 out of the box, no patching required.
./ul.

Its compilation is very quick. Its configuration is simpler than that of Apache. 

Supposing I'd like to point my browser at "http://localhost:8000/path/to/MyProject.weave"
Then the minimal configuration will look something like this:


<<minimal thttpd configuration>>=
#
host=localhost
port=8000
dir=/my/home/00trash/tmp/literate.perl/WORKDIR
data_dir=/my/home/00trash/tmp/literate.perl/WORKDIR
#chroot

# extensions understood as valid "cgi" scripts:
#cgipat=/**.cgi|/**.weave|/**.pl
#cgipat=/**.tangle
cgipat=/**.weave

#logfile=/my/home/00trash/tmp/literate.perl/WWW.server/thttpd.log
logfile=/dev/null

#pidfile=./thttpd.pid
pidfile=/home/vedmed/00trash/tmp/literate.perl/WWW.server/thttpd.pid

# uncomment this to be able to link from anywhere to your web server document dir 
# (unsecure, for local development only)
nosymlink
#
@
.b. NOTE ./b. that "nosymlink" schizophrenically .i. allows ./i. symbolic links in spite of what
thttpd documentation tells you

The script to start thttpd (it will detach and run as a daemon) is something like this:

<<run.thttpd.sh>>=
#!/bin/sh
PROJECT_ADMIN_DIR="/my/home/00trash/tmp/literate.perl/WWW.server";
#./thttpd -p 8000 -h localhost -C ./thttpd.config
#$PROJECT_ADMIN_DIR/thttpd -nos -C $PROJECT_ADMIN_DIR/thttpd.config
$PROJECT_ADMIN_DIR/thttpd -C $PROJECT_ADMIN_DIR/thttpd.config
@

}}}3

#-----------------------------------------------------------------------
{{{3 .h3. CREATE a Literate Source file -- documentation chunks markup./h3.
#-------------------------------

#-----------------------
.h4. Doc sections markup ./h4. 
#-----------------------

.ol. .li. .b. The default is to use ordinary 'html' markup ./b. in the document sections
The only difference from "true raw" HTML is that MOLLY adds automatic 
<br> linebreaks unless lines are inside the <pre>..</pre> sections
The script also cuts out vim folding marks -- { { { number ... } } } number
-- without spaces  and "#------------" lines.


./li. .li. .b. Any "markdown" or "wiki"-style markup can be added ./b. to MOLLY. Another 
reasonable suggestion could be a simple translator from basic TeX markup etc.
Some of this functionality is unnecessary to reimplement, as "noweb" or third-party 
filters can be run on the document after MOLLY weaving or from inside MOLLY.

./li. .li. .b. dotHTML is an example of a simple markup ./b. which can be done with regular
expressions, which is several most basic HTML tags inside "dots" instead 
of angle brackets.

Dots do not require switching the keyboard register, and therefore I can speed up
typing and avoid annoying repeating typos. This is my own "markdown" of sorts.

Currently implemented tags are (write them inside "dots", not "<..>"):
.ul. <br> <p>  <s> - </s> <pre> - .. <b> - </b> <i> - .. <ul> - .. <ol> - ..
<li> - ..

Special marks are dot-<-dot and dot->-dot (no dashes, like ". < ." 
without spaces) which are needed if the tag includes some options or
is not among the tags "dotHTML" understands already.
These will be converted to single < and > respectively.
This is clumsy, but for quick sample and to speed up typing I found
it sufficient. So far.


And there are three special, non-HTML marks I introduced for convenience.
(a) dot-x-dot ... dot-/x-dot .i.on one line only ./i. will .x. format the phrase ./x. as spaced
(b) dot-a-dot http://some/URL dot-/a-dot will create a hyperlink .a. http://some/URL ./a. 
(c) dot-sp-dot - creates a space
./ul.

etc. I add them as I go, whenever I need them for my current document.

This formatting also adds <br> linebreaks unless lines are inside the 
<pre>..</pre> sections.
"dotHTML" also cuts out vim folding marks 
.pre. { { { number ... } } } number ./pre.
without spaces, and  comment lines with dashes
.pre. "#------------" ./pre.
./li. ./ol.


#------------------------------
.h4. Markup and Escaping ./h4.
#------------------------------

Escaping in files marked in multiple ways is a big source of all kinds of errors.
Currently Molly should be able to take care of most cases.

Exceptions include:

1.  .b. double angle brackets ("< <" and "> >" without spaces in between) and the "at" sign ./b.
Those confuse the "notangle" tool from Ramsey's "noweb". While Molly treats
double angle brackets and "at" as a switch between documentation and a code chunk .i. only
if those are in the first position in the line ./i., "noweb" stumbles.

If you tangle through Molly (by running "my_project.tangle > source.code"), Molly will
filter these out. If you run "notangle" directly on the project file ("notangle -R'some 
root chunk' my_project.weave > source.code"), it will fail.

Therefore in this file I always .i. use extra white space btw angle brackets as an escape ./i.

2. If you enabled the use of ASCIIMathML.js library to display mathematical exressions in
you document, then .b. double backticks ./b. on both sides of any expression pass 
processing to the library. (It also processes everything between "a m a t h" and
"e n d a m a t h" tags - no spaces btw letters - in you file).
Make sure that your target programming language or any future "markdown" you are going to 
add to Molly does not use these signs at all -- or re-edit the javascript library to
substitute all inclusions of double backticks to sth else.

}}}3

#------------------------------------------------------------------------------
{{{3 .h3. Mathematical Formulae - MathML inside Mollified Literate source files ./h3.
#------------------------------------------------------------------------------

.i. The most common reason users put forward for the continued use of (La)TeX in this day 
is its facility in dealing with mathematical notation. However today much .b. simpler HTML ./b. 
(which is often further reduced to "markdown" level) if .b. used with MathML ./b. can cover 
most of such needs./i.

.b. 1 ./b. There are two libraries in JavaScript, ASCIIMathML.js and LaTeXMathML.js (derived 
from the former) which do translation "on the fly" in the reader's browser. Those provide 
almost a drop-in  functionality and can be used with Molly.

The latest version of the ASCIIMathML.js library (2.0.1) includes .b. .i. both ./i. ./b. 
ASCII and LaTex processing. 

.b. 2 ./b. There is a very nice "mimeTeX" application which is a C program that can be run
as CGI (i.e. under the same web browser you use for Molly), which produces GIF renderings
of LaTeX formulas on the fly. It is more complete that ASCIIMathML.js.
I will include an option to use it with Molly if it is dropped into your work directory in
a next version.

#----------------------------------------
{{{4 .h4. How to use ASCIIMathML.js in Molly ./h4.
#----------------------------------------

.b. 1 ./b.. To enable MathML one needs to use a compliant browser. Currently MathML is built in
Firefox, or it can be enabled in Internet Explorer with a (free) plugin.

For Opera the support is also built-in, however the library actually checks for the browser type
and then it seems disallows Opera. The Opera browser, however, has another feature to bypass
exactly that and lie about its identity. If "identify as Firefox" is set in your Opera browser,
the MathML output is caught and rendered.
I did not see any difference between Firefox and Opera_pretending_to_be_Firefox in rendering
output of the library.

.b. 2 ./b.. To enable MathML while dynamically creating the folding-html file, I use an LGPLed
Javascript library called "ASCIIMathML.js" from 
.a. http://www1.chapman.edu/~jipsen/mathml/asciimath.html ./a.
(the home page), while only the library itself can be copied from
.a. http://www1.chapman.edu/~jipsen/mathml/ASCIIMathML.js ./a.

.b. 3 ./b.. The use of MathML must be .b. enabled in the "mollifying" template ./b. at the top of your
Literate Project file, and the path to the ASCIIMathML.js added. See the config. 
template subsection above

.b. 4 ./b.. I had to .b. change escape symbols ./b. in the library not to conflict with 
.i. programming symbols ./i. - now it's double backticks instead of single ones -- and 
change config option enabling "preservation of $ and $$"

Therefore a copy of modified library is distributed with the Molly script.
The default location for Molly to work with is in the same directory as the Molly.pl.
Adjust configuration as needed at the top of your script.

If the rest of your file does not conflict with default ASCIIMathML.js escapes, i.e. does not use
$ signs and single backtics, you can point to the original unmodified library and distribute that
one with your work (see detailed explanations below).

.b. 5 ./b.. This javascript library allows a user .b. to type math formulas in simple calculator-
like ASCII notation with LaTeX constants ./b. if needed.

The interpreted parts of the text must be either:

(a) .b. .i. between "a m a t h" ...... "e n d a m a t h" tags (no brackets). ./i. ./b. The script
then tries to differentiate between ordinary text and math expressions and renders the latter
dynamically as MathML - which is then displayed by your browser.

It might get confused etc. (e.g. because you used underscores somewhere); then your math
could be

(b) .i. .b. escaped (the math expressions only) with DOUBLE BACKTICKS around them. ./b. ./i.

}}}4

#----------------------------------
{{{4 .h4. 6 . Some examples and LaTexMathML.js library versions ./h4. 
#----------------------------------


..are quite intuitive:

Let's try some interesting formulas: 
E=m c^2 ---> ``E=m c^2`` and e^(i pi)=-1 ---> ``e^(i pi)=-1``

and AA x in CC (sin^2x+cos^2x=1) ---> ``AA x in CC (sin^2x+cos^2x=1)``
and one more: sum_(i=1)^n i^3=((n(n+1))/2)^2 ---> ``sum_(i=1)^n i^3=((n(n+1))/2)^2``

..and here are .b. more realistic math expressions ./b. taken from a depository of some math 
    student and written in TeX notation. I drop $$ .. $$ wrapping the in-lined expressions 
    though and delimit it with double backticks instead. Here's the test:

    Hover your mouse over the expression to see the ASCII/TeX coding:

Freudental Formula
``mult(\xi)=\frac{2}{(\mu+\rho|\mu+\rho)-(\xi+\rho|\xi+\rho)}\sum_{\alpha\in\Delta^{+}} mult(\alpha) \sum_{k=1}^{\infty}mult(\xi+k\alpha)(\xi+k\alpha|\alpha)``
It includes roots ``\Delta=\left\{k\delta+\alpha|k\in Z,\; \alpha\in \Delta_0\right\}``
positive roots ``\Delta^{+}=\{k\delta+\alpha|k\geq 0,\; \alpha\in \Delta_0^{+}\}\cup \{k\delta+\alpha|k\geq 1,\; \alpha\in \Delta_0\setminus \Delta_0^{+}\}``

.i. NOTE ./i. If you hover with your mouse over some interpreted expression, a baloon
will appear showing the original ASCII markup for the expression. Very nice.

.i. NOTE 2 ./i. the "pre" (preformat) "/pre" HTML tags prevent the library from
rendering the expressions and might even be used as a quick escape tool when you are writing
your page.



.b. Some TeX operators are not understood by ASCIIMathML.js ./b.
(the failing test is in the ADD-ON MAthML subsection of the Source Code
 section in this document). The reason is most likely that the lib was 
never told about those 1 or 2 constants and operators on which it fails

.b. To solve ./b. the problem one might explore another version of the library, "LaTexMathML.js"
(of which there are 2 or 3 versions) changed to  interpret  the actual LaTex code:
.a. http://www.maths.nottingham.ac.uk/personal/drw/lm.html ./a.

One more version is here:
.a. http://math.etsu.edu/LaTeXMathML/ ./a.

One more version (related) of LaTexMathML.js is here:
.a. http://pillars.che.pitt.edu/LaTeXMathML/ ./a.
.a. http://pillars.che.pitt.edu/LaTeXMathML/latexmathmlguide.xhtml ./a.

.. and there is even a perl port for that
.a. http://pillars.che.pitt.edu/LaTeXMathML/ ./a.
(which also can potentially be used from MOLLY)


I have not tested those in full, but the use of JavaScript libraries from MOLLY should be
identical (and so it says in the documentation inside the libraries) to that of ASCIIMathML.js
They are directly interchangeable in a standalone HTML-based editor. Just point to a copy of the 
needed lib in the configuration section of your Literate Source file.

.b. Secondly ./b. the home page for the library mentions (at the very bottom) that the library
encoding in its JavaScript source file is straightforward and more translations can be added
as needed.
Here is the URL: .a. http://www1.chapman.edu/~jipsen/mathml/asciimathextend.html ./a.

I will provide a section in the Literater Source of Molly (in the ADD-ON section for MathML) 
to add all necessary definitions. It .b. .i. is ./i. ./b. very easy ;))

.b. NOTE ./b. 
.ul. .li. I had to adjust the lib (double backticks and preservation of $) because I was concerned
with programming languages. The source code must stay untouched by the math library 
(mis)translations. That is why I provide a copy of the lib with MOLLY.

./li. .li. If one wishes to use MOLLY for writing mathematical notation without conflicting computer\
language code sections, one can always .b. link to an unmodified copy of the same lib ./b.
and distribute that one with your work ( in *.mht files, see below) or even link to an 
address on the web.

./li. .li.The same applies to a version of the lib to interpret TeX rather than ASCII math notation: 
MOLLY inclusion of the library is generic, just point to the correct javascript library.
./li. ./ul.

}}}4

#--------------------------------------------------
{{{4 .h4. 7 .  ASCIIMathML Markup - reference ./h4.
#--------------------------------------------------

The full set of ASCII notation conventions for the library can be found on its
home page.
.a. http://www1.chapman.edu/~jipsen/mathml/asciimathsyntax.html ./a.

There are 2 pages there, the first describes the syntax, and the second one shows allowed 
LaTex escapes.

The easiest way to see the ascii code and to use any interpreted page as a reference is to
hover your mouse over an interpreted math symbol or expression. In about a second a baloon 
appears  with the ascii source in it.

There is an on-line tutorial in the use of ASCII math notation  for the library at
.a. http://www.wjagray.co.uk/maths/ASCIIMathTutorial.html ./a.
and .a. http://www.wjagray.co.uk/maths/ASCIIMathMLinfo.html ./a.

.b. One more URL ./b.
"an on-line ASCIIMathEditor" is here
.a. http://www1.chapman.edu/~jipsen/mathml/asciimatheditor/ ./a.

It is great to quickly test your expressions. 

Works in my case (firefox on Linux) if I save the page ("full page") and use it from
local files. Could immediately see what I am typing, next copy and paste expressions
into my target file.

Useful. Just delete the spy from google, "the urchin tracker" from the page ;)) .

}}}4

#----------------------------------------------------------------
{{{4 .h4. How to distribute your final folding HTML-formatted work ./h4.
#----------------------------------------------------------------

.b. 8 . To distribute your HTML-weaved folding files with MathML notation ./b.
afterwards you'll have to provide a copy of the JavaScript library with the weaved html 
file, as well as any images you might have used there.
This can be done by creating .b. *.mht archives ./b. from them.

(to explain: MHT is a base64-encoded concatenation of elements of a page
    and its images, scripts etc.;
    MAF is a Mozilla zip-comression of page or several with all images etc into one
    archive file).

Note that because I had to modify escapes in the library for it not to clobber single 
backticks and $ symbols, so common in programming, one has to provide a copy of the 
modified lib with your HTML work.  You cannot simply link to any copy ot ASCIIMathML.js 
found on the Net. (You could if you use an unmodified copy though).

Internet Explorer has built-in support for *.mht (as it is a MSoft standard).
For Firefox the problem is solved easily by installing either
"UnMHT" add-on: .a. http://www.unmht.org/unmht/en_index.html ./a.
or "MAF" add-on: .a. http://maf.mozdev.org/ ./a.

Then just open the weaved html file in your browser, and "Save As" *.MHT, it will 
include all images and the library with it.

So: (a) weave an HTML file from Molly
    (b) open it in IE or Firefox with MHT add-on, and 
    (c) save it as one file.

This will allow you to distribute your MathML marked files with included images, plots
etc. in a convenient manner.
If you are strictly Firefox-based, you can also use the open zip-based MAF format.


}}}4

}}}3

#-------------------------------------------------------------------------------
{{{3 .h3. READ and SEARCH inside a Folding Literate Source file ./h3.
#------------------------------------------------------



#----------------------------------------------------------------------
.h4. Opening many relevant subsections together, TOC highlighting ./h4.
#----------------------------------------------------------------------

One advantage of the folding format is that - in contrast to most other tools - it allows
    the programmer to open .i. many ./i. relevant sections from any parts of the file .i. at the 
    same time ./i.

    This can be done by "walking" the Literate Source file, as its sections and subsections are a 
    kind of TOC of themselves.
    This can be done from the TOC section as well. The open sections get a highlighted background,
    and highlighting appears irrespective of whether the section was opened from the TOC or in the
    body of the text.



#--------------------------------------------------------------
.h4. Keeping some sections of the LSFile permanently open ./h4.
#--------------------------------------------------------------

The behaviour of folding sections in the mollified LSFile is as follows:
    .ul. .li. If you click on the .b. "expand all" ./b. link anywhere in the document, all folding 
    sections in the body (not TOC/Index) will open. The limitation is 10000 objects per document,
    hardcoded.
    ./li. .li. If you click on .b. "collapse all" ./b., all folding sections in the body will fold. 
    The limit is 10k objects per document
    ./li. .li. If you .b. reload the document ./b. in your browser ("Ctrl-R" or an icon click), the
    document will be shown with sections open or closed .b. as marked ./b. in the document itself.
    ./li. ./ul.

    .b. The markup ./b. is simple: if you'd like a section to stay open upon load/reload,  
    add a "+" before "h" in the opening  heading tag:
    .pre. <+h1>, or <+h2>, ... ./pre.

    This is important when you work on a section or many sections of your LIterate Source file for
    a longer period and could not click them open in teh browser time and time again, after each 
    minor code change when you reload the "project.weave" in your browser to see the updates.

    Such changes - adding or deleting a "+" - can often be done with one command in a programming editor.
    For example, to open the whole subthread in vim, issue a range command, sth like
    .pre. 1024,1150s/<h/<+h/ ./pre. (i.e. substitute between lines 1024 and 1150 of your Literate Source file)

    Another suggestion is, when you, for example, work with several program files inside your LIterate
    Source (project) file, you might keep subthreads marked open, while changing only the topmost 
    heading to show/hide the whole of that file/subthread code and notes.

    Even when you handpick the sections to keep open, I found, this arrangement suits me well, at least
    for medium-sized LSFiles up to several thousand lines long.
    I also use folding inside "vim", and so line ranges are visible at one glance: "z-a" to collapse the
    vim fold, and then see the range and issue the range command.

    .i. Note ./i. 
	.ul. Use of folding inside your programming editor .x. is not a substitute ./x. for reading 
	a well-laid out formatted document in the browser. Vim folding is still "blind" and  navigation
	inside such a file still has to rely on your memory of the full layout. 

	MOLLY numbers lines in the code sections by default, making jumps from reading in your browser
	to editing a particular line in your editor painless. I could also put it like this: .b. I view
	the file globally ./b. in my browser as a folding document when I am thinking, .b. while editing 
	"locally" ./b. in a programming editor, without thinking about the overall layout of the file.

	./ul.

    MOLLY.pl is written to filter out vim folding markups ( {{{number ... }}}number ) and those 
    will not show on your web page.




#------------------------------------
.h4. TOC and Code Chunks Index ./h4.
#------------------------------------

Traditional literate programming tools create extensive indeces of variables and code chunks.

    The approach in this script is as follows:

    Index of all code chunks in your LSFile exists (unless a configuration opton in the 
    template tells MOLLY to skip it) right under TOC. Click on teh line to expand it, and then use
    TOC section numbers to click open the sections which contain or define the chunks you need.

    Remember that .i. all parent sections ./i. above the needed one must be open for you to see 
    the innermost subsection in your browser. This is easy to control through TOC highlighting, and
    as an additional indicator, the slider on your web browser will visibly jerk and shorten when 
    new sections will become visible in the browser window.

    It's also convenient to keep some inner subsections open, but click closed the topmost section to
    quickly hide and unhide larger pieces of code (e.g.complete files which live inside the Literate
    Source File when it is used as a common Project file for many source files, test files, makefile(s)
    etc.



#------------------------------------------------
.h4. Searching for symbols, chunks, phrases ./h4.
#------------------------------------------------

Web browsers "search" functions  will work on open sections only, at least that's the behaviour of
    Opera and Mozilla browsers.
    This means that instead of creating exhaustive indeces of symbols, which clutter program text, 
    especially when they display as HTML links in the output of Weaver tools, one can ensure only the
    interesting subsections are open and then search using the built-in browser function. It usually
    highlights the results and iterates over the found items, which is a nice behaviour.

    To search in the whole of the LSFile, simply click on the "expand all" under any of the subsections,
    and then again use the browser search function.



#--------------------------------------------
.h4. TOC/Index unfolding and collapsing ./h4.
#--------------------------------------------

    The TOC and Index at the top of the document can be kept folded or expanded upon initial load
    depending on the configuration variables in the "mollifying" template you add at the top of 
    your Literate Project file. Please see the subsection titled '"Mollification" - full template' above
    Of course, those subsections can always be opened/closed manually at any time

#--------------------------
.h4. Use for printing ./h4.
#--------------------------

Unfolding only the needed sections also seems to work well with printing from the browser window.
    You can therefore avoid picking certain pages manually from "print preview". You'll print only
    the visible part(s) - i.e. the open sections and the topmost folded section names, which do not
    take place if your document is marked in a sane way, and rather help the reader to orient himself
    while looking at the printout.

    Just remember to check the font size in the "print preview" when preparing to print for the first 
    time.



#--------------------------------------
.h4. Text browsers and JavaScript ./h4.
#--------------------------------------

Web page folding seems to work well with text-only www browsers, such as  "lynx" or 'w3m': they do not 
understand javascript folding, and so display the whole document.

Here's an example invocation with w3m:
.pre.  ./MOLLY.weave | w3m -T text/html  ./pre.
.i. Note ./i.MOLLY does not issue HTTP headers, and this may affect browser behaviour. The web server
 and/or browser may add them or not, or ignore them or not. I might need to correct that.

If JavaScript in your GUI browser is turned off, you'll see only the sections marked in the body
of the Literate Source file as open.


}}}3

#------------------------------------------------------------------------------------------
{{{3 .h3. SUGGESTED USES: Work with Folding LSFiles./h3.
#-----------------------------------------------------------
.i. .b.  section unfinished; an outline of major points for now ./b. ./i.

I do not show examples below, as the document you are reading itself is an example of the
techniques (and that may be the reason it is too bloated and somewhat unorderly ;)) ).

.ol. .li. Literate Programming proper.

    Emphasis on note-taking rather than producing a polished "essay" or "documentation"
	
    Traditional Literate Programming texts place much emphasis on the fact that it is a means of 
    providing .i. documentation ./i. (albeit with source code, and reflecting the thinking rather
    than machine-imposed order).
    Knuth first thought of LP as a documentation tool, then upgraded it to a "programming paradigm",
    but insisted on writing programs "like literary essays".

    However I would like to suggest placing emphasis on NOT documenting and NOT producing 
    polished code or an essay in thinking. The first use of this programming technique is 
    to  .i. keep a full log of your thinking ./i. irrespective of how polished or stupid it is.

    This is most precious. When you first attack a problem, several directions might come to mind,
    but once you began to work out one of then in detail, everything else is lost. This is the
    way human mind works. Keeping even briefest notes is more valuable than attempting to produce
    polished exposition.

    Psychological restrain people feel when they are compelled to prepare something for other people
    is probably the third major hurdle to wide spreading of L.P. (the first two were flat file 
    structure and formatting languages which doubled the effort of programming and debugging).

    My MOLLY Literate Source file is a log of my thinking, trials and experiments. I might later offer
    a cleaned version to other people, but I do not give a damn about them in the beginning.

    Non-folding L.P. source files could not accomodate inclusion of old versions, test files, bad
    versions and skeletons without polutting the file to the degree of becoming unusable.

    Folding version of L.P. source allows one to relegate bad trials into subsections  nicely folded
    out of the way by merely adding a single header line.

    When creating documentation, I could double the content of some sections, by copy-pasting the
    "cleaned" versions, and then save a version with the original snippets bypassed, which is
    easy and mechanical with tools like "gema", "awk" or "perl", just put a code word like
    "scrap" in the beginning and end of those sections you'd like to avoid.

    This ability to bypass marked sections when weaving, by the way, might be incorporated as an
    option into a future version of MOLLY, to produce both 'clean' and 'dirty' versions of the
   formatted Literate Source doc from one file.

./li. .li. Use as a combined Project file
    .ul. .li. to include tests and snippets that implement skeleton functionality to
    be embedded into the main program
    ./li. .li. to include versioning and changes in the way  that does not break what
    has been working so far (there was even a special term for that as a programming 
    principle). Keep the old version, put it into a subsection, and rename the chunk
    to bypass it. The newer version of the piece of code that is being reworked will
    get the old chunk name to be included into the chain to tangle out.
    ./li. .li. To keep a makefile (split, to which I can add lines from many places in
    my Literate Source as I grow it) together with source file(s)
    ./li. .li. To keep several source files related logically in teh same Literate Source file.
    ./li. ./ul.

    .i. Folding meta-files ./i. could be used for larger projects, in which 
    the meta-file, a folding document, would describe teh topmost level layout of the 
    project, and contain ordinary HTML links to partial Folding Literate Sourcefiles, which
    will keep all the junk as described above.

    In any case, the use of Folding Literate Source files would considerably simplify tracking
    of the project files in a version control system.

./li. .li. Use for system administration etc. - as a single file to keep many sysadmin scripts, 
    descriptions of conventions and procedures, bugs and changes in the system .b. .i. in one place ./i. ./b.
    from which any of the included source (or texts, if they are kept in the "source chunks") 
    can be obtained easily with a single command.
    ALSO: combine LIterate Source project file with a makefile as a simple means to keep 
    one-command tangling of multiple targets.

    This Literate Source can live in a central place (e.g. root home) and be under version control.
    The tangled pieces, config files or scripts could be copied to files on one or many machines.

./li. .li. Use for non-programming tasks:
    .ul. .li. as a note-keeper. E.g. I kept job listings and followi-up info in a folding
   MOLLY file and found it quite convenient. 
    ./li. .li. as an outliner for general purpose texts.
    ./li. .li. for keeping documentation, books etc. I keep documentation for a number of
    software tools (e.g. "awk", "newlisp", "monotone") in folding format. It .i. is ./i. helpful.
    ./li. .li. for editorial work on larger texts. The text itself will become "code chunks", 
    and editorial remarks and meta-thinking will remain as "documentation" in a Literate 
    Source file.
    ./li. ./ul.

./li. ./ol.


.h4. scrap ./h4.
(a) //CGI and CL invocations - compared to "noweb"
    // dotHTML tagging; alternative tagging, translations
    // alternative tanglers and pass-through tangler; makefile problem

(b) ideas - how to incorporate tests; how to keep a single project file;
how to set up dummy plugs and alternatives (i.e. to develop without destroying
the old working version)
Maybe: for distribution of a lot of small scripts (admin etc), the  way I used
Makefiles?

(c) It's possible even to do development in smallest chunks -- and later (e.g. for
outside clients or for higher-level documentation, etc.) to consolidate the tiny fractured 
bits and pieces, with plenty of alternatives, dummies, plugs and trials etc. etc.
How? - by tangling those from some certain level and copy-pasting the result into the
Literate Project File.
One could even keep the actual development fractions in a subsection, while retaining
higher-level and cleaner view in higher level sections. I do not care about doubling the
text at all.

.b.suggestion from a Slashdot 2002 discussion ./b.(see ref above) about style or approach:
do not document what the code does (which is redundant, as can be seen from the code itself),
document rather WHY it does it (what's the purpose or the idea).

.b. Also ./b. use this file itself as an example of all illustrated techniques.

Use .b."mollify"./b. as  a technical term (insert MOLLY.pl invocation into the LitProject file)

}}}3

}}}2


.h2. ./h2.

#------------------------------------------------------------------
{{{2 .h2. PART III ------------ LITERATE SOURCE OF THE SCRIPT ------------ ./h2.
#-------------------------------------------------------


#----------------------------------------
{{{3 .h3. Local Reference ./h3.
#--------------------------------

.b. VIM regexp to highlight literate code sections only: ./b.
.i. HAD TO spoil it because "notangle" complained about double diamonds 
"in documentation chunk", bastard ./i. .b. delete spaces btw angl brckrs ./b.
.pre. ^< <.*> >=\_.\{-1,}\n^@/e ./pre.
.. and vice versa, highlight text, leave only code unhighlighted:
.pre. ^@\_.\{-1,}\n^< <.*> >=/e ./pre.





}}}3



#----------------------------------------------
{{{3 .h3. Bugs, status, changes ./h3.
#----------------------------------------------

#-------------------------------
{{{4 .h4. Ideas - versions - changes./h4.
#-------------------------------

Current version:
.ul.
    .li. creates folding documents on the fly..
    ./li..li. ..based on dotHTML or rawHTML markup 
    (i.e. either to create new docs or convert existing HTML into folding format);
    ./li..li. and generates dynamically TOC and code chunks index;
    ./li..li. ties collapsing/expandind of sections with TOC highlighting;
    ./li..li. ..provides pass-through tangling with "noweb".
    ./li..li. provides built-in simple tangler which does not clobber tabs
    ./li..li. provides a tie to ASCIIMathML.js library for inclusion of 
	    mathematical expressions in your documents.
    ./li../ul.

    This script is a test of the concept (LitProg+folding+dynamic web formatting)


#--------------------------------
{{{5 .h5. first ideas ./h5.
#--------------------------------
    

    Options for future versions --  3 ideas for now:
    .ul.
    .li. .s. add a built-in tangler (while retaining the possibility to tangle
    through an external tool, such as "notangle" with all its options and filters). ./s.
    -- DONE

    ./li..li. .x.create a fully self-contained./x. folding web-based .x.weaver./x.
    ("Lilit") (plus possibly a built-in tangler).
    This can be done in newlisp (www.newlisp.org), which has a built-in httpd
    and allows creation of 250k+(size of script) standalone executables on all
    major platforms (unix/linux, windows mac).

    ./li..li. maybe - .x.add "views" (a la Leo views)./x. and maybe editing of single
    subsections (in a pop-up term window with a running editor).
    This - as I see it now - may/will involve storing each subsection in its 
    own little file and dynamically concatenating them both for dynamic weaving
    and for tangling ( keep a third name, some "scriptname.src" for dumping the
    full file to STDOUT?? )
    This can be done dynamically: a huge project file will be displayed fully
    collapsed, and then only the sections marked open will be dumped to the web
    browser dynamically.
    The whole thingy can be kept either as a bunch of section-files in a subdir,
    or (and/or) in a tar file (gzipped or not, indexed or not).

    .b. One possible implementation ./b. is with .a. http://www.wikiwyg.net ./a.
    - the "wikiwyg" library, which can turn any "div" into an editable section.

    The lib as it is distribted does not save (no sub that saves, actually), but
    one can "save in the browser" and next save the page from the browser to a 
    local file

    For a local programming setup ( thttpd on localhost:8000 for example) this
    will do. However one still needs to figure out if there is a possible post-
    processing of the dynamically created (and then saved from the browser) page
    with some script that would strip back the "frameset" decorations and the 
    invocations of folding plus the html head and TOC/chunks index sections.

    I might say, I need the "reverse weaver" (although not as thorough ?)

    .. and, secondly, after post-processing, if there is an invocation of "patch"
    which would apply the diffs back to the Literate SOurce file.

    .ul. .li. Will a "context patch" do? Can I postprocess
    ./li. .li. Can I postprocess the dynamically generated HTML to mimic some
    sort of diff markup (unified? Context? ...)
    ./li. .li. Third, the exact invocation to apply it to an LSF.
    Is manual restoration of this kind possible? Is it poss to run through a GUI
    merge tool? An "apply all left to the right one" automatic tool?
    ./li. .li. This can be presented as buttons on the page (when the wikiwyg
    option is enabled) etc.
    The script then would take another option (your_filename?apply_changes) to
    run this, and fail with a request to do a manual merge if not possible.
    ./li. ./ul.

    Then the question   remains, how practically useful/convenient that is.
    

    .i.How to do it./i.
    /* Basically, to manage sectionfiles I'd have to code as if those are comments
    to a blog entry (and dynamic gathering of them is the same, too. Should be
    rather obvious and possibly quite easy*/
    This 'views_enabled' mode will switch to sect-files in a ./.molly/ and will
    add dynamic links to each section: "edit section" (in an external editor);
    "update Literate Source Project file". And the script will start to check the
    subdir and dynamically reconstruct its HTML output in this mode.
    Same must be true for the "tangler" pre-filter, too - it will reconstruct
    the whole before passing it to the "notangle" utility.

    ./li..li. Is it possible to do .x."promoting/demoting"  of branches??./x.
    Is it possible in the view-enabled weaver?

    ./li..li. .x.add "web tangle mode"./x., in which MOLLY will dump coloured diff
    of the subsections (or the whole file if not too large), of the current version,
    tangled via the browser form versus a file on disk.
    (I do it all the time firing fldiff after each tangle - would be convenient to
    have the functionality before tangling to disk (with file renaming etc), just
    by reloading a page in a browser.
    Will need to allow saving files (or some branch of chunks) from the browser, then.

    Do I underuse .x. Vim ./x. ? - it does have .b. some "diff" mode ./b. for side-to-side
    display. Just open 2 files, current and prev. vers. and toggle btw one-file
    view and edit or side-by-side coloured diff ???

    .i.How to do it./i.
    .. by first (poss) checking that the files are not identical, and then by
    filtering into "diff":
    .pre. MOLLY.tangle|diff -y -w --left-column xxz - |less ./pre.
    Just wrap it into html-body-pre tags and colour if there's something in the 
    right half (not necessary, really)

./li. .li. .b. context diffs and sections editing ./b.   
./li. ./ul.

}}}5



#-----------------------------------
{{{5 .h5. more ideas ./h5.
#-----------------------------------

.b. More ideas: ./b.

.b. 1. Maybe ./b.  have the .x. "composite document" ./x. (or "fragmented document") 
    option for .x. the second-level ./x. meta-management .x. of project files ./x.
    I.e. one project could be split into many file-sections, and MOLLY weaver will 
    assemble them into the doc.
    OR: I maintain logically consistent pieces in medium-size project files, and
    keep a meta-project file with the split option enabled.
    The "edit" links from it will pop up gvim or another editor of choice with
    the full piece in it.
    While viewing will present it all as if one LIterate Source project file.
    I'll need only to mark the pieces in the TOC, possibly, as a separate doc,
    and -- .b. how will I treat TOC compilation then ? ./b.

.b. 2. Maybe ./b. - if I find an ASCII script (ascii art from commands and 
    descriptions), I could automatically generate .x. ascii-art "maps" ./x. 
    of the chunks ??


.b. 3. introduce horizontal/vertical layouts? ./b. 
    I.e. TOC and Chunks Index either on top of the file or on the left of it for
    "wide screens", like those on notebooks ??
    Changes are in  "Print out the resulting page" (currently line 3359)
     - plus options, of course

    Note: will require gluing TOC or the body to stick at the top, not simple table
    cells, which will center and resize depending on relative cell content sizes.
    May require separate scrolling for the two panes?

OR: .b. TOC/Index in a floating window? ./b. -- should be easy, just  name the
    output windows.

.b. 4. Maybe ./b. add ancors to folding section names to be able to 'hyperlink' 
    and refer to them from other parts of the document??
    // no jumps from the TOC? or with a separate 'jump' icon? //
    // no jumps to closed sections will work anyway, then what to do? //

}}}5




#-------------------------------------------
{{{5 .h5.  CONTRACT PROGRAMMING and Molly?? ./h5.
#-------------------------------------------

possibly add conditional tangling to produce a contract-assertion-littereted prog during
development and debugging --
versus a "clean" copy -- ???

.b. OR ./b. just keep an "assertion-full" skeleton  by using a simple "rename" or a 
meta-chunk which is a dispatcher??
.pre. [chunk_to_do_sth]=
 code code code code
 [another_chunk_ref]
 more code more code
 @
./pre.
...NO, I cannot do that without conditional tangling
...or - do it in the target language using a "lazy and" for conditionals:
(and (debug_assert_flag) (block .....with some code.....))

.b. Well, this is what I can do: ./b.
.pre.
< < main code chunk > > =
if ($DEBUG) {
< < pre-chunk assertions and if-checks > >
} # fi DEBUG

# main chunk code goes here

if ($DEBUG) {
< < post-chunk assertions and if-checks >>
} # fi DEBUG
#end of chunk here @
./pre.

Then I'll be able to produce debug code by tangling:
.pre. notangle -R"some root" project.weave ./pre.
and the "clean code" without assertion checks I'll get from it
by simply filtering with
.pre. perl -ne 'print unless m!^if ($DEBUG) {! .. m!^\} # fi DEBUG!' tangled.code \
> clean.distribution.code ./pre.

Should be easy enough ;))

}}}5

#-------------------------------------------
{{{5 .h5. Editor highlighting, Perl POD and Literate Markup ./h5.
#-------------------------------------------

The editor highlighting and literate marks  - is .i. bullshit ./i.
The way I danced around it in Molly is half-insane.

.b. SO: the solution might be ./b. to configure POD marks as 
alternative literate markup boundaries, and/or filter the shit
substituting for the real ones in the "pass-through tangler".
Will be Ok at least for quick development, won't it?

The namess of the POD sections are the names of literate chunks, then.

I coould try "=pod Name of the Chunk"
as simple PODs stand for nothing

	(a) need empty lines around all POD markers
	(b) =pod is ignored unless there is a =meaningful_mark
	before
	(c) =pod SOME TEXT -- text is ignored

So, I could use it, it seems? OR: is there any sense in that??

}}}5

}}}4


#----------------
{{{4 .h4.Done ./h4.
#----------------


#-------------------------------------------
{{{5 .h5. for Tangling ./h5.
#-------------------------------------------

1. command-line options (for weaver, too?) to imitate "noweb" (?)
Options: 
    .ul. -to show all roots??
    - mark refline nums and offsets of the Lit Source in the tangled code
    - root to tangle 
    - keep docs in comments (and/or Pod sections?? ./ul.

2. ability   to tangle over several file. I.e.
    .ul. I grow my LitSource for a while, then split it almost
    mechanically, not making splinters self-contained
    I then supply all splinter file names to "MOLLY.pl my.project-*.weave"
    and it tangles them out, however my prog is going through the splinters.
    ./ul.

3. 


}}}4


#----------------
{{{4 .h4.Todo -  current./h4.
#----------------

.b.1. Problem of double diamonds in doc chunks ./b.
.ul.
    .s. change the pass-through tangler to isolate the "notangle" from docs sections???
    (will squash the prob of double angle brackets in documentation chunks)

    OR - introduce a sort of escape?? Because sol 1 would clobber correct line numbering??
    But I do not number lines in the default pass-through invocation..
    The standalone will be affected, anyway.

    I could add regex conversion to hexadecimals in the pass-through tangler.
    However it would still break the "notangle" when run standalone. ./s. -- DONE

    I could collect command-line options in case of "scriptname.tangle" invocation
    and pass them to "notangle" - that could be a sort of solution.
./ul.

2. .s. Change logic of "weave-tangle" ("main despatcher"), as it is stupidly convoluted 
and ugly now ./s. -- DONE

3 and 8. (++) .s. rawHTML mode ./s. -- done

4. (++-) see below in "done"

5. .s. .b. BUG of sorts ./b.
the "lt" and "gt" escapes in the code chunks right above ("tangle me with filtering") are not 
displayed correctly  by the web weaver: the browser displays them as real angle brackets. ./s. 
-- DONE

6. .s.HTMLize the error message in the main despatcher (if "I am a module", print it as
an html file). Otherwise it won't look good in the browser. ./s. 
.b. NOT NEEDED ./b. as "tangling" is done from CL only

9 (++). DATA or ---start of script-- to filter?? - done

10. Add "expand subthread" ?? - to open only the current branch of the L.T.File?

11. .s. Add auto-href creation (i.e. posting a URL with minimal markup must create a valid
    HTML link with URL as the name of it. ./s. -- done

12 (+--). and checking 
.s. qwer qwer .x.spacing./x. of one word and .i..x.of  many  on  the  same line./x../i. asdf asd  
SO: to do word boundaries properly. ./s.
DONE although not very cleanly. The tag will break across several lines

13. Add a full set of HTML escapes to "dotHTML" and "rawHTML" ?




}}}4

}}}3



#-------------------------------------------------------------------
{{{3 .h3. PRELIMINARIES: The script layout and idea ./h3.
#-----------------------------------------

.. are very simple.

.b.1. ./b. It is possible to include an invocation of a  perl script with 
.pre. "do script.pl" or "use script.pl"  ./pre.
as the first lines in a Literate Source file.  This turns the source into a standalone perl script. 
If we write the script to process the L.Source file itself ($0 in perl parlance) then the script can do 
weaving and tangling of it. The output, which is formatted documentation (which was "weaved" from L.P.) 
or the sources usable by a computer ("tangled") can be  saved in a file, as with traditional literate 
programming tools. But which is more convenient, the formatted documentation on STDOUT can 
be  picked up by a web  server.  We'll see formatted representation of work in progress immediately
upon reload of the page in a web browser. 

When I think, I prefer to look at the formatted document, and when I edit, I do it "locally" in a good
programming editor (such as "vim"). Even with vim folding the difference in perception is enormous.

.b. 2. ./b.I see three advantages to such an arrangement:  
.ul..li.first, web markup is ubiquitous today, and it is quite sufficient for most publishing needs. 
So Literate Programming with HTML will free us from a tie to TeX which so negatively affected 
perception of L.P. by the masses of programmers. The markup becomes very, very simple. 

This eliminates a source of one major complaint about the traditional L.P. - that the programmer
has to maintain not one, but two "programming languages" while working with LP, the target one
and the formatting one. This - the complaint goes - becomes a source of errors from an additional
layer of programming in addition to writing the code itself. It taxes the programmer's mind rather
than relieving it.

In fact, simple HTML is almost self-correcting, as wrong markup becomes immediately obvious
in the browser. 

./li. .li. secondly, this eliminates "weaving" as a separate step during development, but more
importantly, such an arrangement allows a programmer to think about his program while looking
at a .i.folding./i. document, in which only relevant sections are open.

I perceive .i. folding ./i. as a major advantage

With .i.folding./i. the Literate Source file becomes manageable even for really large texts. 
This in turn allows the programmer to keep .i. many files ./i. inside the LPSource, including
test snippets, the makefile, preserve old versions of parts of the source etc. etc.
Literate Source file is painlessely turned into a Project File, one file, from which anything
can be easily generated.
It is this one file that my version control system must track now. For really large projects,
we can keep a meta-file (also in the folding format) with largish partial files as links,
corresponding to logical pieces of the project, which will open in the browser as automatically
weaved Literate Source Files.

I attempted to explain this at length in introductory sections above.
./li../ul.

.b.3. ./b. How the script works overall

After figuring out how it was invoked, the script:
.ul..li. .b.when it is supposed to weave./b., scans into memory the Literate Source 
file, marked up in "noweb" notation (and its document sections marked with raw HTML 
or in "dotHTML") doing necessary substitutions and conversions along the way.
Then the buffered string thus formed and several auxilliary buffers (for document TOC 
and Index sections) are printed out to STDOUT. They can be redirected into files, if 
LPSource, now also an executable script itself, is run from command line, or they can 
be picked up by a local personal web server that is used by the developer, which  should 
recognize the LPSource as a valid CGI script

After any changes in the script, the user can reload the page in his web browser and 
immediately see the changes.

./li..li. .b.If invoked to tangle./b. the source of the program, this version of the 
script will either use the built-in tangler, or refer the actual tangling to the 
"notangle" utility from "noweb" suite of  tools by Ramsey, depending on configuration 
at the top of your litsource file

The built-in tangler does not scan the file into memory. Rather, it does a first pass over
the file noting the offsets where code chunks start, end or get referred to.
The second pass then recursively prints them to STDOUT.
./li../ul.
.b.5. ./b. .x. A future version ./x. of the script may be made completely self-contained, i.e. 
include a mini-web server as well as a folding weaver and a tangler.

}}}3


.h3. ./h3.

#------------------------------------------------------
{{{3 .h3. MOLLY.pl - top of the script ./h3.
#------------------------------------------------------

<<MOLLY.pl module>>=
#!/usr/bin/perl

#---------------------------------------------------------------------------------    
#
#	This script is licensed under GPL version 3
#
#----------------------Script proper----------------------------------------------


<<general settings>>
<<main despatcher>>
<<tangle me>>
<<weave me>>

# just in case:
close LITSOURCE;
exit;

# END OF SCRIPT

@


#-------------------------------
{{{4 .h4. general settings ./h4.
#-------------------------------


Some internal script parameters are set here.
E.g. "noweb" tangler gets confused if it finds double angle brackets
anywhere, so sometimes it's possible to fool it by setting a var in the
perl script like this:

<<general settings>>=
  # need to fool the noweb "notangle" utility, switch markup modes etc.
  $lt = "<";
  $gt = ">";
  $lt_esc = "&lt;";
  $gt_esc = "&gt;";
  $dash = "-";
  $dot = "\.";
@

But more importantly:
There are a number of parameters that can be set from the literate source file
at the very top before loading the module with "do MOLLY.pl" (or "use MOLLY.pl").
These are assigned defaults here. You can refer to this portion of the script
to find out what parameters are settable in your document template and expand the
tunings if you modify MOLLY.pl

<<general settings>>=

  # ----- GENERAL settings -----
  
  # am I a module? 1:0
  $i_am_module = 1;

  # print toc? 1:0
  $print_toc = 1 unless defined $print_toc;
    
  # keep TOC expanded on initial load? "block":"none"
  $toc_expanded = $toc_expanded || "block";

  # keep TOC expanded in initial load? "block":"none"
  $ind_expanded = $ind_expanded || "none";
@

The script will behave differently depending on its own name. One "major" name
can be used with others existing as soft links (although an "thttpd" lightweight
web server insisted on a hard link in one case).
The modes are detected by file extensions, which are set here.
'Weaving' = creating a formatted HTML documentation file on STDOUT
'Tangling' = creating the program/script source on STDOUT

<<general settings>>=
  # what is the file extention to weave it? (perms must allow execution!)
  # e.g. "scriptname.weave" or "scriptname.cgi" etc.
  $weave_extension = $weave_extension || "weave";	# default is "weave"

    # what is the file extention to tangle it? (perms must allow execution!)
    # e.g. "scriptname.tangle",  "scriptname.pl" etc.
    $tangle_extension = $tangle_extension || "tangle";	# default is "tangle"


    #When tangling, should I use the built-in tangler? 0:1
    # (if 0, the "pass-through" tangling will call "notangle"
    # from Ramsey's "noweb" tools, must be installed and in your path)
    # use_builtin_tangler = 0; # default for now is to use external "notangle"
    $use_builtin_tangler = $use_builtin_tangler || 0; 

    # Actually, let's always do it and disallow unsetting
    # number lines ? 1 : else
    $line_numbering = 1;

@

The document sections ("chunks") can be marked with actual HTML tags ("rawHTML") or
with a smaller number of the same tags in "dots" in place of "angle brackets", i.e.
dot-br-dot, not open.angle-br-closing.angle
This is selected here:

<<general settings>>=
    # how are doc sections marked? "dotHTML":"rawHTML"
    $weave_markup = $weave_markup || "rawHTML"; # default is "rawHTML"

    if ($weave_markup eq "dotHTML") {
	$tag_open_symbol = $dot;	# this will take care of default
	$tag_close_symbol = $dot;	# when no var is set in the Lit Src file
    }
    elsif ($weave_markup eq "rawHTML") { 
	$tag_open_symbol = $lt;
	$tag_close_symbol = $gt;
    } #fi

@


Do we need to enable MathML functionality? If "yes", set the path to the js library
"ASCIIMathML.js" and enable the switch.
This slows down interpretation of the file on reload drastically (from nothing to
3 seconds with 4-5 example formulas), so for sfw development usually this should be off.

<<general settings>>=

    # enable MathML interpretation? 1 : 0
    $enable_ASCIIMathML = $enable_ASCIIMathML || 0;
    # If enabled, set the path; default is local in current dir
    $path_to_ASCIIMathML = $path_to_ASCIIMathML || "ASCIIMathML_with_modified_escapes.js";

@


It would make sense to add a few more markups to the program, i.e. some "wiki" many use,
and some TeX basic tags for automatic translation, if the doc is tagged as a TeX file.

In more detail dotHTML is explained in its own section

}}}4



#-------------------------------
{{{4 .h4. main despatcher ./h4.
#-------------------------------

The script figures out how it was invoked and then starts either a tangler
or a weaver, or fails with a usage line.

If the script name ends in "weave" (e.g. script.weave), it will be weaved to STDOUT.
If the name ends in "tangle", the source starting from the default chunk < <*> >
(without spaces) will be dumped to STDOUT:

<<main despatcher>>=
<<main despatcher with CL>>
@

There later may be other versions of despatchers to take care of command-line invocations
of Molly etc.

#-------------------------------------------------------------------------
{{{5 .h5. "Main despatcher with CL" ./h5.
#-------------------------------------------------------------------------

Adding command-line processing.
For now the logic is as described below in sub "usage".

More options are typed below, but they are disabled for now.
This version allows using MOLLY.pl from command line to tangle from any root
in addition to the standard "mollified" file weaving and tangling as described
in the docs.

<<main despatcher with CL>>=
  # -- MAIN DESPATCHER WITH CL----
  use Getopt::Std;

sub usage {

    print STDERR<<'end_of_usage';

    USAGE: MOLLY.pl [options] [--] filename

	-h, or no filename
		get this help message

	-R "root_chunk_name", 
		tangle starting from this chunk. if omitted, "*" is default.
		

    FOR INTERNALLY MOLLIFIED FILES:
	shortcut invocation - depending on file extension. If run as script

	"lit_prog_file.tangle" 
		tangle to STDOUT, from default root "*" only. 
	"lit_prog_file.weave" 
		weave to STDOUT as folding HTML; usable under CGI
	
	/ OR: whatever extensions are set in the lit.source configuraton /

end_of_usage

 exit;
}

    # ---
    # -1- shortcut invocations for "mollified" LitSrc file depending on its extension ---
    #

  if ( $0 =~ m!\w+\.$weave_extension$! ) { 

	open LITSOURCE, "< $0" or die "could not open the target file\n";
	goto WEAVE_ME;
    }
    elsif ( $0 =~ m!\w+\.$tangle_extension$! )  {

	open LITSOURCE, "< $0" or die "could not open the target file\n";
	goto TANGLE_ME;
  }

    # ---
    # -2- MOLLY.pl as applied to an external target file. --- 
    # check if MOLLY.pl was called from CL or under CGI, and despatch accordingly.

  else {

    if (-t STDIN) { # running on interactive TTY
	#print STDERR "$0 was called from command line..\n";

	#getopts("hwu:l:d:R:", \%cl_args);
	getopts("hR:", \%cl_args);

	# -- print USAGE if not evoked correctly
	if( (! defined $ARGV[0] ) or  ( $cl_args{h} ) ) { usage(); exit };

	# -- does target file exist?
	if ( -f $ARGV[0] ) {
	    ; # nop, a debug printout
	    #print STDERR "target file to operate on is $ARGV[0]\n";
	}
	else { 
	    print STDERR "No target file found\n";
	};


	# -- process other args for tangling an external file from CL --
	#	disabled for most of then now

	if($cl_args{d}) { 
	    #print STDERR "doc sections in coments; comment char is $cl_args{d}\n" 
	    };

	if($cl_args{l}) { 
	    #print STDERR "will add reflines; comment char is $cl_args{l}\n" 
	    };

	if($cl_args{u}) { 
	    #print STDERR "applying UN-tangling with script char is $cl_args{u}\n" 
	    };


	# -- getting the root chunk for tangling --
	#
	if($cl_args{R}) { 
	    $root_chunk = $cl_args{R};
	    print STDERR "tangling root chunk '$root_chunk'\n"
       	};


	# -- Final CL despatch, do it: --
	
	open LITSOURCE, "< $ARGV[0]" || die "could not open the file to tangle\n";

	if($cl_args{w}) { 

	    ; # nop, weaving is mangled at the moment	
	    #print STDERR "weaving from CL, got $cl_args{w}\n"; 
	    #goto WEAVE_ME;

	}
	else {
	    
	    goto SEEK_PEEK_TANGLER;

    	} # fi - CL final despatch


    exit; #redundant and unused
    }


    # -3- MOLLY.pl as a standalone script is called from CGI, nothing in here yet ---
    #
  elsif (defined $ENV{'REQUEST_METHOD'}) {

	print "Content-Type: text/html; charset=utf-8\n\n";
	print <<_XXX_;
	<html><body>
	<p>
	<b>I was caled as CGI, but this invocation seems to be meaningless.</b><br>
	Maybe you meant to "weave", but set a wrong file extension.<br>
	Goodbye.<br>
	<i>-- MOLLY.pl --</i>
	<p>
	</body></html>
_XXX_

  exit;

  }

  # -4- other cases ---
  #
  else {

	print STDERR "MOLLY.pl: I do not know how I was called, exiting anyway\n";
	exit;

    }

  exit;

  } # fi, end of despatcher

exit;  
  
@



}}}5

#-------------------------------------------------------------------------
{{{5 .h5. "Main despatcher simple" ./h5.
#-------------------------------------------------------------------------


This one is for "mollified" file processing only; no use of MOLLY.pl as
a standalone script on external files will be possible.
For that enable the "main despatcher with CL" chunk.

.b. Note ./b. Now that I'm redoing target file opening there, this despatcher
needs to be adjusted too, or it will break (open $0 as LITSOURCE here)

<<main despatcher simple>>=
  # -- MAIN DESPATCHER ----

  # check if $i_am_module and set filenames to $0 - or 
  # process CL options otherwise

  # (temp) - 2 options, to weave and to tangle in module mode:
  #
  if ( $0 =~ m!\w+\.$weave_extension$! ) { goto WEAVE_ME }
  elsif ( $0 =~ m!\w+\.$tangle_extension$! )  {goto TANGLE_ME}
  else {
  print <<end_of_print;

	USAGE:
	Not set to tangle (wrong file extension).
	Set config variables at the top of the script.  

end_of_print

exit;
  }

@

}}}5

}}}4

}}}3


.h3. ./h3.

#---------------------------------
{{{3 .h3. TANGLER ./h3.
#---------------------------------

#---------------------------------
{{{4 .h4. Notes on; difference btw built-in and "notangle" ./h4.
#---------------------------------



    This version of the script includes a built-in tangler. However if you set
    "$use_builtin_tangler" to 0 in the settings, the script will pass ithe request 
    through to the "notangle" utility of the "noweb" Literate Programming tool 
    to tangle starting with .i.the default chunk < <*> >./i.   and without other 
    options passed. I only set "notangle" below to preserve the tabs in case you 
    are tangling Makefiles.

    If you set $use_builtin_tangler to 1, the "seek-peek" tangler will be used.
    It does not clobber tabs at all, so tangling out Makefiles is possible.
    It does not choke on double < < in text chunks, either.

    It is:
   .ul. .li. not so much tested (but seem to handle example from "noweb" distribution
    after those have been brought to "canonical form", i.e. .b. all code chunks
    end with "@", no exceptions ./b. 
    ./li. .li. can handle multiple refs on the same line surrounded by other text,
    ./li. .li. and tangles only the default chunk "*" (again, for now),  
    ./li. ./ul.
    so you might want to use the Ramsey's tool, at least to check the output.
    Norman Ramsey's "noweb" has been around for more than 10 years and been used
    on thousands of lines of other projects.
    You will also have to run "notangle" for getting non-default-root ("*") chunks
    until I have supplied command line processing.

	.ul. .b.  1. Note./b. that for .b. "notangle" ./b. you have   to make sure your 
	double angle brackets are broken by spaces "< <"  or with actual escapes 
	"<\<" even in doc chunks (and escape them in your code, too. "Notangle" 
	reacts to them NOT only at the beginning of the line, as my tangler does, 
	but everywhere and chokes if finds them.

	.b. 2.  Note./b. that the built-in tangler ./b. uses "noweb" markup, but it is 
	.i. more restrictive ./i. in one sense: .b. all code chunks MUST end with "@"./b. 
	    .pre.< <name of chunk> >=
	    ......
	    @ ./pre.
	Norman Ramsey's convention was: .i. you are allowed not to close the code chunk
	with "@" if the next code chunk is coming right after it ./i.
	./ul.


    So, when the script is invoked as "script.tangle" (which can be a link or a soft
    link to something like "script.weave", it's "real" name), it will dump the source
    to STDOUT, very convenient for development.

    I usually move the root chunk < <*> > along inside the LIterate Source project
    file and assign it to the test script or the part I am working on. The Literate Source
    project file includes several actual source files usually. By the way, it's quite
    nice to be able to keep all partial tests that you do before including those into
    the target program all in one place, your common project file.

    To tangle with more specific options, run "notangle" directly on your "mollified"
    literate source file, e.g.
    .pre.notangle -R my_root_chunk -L script.weave ./pre.

    Later other modes of operation may be incorporated here.

}}}4


#---------------------------------------
{{{4 .h4. Code: run pass-through or built-in tangler ./h4.
#---------------------------------------

    Passes the request to "notangle" from the "noweb" literate tools suite -
    OR starts the built-in tangler chunks.

    1. Pre-filtering needs to be done. E.g. "notangle" gets confused by double angle 
    brackets even when those are inside the document chunks.
    Therefore I will simply cut out document chunks altogether and not pass them to the
    tangler.

    Test line (delete spaces to test): < < get it, choke on this, bastard > >
    < < or this> >=
	or even this
    @


<<tangle me>>=

TANGLE_ME:

#open LITSOURCE, "<$0";

  if ( $use_builtin_tangler ) {

    <<seek-peek tangler>>

  } 
  else { # pass to "notangle" from "noweb" tools by Ramsey

    open TANGLE_PIPE, "| notangle -t4 -";

    while  (<LITSOURCE>) {

	    if ( m!^<\<(.*)>\>=! ... m!^@\s*$! ) { # -- CODE CHUNKS ONLY -- 
		print TANGLE_PIPE $_;
	    }

    } # elihw

    close TANGLE_PIPE;

  } #; esle, pass-through clause end

close LITSOURCE;
 exit;

@

    .b. Speculative: Immediate execution of the script ? Do I need it?  ./b.
    It did not work exactly, but then I did not try it for real -- if it is needed and if your
    language supports taking input from STDIN, it may be possible also to immediately run your
    script skipping the stage of "tangling-into-a-file" before running.
    To be added (possibly).

}}}4


#------------------------------------------------------
{{{4 .h4. seek-peek tangler (working) ./h4.
#------------------------------------------------------

#------------------------------------------------------
{{{5 .h5. Advantages, limitations; escapes; the algorithm ./h5.
#------------------------------------------------------

.b. Advantages, limitations and escapes ./b.

(a) .s. The first version can only take care of one litprog chunk reference per line, and
this ref cannot be surrounded by other text. ./s.
Built-in tangler can handle multiple references per line surrounded by other text

(b) However it does not clobber tabs, so you can tangle out Makefiles with it.

(c) Built-in tangler insists on ending every code block with an explicit "@"
("notangle" allows to drop them if the next chunk is code, too)

(d) "notangle" by Ramsey is confused by < <  even inside documentation chunk, in any position.
My default "pass-through" tangler filters those out and treats as "real" only the dbl-angle
bracketed stuff .i. in the first position in its line ./i.

This 'seek-peek' tangler also filters out all of documentation chunks and looks only for 
.b. dbl angles and the @ sign in the first position of the line ./b.

(e) The used regexps ensure that if you have both opening and closing double brackets
somewhere in your code, the S-P tangler will get screwed.
This and the first-positioned symbols are the only escapes one needs to observe as
far as I understand.

(f) The S-P tangler only reads files on disk, two times actually. So for now at least
you cannot pipe into it. (It works roughly 3 times faster though and can potentially
work across several litsource files (not implemented yet))

.b.The idea/algorithm is to:./b.

(a) run a first pass over the file collecting a list of 
	chunk offsets, or "addresses"

(b) run a second pass recursively, already knowing where to read the
	bits and pieces from . That's all there is to "tangling".
	
(c) Filters could apply to some chunks for:
	/weaving/
	* feeding the text to a markdown lang
	* cutting sth out for a math processor 
		(e.g. mimeTeX, or to ASCIIMathML.js)
	/tangling/
	* for conditional tangling of certain chunks
	(e.g. those whose names start with DEBUG, negative
	or the opposint, CLEAN, for a positive filtering)
/none of the above are used now/	

This type of tangler will not be able to get input via pipes,
but - it should be fine working across .b.several literate source
files./b., the only requirement is that their chunk namespace should be
flat (unique names across your whole project). 
It can be managed by prepending the chunk names by their file IDs, for
example.
/* command line option to get several files and their processing by the 
script are not implemented yet */


#-----------------
{{{6<h6>Makefile for s.-p. tangler tests</h6>
#-----------------

a small informal test for now; to be expanded to:
    - "make" --> "help"
    - "make target" -> for tests, tangling out parts of the project etc



<<seek-peek tangler Makefile>>=

all: tangle  perl-check run compare
#-

tangle:
	./zz-seek-peek.tangle > zz.pl;
#-

perl-check:
	perl -c zz.pl;
#-


run:
	perl zz.pl zyy-test.litsource.txt >test.out;
#-	

compare:
		fldiff zyy-test.litsource.txt test.out;
#-

 
@


}}}6

#-----------------
{{{6 <h6>todo</h6>
#-----------------
.s. Now, the next step is to fix the trailing line with @

.i. HOW: ./i.
I'll "tell" on each line and use as my end-of-splinter address
the one from the previous line (i.e. just before the last line, 
which contains the trailing rubbish).  ./s. -- DONE

.s. NEXT is many chunk refs on teh same line surrounded by other text/code ./s.
--done--

NEXT is command-line processing for tangling any given root

NEXT is adding comments with line nums and offsets in teh original Lit Source
into the tangled out code

NEXT is "un-tangling", i.e. reimporting code, changed during testing back into
LitSource (? possibly)

NEXT possibly - processing over several files, which are mechanical splinters
of the same Literate Project

}}}6

}}}5

#-----------------
{{{5 <h5>The code</h5>
#-----------------

<<seek-peek tangler>>=

SEEK_PEEK_TANGLER:

	<<pass 1>>
	<<pass 2 and print>>
	<<main: call the sub>>

close LITSOURCE;
exit;

@

"pass 1" "goes through the file collecting addresses.

Then "pass 2" sets a recursive sub to "untangle" the chunks with
their included references.

The "main" sets the root chunk and calls the sub

I'll ' add command-line and CGI arguments processing later.

<<main: call the sub>>=

	#~ $root_chunk = "chunk 1";
	#~ $root_chunk = "DEBUG print one reference";
	$root_chunk = $root_chunk || "*";

	print_chunk($root_chunk, 0, 1); 

@


#------------------
{{{6 <h6> PAss 1 </h6>
#-------------------

declare and initialize some vars

<<pass 1>>=

	<<declarations and initializations>>
	<<while-loop and peek file ofsets>>

@

<<declarations and initializations>>=

    my $chunk_beg_pattern = q(^<\<(.*)>\>=);
    my $chunk_end_pattern = q(^@\s.*$);
    my $chunk_ref_pattern = q(<\<(.*?)>\>[^=]); # can be used several times in a line

    my $current_chunk_name = "";
	my $current_chunk_start_foff = ""; # "foff" is a "file offset"
	my %file_offsets_hash = ();
	my %left_margin_hash = ();

    my $line_num = 0;
	my $previous_line_foff = 0; # "foff" is a "file offset"

@


.b.Main loop./b.
Need to collect chunk addresses (with "tell"), and keep .i. a hash of lists./i.
with addresses of all chunk continuations (if any)
    .pre. (beg_offset, end_offset) ./pre.

I'll need to push them in, and in pass 2 I'll iterate over them, 
and so ensure all of a split chunk is read.

.b.Anyway,./b. to deal with references to chunks from inside chunks I 
will insert ("ref", "referred_chunk_name", left_indentation) into my 
    .pre.%file_offsets_hash ./pre.
during the first pass. This pair is different from numeric beg-end offset pairs,
and I'll start a recursive printout of the chunk referred to when I detect it.

I'll need to keep "left margin", the indent for the reference as a next value
in the list/array, so it is
    .ul..li.pairs (beg_chunk_offset, end_chunk_offset) for regular chunks
    ./li..li. and a triple ("ref", name_of_referred_chnk, its_left_indent) for refs
    ./li../ul.

I might need to keep more information (e.g. "line numbers in the Literate Source),
then those become quadruples and quintil.. whatever ;)


#------------------
{{{7 <h7> Ref: perl operators </h7>
#-------------------

.b.---Perl operators----./b.
	
.b.pos./b.

.ul.
3253   while ( $string =~ m!\G(.*?)<\<(.*?)>\>!gs) {
3254     
3255     $off = length($2);
3256     $position = pos($string);
3257     #pos($string) = $position + $off;
3258     print "\n\t---title---\n$2 of length $off at $position \n\t----after----\n$1\n========\n";
3259   
3260   }
./ul.

.b.tell filehandle./b. (if omitted, the last file read)
		
.b.seek FILEHANDLE,POSITION,WHENCE ./b.
Sets FILEHANDLE's position, just like the fseek call of stdio . 
FILEHANDLE may be an expression whose value gives the name of the filehandle. 
The values for WHENCE are 0 to set the new position in bytes to POSITION,
	
.b.read FROM_FILEHANDLE, IN_SCALAR_BUFER_VAR_OR_STREM, LENGTH_IN_BYTES_OR_CHARS./b.
There .b.may be problems./b. if FH is opened in non-bytes mode, or if some pragma is used

-------------------

}}}7

}}}6

#------------------
{{{6 <h6> Pass 1: main while-loop and foffs</h6>
#-------------------


.i. A loop over the doc starts here ./i.
Process inside doc sections:

<<while-loop and peek file ofsets>>=

 while (<LITSOURCE>) {
    $line_num++;

	# --- CODE CHUNKS -- not inside documentation section
    if ( m!$chunk_beg_pattern! .. m!$chunk_end_pattern! ) {

	<<chunk beginning>>
	<<chunk ending>>
	<<chunk reference>>
	<<chunk body>>


    } #fi

	$previous_line_foff = tell LITSOURCE;

  } #eliwh

@

.b.A later adjustement, actually to rid of the last line trash./b.
    "tell" gives addr .i. at the end of the matched line./i. So,
    I'll have to use .i. offset from the previous match./i. to
    rid of the current line rubbish - this is what the last
    var assignement in the loop is about.


.b.First, the chunk body./b. 
It closes the "if" opened in "chunk beginning", The rest of then are
"elsif" clauses. 

There's nothing to do here in pass 1; just here not to leave it
implicit and hidden

<<chunk body>>=

    else { # chunk body

	; # nop; here just not to hide an implicit case
	#~ print "."; # debug: show dots for lines 
    }

@


.b.Next, match for a first line of a new chunk./b. (which can continue
some previous splinters of the same chunk in the LitSource file)

If a chunk begins (or continues) here, 
	- set the current chunk name
	-pick up its "peeked" offset in  the file 
	- and push it in the hash of f_offs under the current chunk name

Hmm.. The perl "tell" gives the position after the read line, I understand.
No adjustment is needed for the beginning chunk match, and it'll eliminate
the title from the later output.

<<chunk beginning>>=

    if ( $_ =~ m!$chunk_beg_pattern! ) {
	$current_chunk_name = $1;
	$current_chunk_start_foff = tell LITSOURCE;

	push @{$file_offsets_hash{$current_chunk_name}}, $current_chunk_start_foff;
	#~ print "[***debug: I am chunk $1 -- I start at $current_chunk_start_foff***]\n";
	#~ print "----> chunk $1 line $. offset $current_chunk_start_foff\n";

    }

@


.b.If a chunk ends,./b. peek its end offset in the file ("f_off") Actually, not to pick
up the closing "at" signs, get the previous line's told offset.

.. and push it in the hash of lists
Plus - set $current_chunk_name=""; # just in case

<<chunk ending>>=

    elsif ( $_ =~ m!$chunk_end_pattern! )  {

	$current_chunk_end_foff = $previous_line_foff;
	push @{$file_offsets_hash{$current_chunk_name}}, $current_chunk_end_foff;
	#~ print "[+++debug: $current_chunk_name ends at off $current_chunk_end_foff++++]\n\n";
	#~ print "\tline $. offset $current_chunk_end_foff<------\n";

    	$current_chunk_name = "";
    }

@

.b.Ok, so we put the foffs  in the (beg, end) order./b..
Now, "pop" will get them in the pop1 -> (end), then pop2 -> beg order
While  shift_first -> beg, shift_second -> end. This will be the right one
for later tangling.


.b.Now, the chunk refs ./b.

If we get a reference, regex-split the line 
	- set the end offset of the current chunk
	- push it in the hash of lists
	- figure the offset after the chunk ref
	- push it into the hash of lists using the current chunkname
	- IMPORTANT COMPLICATION
		deal with the case when several chunk refs on the same
		line are present;
		do .i.not./i. do it for the first version of the script.

for many matches on a line - 
Here we'll have to match with continuation and repeat matching in a loop until the line 
with matches is exhausted.

<<chunk reference>>=
    <<chunk reference - multiref inside other text>>
@

}}}6

#------------------
{{{6 .h6. multiple refs on the same line./h6.
#-------------------


.b. Multiple references on the same line surrounded by other text./b.

First, I'll need to change the regexp pattern:
mm.. I probably needn't. I'll get to it on a normal regexp, and use the
multiref regexp only within
The "chunk_ref_pattern" is set to q(<\<(.*?)>\>[^=])

So, if I got (one, first) reference using a normal regex,
start iterating on this line using a multi-match regex.
'The rest of the line' can be got right after the while{} loop.
I'll need to subtract
.s."told offset" - "line length" + "pos-given offset"../s.
I have $previous_line_foff

.i. NOTE: "pos" does not work intuitively, so I do not use it below ./i.

I'll write out logic later, after I have tested and adjusted it enough

<<chunk reference - multiref inside other text>>=

 elsif ( $_ =~ m!$chunk_ref_pattern!g ) {

    my $line = $_;
    my $current_foff_pos =  $previous_line_foff;
    my $initial_margin = 0;
	my $homegrown_pos = 0;

    while ($line =~ m!(.*?)<\<(.*?)>\>!g) {

	# "end" of prev pair
	push @{$file_offsets_hash{$current_chunk_name}}, 
	    $current_foff_pos + (length $1); 

	#-------deal with pushing ("ref", "chunkname") pair -----
	# special id string for refs
	push @{$file_offsets_hash{$current_chunk_name}}, "ref";
	# name of reference
	push @{$file_offsets_hash{$current_chunk_name}}, $2; 

	# -- next a special entry for refs: (left_margin)
	$initial_margin += (length $1);
	push @{$file_offsets_hash{$current_chunk_name}}, $initial_margin; 

	my $homegrown_pos = (length $1) + (length $2) + 2*(length "<>");
	my $end_of_match_pos = $current_foff_pos + $homegrown_pos;

	# "start" a new pair.. - ok, let's not use "pos" at all, if it fails
	push @{$file_offsets_hash{$current_chunk_name}}, $end_of_match_pos;

	#  I'll need to reset current_foff_pos to the pos
	#   (or to the directly caclucalted offset, if I prefer that):
	$current_foff_pos = $end_of_match_pos; 
	$initial_margin += (length $2) + 2*( length "<>"); 	

    } # elihw

    # This is where chunk refs get an extra newline ?

 } # fisle

@

 .b.This works../b.

  Handles Ramsey's test progs .b.when those are cleaned of an annoying
 irregularity in his notation./b., i.e. when .b.all./b. prog chunks start
 with title in dbl brackets and end with an "at" (exactly in the first
 position on the line)

.b. aligning printout./b.
Need to save left margin (here) and apply it in the sub print_chunk below


#-----------------------------
{{{7 <h7> first test: how to iterate over regex, using pos</h7>
#-----------------------------


This is a snippet showing how it can be treated:

.pre.

#~ Nope, they use it inside "while" 
#~ OK, this is how it will work in the script:
#~ /the while loop is over the line that contained at least 
#~ one ref; the loop body includes pushes into the hash/

	$line = "asdfas asd <<qewrqw>> opiopiopi <<2345>> asdasdf";
	$llen = length $line;
	print "the original line:: [$line] -- of length $llen\n";


	while ($line =~ m!(.*?)<<(.*?)>>!g) {
		print "$1 -- $2\n";
		$ancor_off  = pos $line;

		print "ancor position is $ancor_off\n";
	}

	print "THE LAST PART IS  ", (substr $line, $ancor_off), "\n";

./pre.

And this is its output:

.pre.
the original line:: [asdfas asd <<qewrqw>> opiopiopi <<2345>> asdasdf] -- of length 48
asdfas asd  -- qewrqw
ancor position is 21
 opiopiopi  -- 2345
ancor position is 40
THE LAST PART IS   asdasdf
./pre.

}}}7

}}}6

#---------------------
{{{6 <h6> pass 2 and print </h6>
#---------------------

OK, now we have a hash of pairs (beg_chunk_offset, end_chunk_offset) with triples 
("ref", "ref_chunkname", left_indent) interspersed where there were references included.
    - start from the given root
    - iterate over subchunks of a given chunk - beg_f_off, end_f_off
    - print out the file verbatim
    ...
      IF there WAS a ref, RECURSE on the new chunk name

That should be it

<<pass 2 and print>>=
	<<sub: tangle recursively - nondestructive>>
@


Now - the RECURSIVE PRINTOUT untangling from the default/given root.
--seek, then "read" into some $buf, which then is printed--

    (a) if the pair got from the hash of lists is digits, print out 
    (b) if the first is a specia string "ref", get the ref name from
    the second item in the pair and go there recursively


<<sub: tangle recursively - nondestructive>>=

# USAGE: print_chunk(name_of_chunk, left_margin, print_newline_flag)

 sub print_chunk {

 (my $chunk_being_printed,
    my $snippet_left_margin, 
	  my $snippet_print_newline_flag, @rest) = @_; 


 #~ print "\n---- printing chunk $chunk_being_printed --------\n";
 #~ print "DEBUG: got left.m. $snippet_left_margin nl. flag $snippet_print_newline_flag \n";

 # -- error mess. not to fail silently --
 unless ( defined $file_offsets_hash{$chunk_being_printed} ) {
    #print STDOUT "\t\nERROR: chunk $chunk_being_printed not found in file $ARGV[0]\n";
    print STDERR "\n\tERROR: chunk $chunk_being_printed not found in file $ARGV[0]\n\n";
 }


 # iterate over splinters of a chunk, which are foff pairs
 for ( my $iterate_foffs = 0;
	    exists $file_offsets_hash{$chunk_being_printed}[$iterate_foffs];)
 {

    my $snippet_position =  $file_offsets_hash{$chunk_being_printed}[$iterate_foffs++];
    my $snippet_end = $file_offsets_hash{$chunk_being_printed}[$iterate_foffs++];
    #~ print "debug got: beg $snippet_position -- end $snippet_end\n";

    <<the meat>>

 } # rof non-destructive
	
     return 1;
    } # bus -- ends the recursive sub

@

ok, if we got a chunk ref in our array of pairs, then the next entry after it is 
	(left_margin) 
(that is my nano-protocol here ;)  ). I use these numbers to keep the 
"printer state" before recursively calling this function for the referred 
chunk.

<<the meat>>=

    if ($snippet_position eq "ref") {

	my $snippet_left_margin_ref = 
    	    $file_offsets_hash{$chunk_being_printed}[$iterate_foffs++];
	#~ print "DEBUG: got a ref $snippet_end here -- nl flag $snippet_print_newline_flag_ref\n";

	# any call to a ref uncurs "print newline" flag of 0
	print_chunk($snippet_end, $snippet_left_margin_ref, 0);
    
    }
@

if the next data you got from your list is pairs of offsets (beg, end), 
print them out, observing (a) left margine this chunk is at, and
(b) skipping newlines after a chunk (could be an in-lined ref) unless 
this chunk is last in the referring line.

For that I'll have to keep "a printer state" wth two flags for (a) and (b).

<<the meat>>=
    else { # .. print it here
	seek LITSOURCE, $snippet_position,  0;
	read LITSOURCE, $buffer_out, ($snippet_end - $snippet_position);

	#----Newlines at the end of chunks and refs. 
	# only for the last splinter of a chunk, do newline control:
	if ( ((scalar @{$file_offsets_hash{$chunk_being_printed}}) - $iterate_foffs ) == 0 )
	{ 
		# works, but is suspicious logically:
		# maybe I just have not invented a counterexample yet, and
		# it's a trap waiting for its quarry
		$buffer_out =~ s!\n([\s]*)$!$1! unless ($snippet_print_newline_flag);
	}

	#----Left indent/margin. Seems OK

	$chunk_left_margin = " " x $snippet_left_margin;
	$buffer_out =~ s!(\n)!$1$chunk_left_margin!sg;

	print $buffer_out;
    }

@


#---------------------
{{{7 <h7> two debug chunks</h7>
#---------------------


<<DEBUG print out full hash>>=

	for $k (keys %file_offsets_hash) {
		#~ print @{$file_offsets_hash{$k}}, "\n";

	 while (scalar @{$file_offsets_hash{$k}}){
		print "beg $k foff - ", shift @{$file_offsets_hash{$k}};
		print " -- end foff - ", shift @{$file_offsets_hash{$k}}, "\n";
		}
	}
@

<<DEBUG check hash keys>>=

 #~ for $k (keys  %file_offsets_hash){
	#~ print $k, "\n";
	#~ }

@

}}}7


}}}6

/* end of tangler part of script in the litsource file */

}}}5

}}}4

}}}3


.h3. ./h3.

#--------------------------------
{{{3 .h3. WEAVER ./h3.
#--------------------------------


The idea of the weaver is simple, again.

<<weave me>>=


WEAVE_ME:

#1. Set formatting strings for weaver
<<set formatting strings for weaver>>

#2. accumulate result in a buffer
<<accumulate result in a buffer>>

#3. print out the TOC, the Chunks Index, the output buffer and close the page.
<<print out>>

close LITSOURCE;
exit;

@


#---------------------------------------------------------------
{{{4 .h4. How formatting is done in the weaver ./h4.
#-------------------------------------------------------------

.b.1 The first formatting element ./b.  that is  part of the .i. function ./i. of the script
rather than formatting decorations is the
.pre. frameset - legend - /legend - /frameset ./pre.
which create the distinctive look of the documents generated by MOLLY. I do not wish to
change them (although strictly speaking they are not obligatory).

What can be changed is the Stylesheet (a part of the script, it has its own subsection), so
other people could play with fonts and colors and margins and such by throwing in a simple
switch and copying their alternative stylesheet into the script.

I do not wish to use external files for any configuration, as the whole idea of MOLLY is to
be a single self-contained script, which does not require any "installation" of many files to
many places.

.b.2  Secondly,./b. the "actual working test.html" subsection below probably explains best how
.b. text folding and background highlighting ./b. which is tied to it (i.e. a TOC click will open the 
section + highlight; and click on the section in the body of the doc will toggle it + highlight 
the TOC line ) work.

Actual implementation is spread between several subsections - they are
coded in in the hard way, as I do not expect them to change ever, they are a functional element
not a changeable "skin" or decoration.
.ul..li. vars, JS and styles are set in the weaver "set formatting strings for weaver" subsections;
./li..li. invocations can be seen in "accumulate the result", esp in the "section headings"
./li..li. and more are applied in the "print out the result"
./li../ul.

Some of the vars are set to pieces of formatting strings in the beginning, and later variables
in them are interpolated with "executable" regexs ( the "e" flag at the end of the regex) - see 
"process section headings"


#---------------------------------------
{{{5 .h5. actual working test.html ./h5. 
#---------------------------------------

Here's the actual script that was used to test the JS folding and
tying of folding to the TOC section highlighting:


<<test.html>>=

<html>
<head>


<style type="text/css">


.unhilited {background-color:white}
.hilited {background-color:yellow; text-decoration:underline}
</style>


<script type="text/javascript">

    function setHilite(evt) {
	evt = (evt) ? evt : ((window.event) ? window.event : null);
	if (evt) {
	    var elem = (evt.srcElement) ? evt.srcElement : evt.target;
	    elem.className = "hilited";
	}
    }


function setUnHilite(evt) {
    evt = (evt) ? evt : ((window.event) ? window.event : null);
	if (evt) {
    	    var elem = (evt.srcElement) ? evt.srcElement : evt.target;
    	    elem.className = "unhilited";
	}
}

function toggleDiv(divid) {
var el = document.getElementById(divid);
el.style.display = (el.style.display == 'block') ? 'none' : 'block';
}

function toggleCombined(divid){
    if(document.getElementById(divid).style.display == 'none'){
      document.getElementById(divid).style.display = 'block';
	document.getElementById("toc"+divid).className="hilited";
    }
    
    else{
      document.getElementById(divid).style.display = 'none';
	document.getElementById("toc"+divid).className="unhilited";
    }
}


function expandDiv(divid){
	document.getElementById("toc"+divid).className="hilited";
}



</script>
</head>

<body >
<h2>Here's the tested element</h2>
Here is some ordinary text<br>
<span class="unhilited" onmouseover="setHilite(event)" 
    onmouseout="setUnHilite(event)"> 
    <a href="javascript:;" onmousedown="toggleDiv(15);"><b> process section headings </b></a><br>
    and this is some potentially hot spot text.</span>

<div id=15>
    .. and this is the text<br>
    that should be hidden/collapsed

</div>


<h2>Here's the tested element 0</h2>
HHHHere is some ordinary text<br>
<a href="javascript:;" onmousedown="toggleCombined(13);" id="toc13">
    <b> process section headings </b></a><br>

<div id=13 ><script language=javascript> document.getElementById("toc"+13).className='hilited';</script>
    .. and this is the text<br>
    that should be hidden/collapsed

</div>




<h2>Here's the tested element 1</h2>
HHHHere is some ordinary text<br>
<a href="javascript:;" onmousedown="toggleCombined(14);" id="toc14">
    <script language=javascript> document.getElementById("toc"+14).className='hilited';</script>
    <b> process section headings </b></a><br>

<div id=14 >
    .. and this is the text<br>
    that should be hidden/collapsed

</div>


<h2>Here's the tested element 2</h2>
HHHHere is some ordinary text<br>
<span  id="toc16"> 
    <a href="javascript:;" onmousedown="toggleCombined(16);"><b> process section headings </b></a><br>
    and this is some potentially hot spot text.</span>

<div id=16>
    .. and this is the text<br>
    that should be hidden/collapsed

</div>



</body>
</html>

@

}}}5


#----------------------------------------------------------------
{{{5 .h5. changing text style - the basic JS recipy ./h5.
#-----------------------------------------------------------------

I used this snippet for a start then reworked it into the "working test script" below.

.ul. .pre.
11.8.2 Solution
First, define two style sheet rules, each with a different class selector. Then design 
an event handler for the element to change the element's className property to the desired 
class selector's identifier: 

		<style type="text/css">
		.unhilited {background-color:white}
		.hilited {background-color:yellow; text-decoration:underline}
		</style>
		...
		<script type="text/javascript">
		function setHilite(evt) {
			evt = (evt) ? evt : ((window.event) ? window.event : null);
			if (evt) {
				var elem = (evt.srcElement) ? evt.srcElement : evt.target;
				elem.className = "hilited";
			}
		}
		function setUnHilite(evt) {
			evt = (evt) ? evt : ((window.event) ? window.event : null);
			if (evt) {
				var elem = (evt.srcElement) ? evt.srcElement : evt.target;
				elem.className = "unhilited";
			}
		}
		...
		<span class="unhilited" onmouseover="setHilite(event)" 
			onmouseout="setUnHilite(event)">Some potentially hot spot text.</span>

Adjusting the className property of an element as shown here is a more stable approach 
for early versions of Netscape 6 instead of manipulating styleSheet objects and their 
properties. It is perhaps the most widely used and supported way to implement dynamic styles. 
./pre. ./ul.

If I enclose one "onmousedown" inside another, JScript will most probably not pass it into the inner one.
So I should add:
(a) the TOC line IDs ?? Like "toc.1", "toc.2" etc
(b) keep a separate func, not "toggleDiv", but something else like "toggleTOCandDIV", and run 2 things
from there ??

.b. So, 2 tests: enclosing and if not, then rewriting the collapsing JS func ./b.

}}}5

#--------------------------------------------------
 .h5. Reference - Javascript and DOM ./h5.
#--------------------------------------------------


I'll need some javascript and DOM reference for further work;

a/ http://w3schools.com/htmldom/dom_reference.asp  -- ref from W3C
b/ http://w3schools.com/htmldom/default.asp -- might also be useful
c/ http://www.howtocreate.co.uk/tutorials/javascript/domcss --javascript tutorial (not necessarily best) 
d/ http://www.pageresource.com/dhtml/ryan/part4-1.html - another tutorial


}}}4


#------------------------------------------------------------
{{{4 .h4. set formatting strings for weaver ./h4.
#------------------------------------------------------------

<<set formatting strings for weaver>>=

  #----SETTING FORMATTING STRINGS-----------
  
$html_head = <<head_end_1;  

<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" /> 

head_end_1

#switch on ASCIIMathML.js library if enabled in template options:
if ($enable_ASCIIMathML) {
$html_head .= "\n" . qq(<script type="text/javascript" src="$path_to_ASCIIMathML"></script>) . "\n";
    }

$html_head .= <<head_end;

<<JS script functions>>
<<stylesheet>>

</head>
head_end

$html_body_table = "<center><table class='outertable'><tr><td>";
$html_body_table_end = "\n</td></tr></table></center></body></html>\n";


	

$folding_section_start1_str = <<'fold_sect_start_1_xxx';
	<fieldset><legend><a href="javascript:;" onmousedown="toggleCombined('$section_num');">
fold_sect_start_1_xxx


$folding_section_start2_str = <<'fold_sect_start_2_xxx';
</a></legend></fieldset>
<p>
<div id="$section_num" style="display:$fold_state"> $highlight_state  
<ul>

fold_sect_start_2_xxx


$folding_section_end_str = <<'folding_section_end_xxx';
</ul>
<p>
<br>
<i><font size=-1>
<a href="javascript:;"onmousedown="toggleCombined('$section_num_prev');">
Close the subsection</a></font>
</i> -- <i><font size=-1>
<a href="javascript:;" onmousedown="showAll();">
expand all</a> -- 
<a href="javascript:;" onmousedown="hideAll();">
collapse all</a>
</font></i>

<p>
</div>

folding_section_end_xxx


$code_frameset_start_pre = "<pre><fieldset class='codefieldset'><legend class='codelegend'>";
$code_frameset_start_post = "=</legend>";
$code_frameset_end = "</fieldset></pre>\n";




@

#----------------------------------------
{{{5 .h5. JS functions ./h5.
#----------------------------------------

In my attempts to insert ASCIIMathML.js, I have tried some variations of
math sections markup (with "a m a t h" -- "e n d a m a t h" words and
with backquotes) -- but the stinking lib insists on garbling my file, as
sth triggers it on earlier.

So a next step is to change regexps inside the Javascript lib and forse it
to sane markups. Probably by adding ancoring the key word to the beginning
of the line and/or insisting that it is there alone.

<<JS script functions>>=

<script language="javascript">

function toggleDiv(divid) {
var el = document.getElementById(divid);
el.style.display = (el.style.display == 'block') ? 'none' : 'block';
}


function toggleCombined(divid){
    if(document.getElementById(divid).style.display == 'none'){
      document.getElementById(divid).style.display = 'block';
	document.getElementById("toc"+divid).className="hilited";
    }
    else{
      document.getElementById(divid).style.display = 'none';
	document.getElementById("toc"+divid).className="unhilited";
    }
}


function showAll(){
for(i=1; i <= 10000; i++){
    document.getElementById(i).style.display = 'block';
    document.getElementById("toc"+i).className="hilited";
    };
}

function hideAll(){
for(i=1; i <= 10000; i++){
    document.getElementById(i).style.display = 'none';
    document.getElementById("toc"+i).className="unhilited";
    };
}

</script>
@

}}}5

#--------------------------------------
{{{5 .h5. Stylesheet ./h5.
#--------------------------------------

<<stylesheet>>=
<style type="text/css" media="screen">


BODY {
	FONT-SIZE: 10pt;
	<!--FONT-FAMILY: sans-serif -->
	background: #f0f0f0;
	}
FIELDSET {
	BORDER-RIGHT: #000000 1px solid; 
	BORDER-TOP: #000000 1px solid; 
	BORDER-LEFT: #000000 1px solid; 
	BORDER-BOTTOM: #000000 1px solid; 
	PADDING-RIGHT: 5px; 
	PADDING-LEFT: 5px; 
	PADDING-BOTTOM: 2px; 
	PADDING-TOP: 5px;
	MARGIN-BOTTOM: 1px; 
	background: #f5f5f5; 
	color: #000000;
	}
LEGEND {
	BORDER-RIGHT: #a9a9a9 1px solid; 
	BORDER-BOTTOM: #a9a9a9 1px solid;
	BORDER-TOP: #a9a9a9 1px solid; 
	BORDER-LEFT: #a9a9a9 1px solid; 
	PADDING-RIGHT: 20px; 
	PADDING-LEFT: 20px; 
	PADDING-BOTTOM: 5px; 
	PADDING-TOP: 5px; 
	FONT-WEIGHT: bold;  
	BACKGROUND: #fdfdfd; 
	color: #000000;
	}
PRE	{
        PADDING-LEFT: 20px; 
        PADDING-RIGHT: 5px; 
        padding-top: 0px; 
        padding-bottom: 6px;
        MARGIN-BOTTOM: 1px; 
        BORDER-TOP: #a9a9a9 0px solid;
        BORDER-RIGHT: #a9a9a9 0px solid; 
        BORDER-LEFT: #a9a9a9 0px solid;
        BORDER-BOTTOM: #a9a9a9 0px solid;        
	background: #fefefe;
	}


.tocfieldset {
	background: #ffffff; 
	color: #000000;
	}

.codefieldset {
	BORDER-RIGHT: #000 1px solid; 
	BORDER-TOP: #000 1px solid; 
	BORDER-LEFT: #000 1px solid; 
	BORDER-BOTTOM: #000 1px solid; 
	background: #ffffff; 
	color: #000;
	MARGIN-BOTTOM: 1px; 
	PADDING-LEFT: 15px; 
	PADDING-RIGHT: 5px; 
	PADDING-BOTTOM: 10px; 
	PADDING-TOP: 1px;
	}
.codelegend {
	BORDER-RIGHT: #777 1px solid; 
	BORDER-TOP: #777 1px solid; 
	BORDER-LEFT: #777 1px solid; 
	BORDER-BOTTOM: #777 1px solid
	PADDING-RIGHT: 10px; 
	PADDING-LEFT: 10px; 
	PADDING-TOP: 2px; 
	PADDING-BOTTOM: 2px; 
	background: #ffffff; 
	color: #00b;
	FONT-WEIGHT: bold;  
	/font-variant: small-caps;
	/font-style: italic;
	}



.chunkref {
        color: #00b;	
        background: #f6f6f6;
        /font-style: italic;
        font-weight: bold;
        /font-variant: small-caps;
	}


.outertable {
	width: 99%; 
	cellpadding: 25; 
	background: #ffffff; 
	border: 1px solid;
	}

.hl	{
	 ;
        PADDING-LEFT: 5px; PADDING-RIGHT: 5px; 
        padding-top: 5px; padding-bottom: 5px;
        MARGIN-BOTTOM: 1px; 
        BORDER-TOP: #a9a9a9 0px solid;
        BORDER-RIGHT: #a9a9a9 0px solid; 
        BORDER-LEFT: #a9a9a9 0px solid;
        BORDER-BOTTOM: #a9a9a9 0px solid;        
        background: #f5f5f5;	
        width: 70%;
	}

.hl-wide {
	 ;
        PADDING-LEFT: 5px; 
        PADDING-RIGHT: 5px; 
        padding-top: 15px; 
        padding-bottom: 15px;
        MARGIN-BOTTOM: 1px; 
        BORDER-TOP: #a9a9a9 0px solid;
        BORDER-RIGHT: #a9a9a9 0px solid; 
        BORDER-LEFT: #a9a9a9 0px solid;
        BORDER-BOTTOM: #a9a9a9 0px solid;        
        background: #fbfbfb;	
	}

.lnum {

	color: #a0a0a0;
	/background: #fbfbfb;
	}

.unhilited {background-color:white}
.hilited {background-color:#c0c0ff}


</STYLE>
@

}}}5


}}}4


#------------------------------------------------
{{{4 .h4. Accumulate the result ./h4.
#------------------------------------------------

Some of the vars may be unused later (run perl -wc to check?)

<<accumulate result in a buffer>>=
#2. accumulate result in a buffer


# vars for the main loop over lines of the target file

 $chunkbuf = ''; # collects whole formatted project file in memory
 $tocbuf = "";	# will accumulate TOC contents, i.e. small
 @indbuf = ();  # accumulates index of code chunks, small
 #%indbuf = ();
 @headings = ();	# the stack for nested subsections numbers/ids

 $section_num = 0;
 $section_num_prev = 0;
 $section_level = 0;
 $prev_section_level = $section_level;
 $line_counter = 0;
 $in_pre_tag = 0;
@


The logic is this: (a) all project files, unless they are machine-generated code, are
much below the sizes of RAM on modern machines. So I accumulate in memoru (in a string
$chunkbuf) a copy of the whole file, with necessary transformations and formatting.

Only 3 distinctions need to be made while iterating over hte lines of the Literate Source
file, between section headings, chunks of code and the lines from the body of documentation
chunks.

<<accumulate result in a buffer>>=


while (<LITSOURCE>) {

   $line_counter++;

    # cut out the MOLLY.pl invocation itself, the top of the Lit src file
    #if ( m%^#-+\s*?start of script% ... m%^xxxxxxxxxxxx% ) {  
    if ( m%^__DATA__% ... m%^xxxxxxxxxxxx% ) {
    s!^__DATA__\s*$!!;



<<process code chunks>>
<<process section headings>>
<<body HTML formatters>>


	# debug
	#print "---- $_";

   } # fi "start of script"

} #elihw over the whole input file

	


 foreach (@headings)  {

	($section_level, $section_num_prev) = split /-/, $_;
	$folding_section_end = $folding_section_end_str;
	$folding_section_end =~ s!(\$section_num_prev)!$1!ee;
	$chunkbuf .= $folding_section_end; 

	};

@





#-----------------------------------------------
{{{5 .h5. process code chunks ./h5.
#-----------------------------------------------

"goto" is from an old version of this script, with perl-specific options, I'll delete it
later.

I use perl range operator to cut out the code section between < < chunkname > > and the
closing "at" symbol, as is required in "noweb".
This is a use of the "range" operator inside another "while" loop over each line of the
Lit Source file, and they work together, the range just flips some status var ("in" - "out")
while the outside loop continues over the lines.

Once the section name is extracted with a regexp, the index buffer (indbuf) is formed and
updated.
Then "fieldset" formatting is written around the code chunk and line numbering (if set
in an option var) is written too

<<process code chunks>>=

	if ( m!^(goto)?<\<(.*)>\>=! ... m!^@\s*$! ) { # -- CODE CHUNKS -- 
		$chunk_title = $2;

		s/&/&amp;/g;	# escape &
		s/</&lt;/g;	# escape <
		s/>/&gt;/g;	# escape >

		if (m!(&lt;&lt;(.+?)&gt;&gt);(=)?!) 
		  {
		  $reference = $1;
		  $ind_str = "&lt;&lt;$2&gt;&gt; $section_num";
		  if (defined $3) {$ind_str .= "<sub>def</sub>"}
		  else { s!$reference!<font class='chunkref'>$reference</font>! }

		  unshift @indbuf, $ind_str;

		} # fi - chunks index accumulation

		# simple fieldset frames around code snippets
		s!^(goto)?&lt;&lt;(.+)&gt;&gt;=!$code_frameset_start_pre$1&lt;&lt;$2&gt;&gt;$code_frameset_start_post!;
		s!^@\s*$!$code_frameset_end!;

		if ( $line_numbering ) { 
		$chunkbuf .= "<font class='lnum'>" . $line_counter . "</font>   " . $_;
		}
		else{
		$chunkbuf .= $_;
		}

	} # fi code chunks
@

}}}5


#----------------------------------------------------
{{{5 .h5. process section headings ./h5.
#----------------------------------------------------

This is where folding sectons are created.
The more complicated logic is needed to .i.close./i. the sections properly, when subsections
are included (i.e. creating a step and forming the "close subsection" at the end in the correct
place.

1. Several formats were possible for collapsing sections, I chose the one you can observe while
reading the weaved document: subsections are completely enclosed by their supersections;
once a child subsection is initiated, the parent subsection cannot continue its body after
the end of the child.
I.e. once you started 12.2.1 inside your 12.2, you cannot write into 12.2 after 12.2.1 is finished, 
but you can add 12.2.2, 12.2.3, 12.2.2.1 - etc. - inside the enclosing section.

The logic was tested first in an external skeleton script.

2. I may need to disassemble this code to create "view mode" for my script - see "versions - 
CHANGES" subsection


<<process section headings>>=

	# -- SECTION HEADINGS 
   #elsif ( m!\.(\+)?h(\d)\.(.*?)\./h\d\.! ) {	# old version, no "rawHTML" enabled yet
   elsif ( m!$tag_open_symbol(\+)?h(\d{1,2})$tag_close_symbol(.*?)$tag_open_symbol/h\d{1,2}$tag_close_symbol! ) {	



	# -- using split vars for substitution to avoid
	#	regexps and need to keep old state --	

	$section_num_prev = $section_num;
	$section_num = $section_num + 1;


		#default for fold state in "settings" ??
		if ($1 eq "+") {
		    $fold_state="block";
		    $highlight_state = qq!  <script language=javascript> 
		    document.getElementById("toc"+ $section_num).className='hilited';
		    </script> !;
		} 
		else {
		    $fold_state="none";
		    $highlight_state = "";
		};
		$section_level = $2;
		$section_title = $3;


	

	

	$folding_section_start1 = $folding_section_start1_str;
	$folding_section_start2 = $folding_section_start2_str;
	$folding_section_end = $folding_section_end_str;


	$folding_section_start1 =~ s!(\$section_num)!$1!ee;
	$folding_section_start2 =~ s!(\$section_num)!$1!ee;
	$folding_section_start2 =~ s!(\$fold_state)!$1!ee;
	$folding_section_start2 =~ s!(\$highlight_state)!$1!ee;
	$folding_section_end =~ s!(\$section_num_prev)!$1!ee;


	$section_id = $section_level . '-' . $section_num;


	# finish previous subsection if not the first section in the file
	# ..and deal with nesting of sections according to their "depth level"

	# this is NOT the first section:
	if ( exists $headings[0] ){

		($prev_section_level, $prev_section_num)  = split /-/, $headings[0];

		if ($section_level == $prev_section_level){

		# close prev, start new
		$chunkbuf .= $folding_section_end;
		shift @headings;
		
		}

		elsif($section_level < $prev_section_level){
		
		  # close a bunch of them, in a loop -- THEN start a new one.
		  do  {
			($prev_section_level, $section_num_prev) = split /-/, shift @headings;
			
			$folding_section_end = $folding_section_end_str;
			$folding_section_end =~ s!(\$section_num_prev)!$1!ee;
			$chunkbuf .= $folding_section_end;

		   } while ( $section_level < $prev_section_level );
		}
	} # fi not the first section


	# common operations		
	unshift @headings, $section_id ;
	$chunkbuf .= $folding_section_start1;
	$chunkbuf .= "<font class='lnum'><i>(" . $section_num . ")</i></font>" . "&nbsp;" . $section_title .
	    "</a>&nbsp;<a><font class='lnum' size=-1><sub><i>(line " .
	    $line_counter . ")</i></sub></font>"; 
	$chunkbuf .= $folding_section_start2;

	#$chunkbuf .= "\n" . "<font class='lnum'><i>------ line " . $line_counter . 
	#	    " ------</i></font><br>\n";


	$toc_indent = "&nbsp;" x ($section_level * 7);
	#$toc_indent = "&nbsp;" x (($section_level-1) * 7 );
	#$tocbuf .= "\n<p>\n" if ( $section_level == 1 ); 
	$tocbuf .= $toc_indent . 
		"<i>" . $section_num . "</i>" .
		qq/&nbsp;<a href="javascript:;" onmousedown="toggleCombined(/ .  
		$section_num . 
		qq/);" id="toc/ . $section_num .
		qq/"><b>/ .
		$section_title . "</a>&nbsp;<a><font class='lnum' size=-1><i>(line " .
		    $line_counter . ")</i></font>" .
		    "</b></a><br>\n";

   } #; fisle: end elif headings

	

@

}}}5

#---------------------------------------------------------
{{{5 .h5. dotHTML formatter and rawHTML ./h5.
#---------------------------------------------------------

It is primitive, and I add needed markup "on the fly", as and when I need it.
The idea is to eliminate angle brackets in html tags, which I cannot type without errors
when typing fast, and substitute those with simple "dots", which do not requre switching
keyboard registers.

.s. This formatting also has problems with escapes.

Whether it's the fault of HTML standards or their implementation, web browsers continue to
react to html formatting .b.even inside the "pre" tags./b., which is obviously insane.
Therefore if your code chunks contain any HTML tags (e.g. processed by your code), you'll
need to escape them to display correctly.
And if you use sth like "& g t ;" in your code, the web page will also lie to you.
This is insane, and there is no good quick solution, one would have to use lengthy escape
tables etc. etc. ./s.

.ul. /* OFFTOPIC, ALSO: add < > and & escapes to the weaved code chunks -- for proper display */
    --- DONE ---
    These escapes exist in two places in the Weaver code:
    "process code sections"  and "body HTML formatters"
./ul.

.br.
This prototype script fails in some (unimportant to me)  cases.
dotHTML markup would also fail if your programming language uses dot-symbol-dot sequences
Mine do not.

The formatter is pretty straightforward, but sequencing of regexps is important.
One also needs to remember that once escaped, angle brackets are non-existent any more, 
and so the subsequent regexps must match on "& l t ;" not on the angle bracket in some
cases.


<<body HTML formatters>>=

	elsif( $weave_markup eq "dotHTML" ) {	# dotHTML formatter here

	      s/^=begin.*$//;	# - eliminate perl escaping, start
	      s/^=cut.*$//;		# - eliminate perl escaping, end
   	      #s/^{{{\d+(.*)$/$1/;	# - eliminate vim folding markup, start 
					# - dummy, as it is killed in "headings" processing 
	      s/^}}}\d+//;	# - eliminate vim folding markup, end

		s/&/&amp;/g;	# escape &
		s/</&lt;/g;	# escape <
		s/>/&gt;/g;	# escape >


	      # Paragraphs and line breaks are automatic now:
	      # ... unless we are dealing with the "preformat" tag
		#--note! that ranges do not work here
		$in_pre_tag = 1 if (m!\.pre\.!);
		$in_pre_tag = 0 if (m!\./pre\.!);;

		s/\.(\/?)pre\./<$1pre>/g;

	    unless ($in_pre_tag) {
	    (m/^\s*$/) and s/$_/<p>\n/
	    or s/\n/<br>\n/;
	    }
@

Now the regexps to cut out "#--------" lines and substitute "dot-notation" with angle brackets:

<<body HTML formatters>>=
	      # originally I separated header from the body with such a line
	      #s/^#-----.*/starting the table here/;
	      s/^#-----.*//;


		# add more here

		s/\.(\/?)b\./<$1b>/g;
		s/\.(\/?)i\./<$1i>/g;
		s/\.(\/?)ul\./<$1ul>/g;
		s/\.(\/?)li\./<$1li>/g;
		s/\.(\/?)ol\./<$1ol>/g;
		s/\.(\/?)s\./<$1s>/g;
		s/\.(\/?)div\./<$1div>/g;
		s/\.br\./<br>/g;
		s/\.p\./<p>/g;
		s/\.sp\./&nbsp;/g;

		s/\.(\/?)tab\./<$1ul>/g;	# "tabbing" with "ul"


		# this is some bullshit ???
		s/\.hr\./<hr /g;
		s/\.\/hr\./>/g;

		s!\.a\.(.+?)\.\/a\.!<a href=$1>$1</a>!g;

		# rudimentary &nbsp; s p a c i n g &nbsp (one word only)
		#s!\.x\.(.+?)\./x\.!join " ","&nbsp;&nbsp;",(split //, $1),"&nbsp;&nbsp;"!eg;

		# slightly better spacing (phrases, too):
		# although redundant  with more work than is needed
		if ( m!(\.x\.)(.+?)(\./x\.)!g) {
		    s!(\.x\.)(.+?)(\./x\.)!join " _ ", $1, (split / /, $2), $3!eg;
		    s!\.x\.(.+?)\./x\.!join " ", (split //, $1)!eg;
		    s!  _  ! &nbsp; !g;
		}
@

.b. BUG! ./b. This URL breaks my "ancor" dot-tags: 
     .pre. http://www.cs.tufts.edu/~nr/noweb ./pre.
.b. Got it ./b. The substitutions above must explicitly use "slash" for the closing HTML tag
in the regexps - otherwise they match stuff like ".cs." inside URLs

If an HTML tag is not in the above chunk, either add it or write with the two following generic
tags (slow and not nice on your fingers, though). You might need to use them also when your HTML
tag conntains some options, and so is not of generic simple type.

<<body HTML formatters>>=


		# generic for all tags with options
		s!\.&lt;\. !<!g;
		s! \.&gt;\.!>!g;


		$chunkbuf .= $_;

	}
@


.b. rawHTML formatter./b.
Raw HTML formatting can be done - either because it is non-restricted, compared to the stripped-down
"dotHTML" of my invention, or because it allows one to convert existing HTML documentation into the
folding format.
I.e. if you have a longish manual in which section headings are marked with HTML h1, h2, h3, ... tags,
you can convert it in 3 simple steps:
.ul. .li. delete opening and closing "html" and "head" "body" tags at the very top and bottom of your 
document
./li. .li. put perl invocation as the first line
./li. .li. set up markup mode in a variable: "$weave_markup = "rawHTML";" and "mollify" the document,
putting  "do MOLLY.pl" and DATA marker
./li. ./ul.
and if there are no interfering div section etc. - no complicated markup inside the headings, you'll get
an automatically generated folding HTML document.

If you do, it is sometimes easy to clean headings with a few regexps in a good editor like Vim

It is very convenient and I keep large manuals as folding HTML documents.


<<body HTML formatters>>=
	elsif( $weave_markup eq "rawHTML" ) {	# if the doc chunks marked up with real HTML
		s!^#-----.*!!;

	      #s/^{{{\d+(.*)$/$1/;	# - eliminate vim folding markup, start 
					# - dummy, as it's killed in "headings" processing 
	      s/^}}}\d+//;	# - eliminate vim folding markup, end


	      # Paragraphs and line breaks are automatic now:
	      # ... unless we are dealing with the "preformat" tag
		#--note! that ranges do not work here
		$in_pre_tag = 1 if (m!<pre>!);
		$in_pre_tag = 0 if (m!</pre>!);;


		unless ($in_pre_tag) {
		(m/^\s*$/) and s/$_/<p>\n/
		or s/\n/<br>\n/;
		}


		$chunkbuf .= $_;
	} # esle -- for rest of the body



@

{{{6 .h6. test of &nbsp;&nbsp; s p a c i n g &nbsp;&nbsp; regexp ./h6.

1. Hell, the thing is multiple sp /sp markups on one line. I need to iterate over
each separately and then put them in their right places, hedging with "nbsp"-ces each word.

2. The invocation is OK for $str_sp, but for boundaries of the string and word boundaries, 
they must be hedged too

3. Could subst spaces-betwen-words to sth like _ (space-underscore-space) as placeholders,
then subst them into nbspx2 in a following regexp

4. This tagging can be done cleanly and span severl lines if I do it in a different place - 
not while still reading the Literate Source file line by line, .x.but later./x. when
$chunkbuf is completely formed in RAM.


<<spacing.pl>>=
#!/usr/bin/perl
#
$str = $ARGV[0];
$str_sp = $ARGV[0];
#print "string is $str\n";

    # "sp" dot-markup to intersperse spaces: the basic formula
    #$spaced_str =~ s!(asdf)!join " ", (split //, $1)!eg;
    #
    
    # -- idea 3 from above: this works but is cumbersome --
    #$str_sp =~ s!(\.x\.)(.+?)(\./x\.)!join " _ ", $1, (split / /, $2), $3!eg;
    #$str_sp =~ s!\.x\.(.+?)\./x\.!join " ", (split //, $1)!eg;
    #$str_sp =~ s! _ ! &nbsp;&nbsp; !g;

    # -- first get the matching string in "if", then massage it:
    if ($str_sp =~ m!(\.x\.)(.+?)(\./x\.)!g) {
	$str_sp =~ s!(\.x\.)(.+?)(\./x\.)!join " _ ", $1, (split / /, $2), $3!eg;
        $str_sp =~ s!\.x\.(.+?)\./x\.!join " ", (split //, $1)!eg;
	$str_sp =~ s!  _  ! &nbsp; !g;
    }

    #print "\nthe string is $str\n";
    print "\nthe str_sp is $str_sp\n\n";
@

}}}6	    

}}}5

}}}4


#-------------------------------------------------------
{{{4 .h4. Print out the resulting page ./h4.
#-------------------------------------------------------

Page and the outer formatting table:

<<print out>>=

  # begin the page:
  #print '<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">', "\n";
  print "<html>\n  $html_head\n <body>  $html_body_table \n";

  # print out the TOC, the Chunks Index, the output buffer and close the page.

@

Next print the short instructions section (collapsible) at the top:

<<print out>>=

print <<end_of_print;
<p><fieldset class='tocfieldset'><legend><b>TABLE OF CONTENTS: outline of the document structure</b></legend>

<ul>
<p>
<br>
<div class='hl' align=center>
<a href="javascript:;" onmousedown="toggleDiv('tochowto');">
<b>HOW TO USE THE FOLDING DOCUMENT [expand/collapse]</b></a>
</div>
<div id='tochowto' style='display:none' style='background:#ffffff'> 
<p>
<ul>
<li><b>Collapsing is necessary when</b> you work on some code and must exclude 
<br>irrelevant sections of the rest of the literate project file. This 
<br>greatly helps to clear thinking by eliminating a general feeling of 
<br>being in a maze of code and unnecessary "housekeeping" tasks.
<br>One can say that there is a limited "buffer capacity" in the human
<br>mind, and relieving it of the need to remember where things are in a 
<br>larger file, at which other points one must fill in values or adjust
<br>invocation etc. <i>immediately makes the user "more intelligent"</i>
</li><li><b>To toggle</b> a section open/closed, click on the corresponding link
<br>Remember to open <i>all sections above it</i> for it to become visible.
</li><li><b>To restore the default view</b> reload the page in the browser.
</li><li>
<b>To keep some sections open</b> upon each reload - 
<br>e.g. you work on the code, update it constantly and cannot reopen it 
<br>again and again - mark their sections in the source file with a plus, 
<br>i.e. write the opening tag (only)  as +h2, +h3 (in &lt; &gt;  or in dots
<br>for dotHTML). Again, all sections above must be marked open too. 
<p><b>Note that</b> "expand all" and "collapse all" disregard these settings.
<br>Reload the page after using those options to again view the text according 
<br>to your preferences.
</li><li>
<b> To use the Index </b>, click on the numbered sections in the TOC above
<br>(opening them; use highlighting as a guide; when sections are visible,
<br>the slider on your browser window  will shorten too), or "expand all", 
<br>and then use your browser's Find function to highlight all chunk name 
<br>instances in the visible text
</li><li>
<b>To search for variables etc.</b>, "expand all" text - or manually 
<br>expand needed sections - and then use your browser's Find function to 
<br>highlight all and jump between the found items.
<p></li>

</div> 
<p>
<br>
<p>
<div class='hl' align=center>
<!--i><font size=-3> expand all -- collapse all</font></i-->
<a href="javascript:;" onmousedown="toggleDiv('tocmain');">
<b>TABLE OF CONTENTS [expand/collapse]</b></a>
</div>

<div id='tocmain' style='display:$toc_expanded' style='background:#ffffff'> 
<p>
<br>
<p>
end_of_print

@

Table of Contents from the formed "tocbuf":

<<print out>>=

 print "$tocbuf" if $print_toc;
 #print "$tocbuf";

print "</div>\n";

@

Start the "Index of code chunks", collapsible:

<<print out>>=

print <<end_of_print;
<p>
<br>
<p>
<!--fieldset><legend-->
<div class='hl' align=center>
<a href="javascript:;" onmousedown="toggleDiv('indbuf');">
<b>INDEX of Code Chunks [expand/collapse]</b></a>
</div>
<!--/legend></fieldset-->
<p>
<div id='indbuf' style='display:$ind_expanded' style='background:#ffffff'> 
<ul>
<p>
<b>"Def" subscript</b> means the chunk is defined, while a bare number means 
<br>the chunk is being used in the given section.
<p>
end_of_print

@


Index of code chunks; calculated in this snippet:

<<print out>>=

	 $ind_outbuf = '';
	 $prev_ch_name = '';

	 #for (sort @indbuf){ print $_, "<br>";}

	 for (sort @indbuf){

	   ($ch_name, $closing_bracket, $ref_num) = split /&gt;/, $_; 
		#/ - for editor colouring bug

	    if ( $ch_name eq $prev_ch_name ){ 
	      $ind_outbuf .= " <b>" . $ref_num . "</b> ";
	    }
	    else{
	      print  $ind_outbuf, "<br>\n"; 
	      $ch_namestr = $ch_name;
	      $ch_namestr =~ s!&lt;&lt;!!;
	      $ind_outbuf = 
	      	"<b>&lt;&lt;</b><font class='chunkref'>" . 
	      	$ch_namestr . 
	      	"</font><b>&gt;&gt;</b> -- <b>" . 
	      	$ref_num . 
	      	"</b> ";
	    }
	    $prev_ch_name = $ch_name;

	 }; # rof - forming the code chunks index

	print $ind_outbuf, "<br>\n";

@


"expand all" and "collapse all" at the end of the TOC/Chunk Index section 
at the top of the page:

<<print out>>=

  # The "expand all" "collapse all" control

print <<end_of_print;
</div>\n<p>
<br>
<p><div class='hl' align=center><i>
<a href="javascript:;" onmousedown="showAll();">
expand all</a> -- 
<a href="javascript:;" onmousedown="hideAll();">
collapse all</a>
</i></div><p>
end_of_print


 print "</ul></fieldset><p>\n<br>";

@



..and the document itself, formed earlier in the "chunkbuf" string in memory:

<<print out>>=

# The FULL OUTPUT, the file body:
 	print $chunkbuf;

@

Close the HTML formatting tags at the end of the page:

<<print out>>=

# close the page
	print $html_body_table_end;
	

#--- END OF SCRIPT ---

@

End of the project file

}}}4

}}}3


.h3. ./h3.

#-------------------------------------------------------------
{{{3 .h3. ADD-ON: example of additional markup - dotHTML - change unfinished./h3.
#-------------------------------------------------------------

.i. This subsection is a good example of the "out-of-order" processing that is
enabled in Literate Programming. Pieces for this subsection come from different
parts of the script and are laid out logically rather than in the order imposed
by the machine ./i.

.b. .i. Notes ./i. ./b.
.ul.
Implementation of a simple "dotHTML" markup  in which angle brackets are substituted
with dots for some of the commonest HTML tags (to speed up typing and eliminate typos).

To add your own markup, such as "wiki" or one of the "markdowns", copy this section
and adjust contents. The idea is that MOLLY iterates over documentation sections
line by line, so your filter can use regular expressions for a line-by-line processing
of the documentation chunk text.

Make sure your new "markdown" does not interfere with the 3 major escapes used in 
the "mollified" Literate Source file: the double angle brackets and the "at" symbol
(imposed by "noweb" tools markup) and the double backticks ( MathML interpretation
if you enable it) plus words "a m a t h" and "e n d a m a t h" without spaces btw letters.
./ul.


.b. .i. ...unfinished... ./i. ./b.

}}}3


#-------------------------------------------------------------
{{{3 .h3. ADD-ON: ASCIIMathML and LaTeXMathML inside Molly  ./h3.
#-------------------------------------------------------------

.b. 1 ./b. .i. STATUS ./i. - Ok, but may be brittle if escapes (double backticks)
get in conflict with the target prog language or some "markdown" 
introduced later into Molly.

Also - may have lost LaTex functionality because of my need to
preserve $ for programming language use.

.b. WILL NEED TO DISTRIBUTE THE MODIFIED LIBRARY NOW with Molly ./b.

.b. 2  Implementation ./b.
.. was straightforward: I simply cut in an invocation of ASCIIMathML.js into the header of 
my generated output folding-HTML file. That's it.

Then I tested the lib and found that it reacts to backticks and $ signs in my code sections etc.
Then I made a customized copy.

If some symbols are missing, you can customize it by simply adding a line to teh MOLLY.weave
source code and re-tangling the MOLLY.pl

Here is how:

{{{4 .h4. Extending the lib with missing LaTeX or HTML symbols ./h4.

Documentation to the library explains how to add lines in JavaScript to your html file which will
extend the list of symbols known to the library.
.a. http://www1.chapman.edu/~jipsen/mathml/asciimathextend.html  ./a.
A copy of the page:
.ul.
.b.ASCIIMathML.js: Extending the symbol table./b.

The standard symbol table of ASCIIMathML.js does not contain many symbols. 
It can be extended by adding additional symbols on any webpage that requires
them. This is done by adding a few lines of JavaScript code.

.b. 1. For example ./b. , suppose we want to add symbols for "not less or equal"
    and "not greater or equal".

.ul. .li. We first have to find the four-digit hexadecimal Unicode value for these symbols
by looking them up at, say, 
.a. http://www.w3.org/TR/MathML2/chapter6.html#chars.entity.tables ./a.

./li. .li. Next we have to decide what input strings we want to associate with these
symbols, say "!<=" and "!>=".

./li. .li. Finally we add the following lines to the head or body of our HTML file:
.pre.
<script type="text/javascript">
define("!<=","\u2270")
define("!>=","\u2271")
</script>
./pre.
./li. ./ul.

Here we test the modified symbol table: a !<= b !>= c produces ``a !<= b !>= c``

.b. 2. To add a symbol to the LaTeX commands ./b., use the following alternate syntax:

.pre.
<script type="text/javascript">
newcommand("\\nle","\u2270")
newcommand("\\nge","\u2271")
</script>
./pre.

Now \$a \nle b \nge c\$ produces $a \nle b \nge c$.


.b. 3. If you know the numeric entity reference ./b.  of the symbol you want 
to use on an ASCIIMathML webpage, you can also refer to the symbol .b. directly ./b. 
by using that reference. 

E.g &#x2270; produces  ``&#x2270;`` . If a symbol is only used occasionally, this is certainly 
the simplest way to include it. 
./ul.

.i. /error/ My copy of the page in MOLLY does not let ampersand invocations through 
ALSO: my copy of the lib, in which I mechanically changed single backticks to double backticks
may have clobbered something, too.
CHECK IT. ./i.

Therefore, .b. to extend it in MOLLY ./b., just continue this chunk here (the "script .." --- "/script"
tags are already provided in the code, do NOT retype them, input only the contents):

<<HTML head section javascript add-ons>>=

//type in commands to extend ASCIIMathML.js here;
// no "script" "/script" wrappers needed
// ....NOT FUNCTIONAL YET.....

@

}}}4

#--------------------------------------------------------------------------
{{{4 .h4. Testing ASCIIMathML.js -- OK partially ./h4.
#--------------------------------------------------------------------------

#--------------------------------------
{{{5 .h5. test one - simple ./h5.
#--------------------------------------

Let's test if it works by adding some formulae here:
.b. I changed the ASCIIMathML.js to use .i. double backticks ./i. as escapes ./b.
So strings wrapped in double-backticks or chunks of text with formulae inside
"a m a t h" .... "e n d a m a t h" are the only ones that should be interpreted.

NOTE: they appear in blue, so errors, if the math lib picks up other parts of 
your LitProg file unnecessarily and mangles them, one could see it with
"expand all" and checking for blue insertions.

NOTE 2: the math lib stops working between the "pre" - "/pre" tags

NOTE 3: Rolling the mouse over the interpreted formula will display
a baloon with the ascii coding of the expression (very convenient)

.ul.
Let's try some interesting formulas: ``E=m c^2``
and ``e^(i pi)=-1`` 
and ``AA x in CC (sin^2x+cos^2x=1)`` 
and one more: ``sum_(i=1)^n i^3=((n(n+1))/2)^2``

(add your own -- note that text-tokens are only recognized if separated by spaces)
./ul.
OK, here we are - in between 2 math sections

.ul.

amath
Example: Solving the quadratic equation.
Suppose a x^2+b x+c=0 and a!=0. We first divide by \a to get x^2+b/a x+c/a=0. 

Then we complete the square and obtain x^2+b/a x+(b/(2a))^2-(b/(2a))^2+c/a=0. 
The first three terms factor to give (x+b/(2a))^2=(b^2)/(4a^2)-c/a.
Now we take square roots on both sides and get x+b/(2a)=+-sqrt((b^2)/(4a^2)-c/a).

Finally we move the b/(2a) to the right and simplify to get 
the two solutions: x_(1,2)=(-b+-sqrt(b^2-4a c))/(2a) 
endamath

./ul.

..and now let's check some LaTeX constants:
.ul.
.pre. \int .sp. \oint .sp. \partial .sp. \nabla ./pre. 
``\int`` .sp. ``\oint`` .sp. ``\partial`` .sp. ``\nabla``
.pre. \pm .sp. \emptyset .sp. \infty .sp. \aleph ./pre.
``\pm`` .sp. ``\emptyset`` .sp. ``\infty`` .sp. ``\aleph`` 
.pre. |\ldots| .sp. |\cdots| ./pre.
``|\ldots|`` .sp. ``|\cdots|`` 
.pre. |\ | .sp. |\quad| .sp. \diamond ./pre.
.sp. ``|\ |`` .sp. ``|\quad|`` .sp. ``\diamond`` 
./ul. 

.i. .b. end of math test ./b. ./i.

}}}5

#----------------------------------------------------------------------
{{{5 .h5. test two - from realistic paper, partially failing  ./h5.
#----------------------------------------------------------------------

.<. hr width=30% align=left .>.

.b. ..MORE from some paper: ./b.

.b. 1. Freudental Formula ./b.
``mult(\xi)=\frac{2}{(\mu+\rho|\mu+\rho)-(\xi+\rho|\xi+\rho)}\sum_{\alpha\in\Delta^{+}} mult(\alpha) \sum_{k=1}^{\infty}mult(\xi+k\alpha)(\xi+k\alpha|\alpha)``
It includes roots ``\Delta=\left\{k\delta+\alpha|k\in Z,\; \alpha\in \Delta_0\right\}``
positive roots ``\Delta^{+}=\{k\delta+\alpha|k\geq 0,\; \alpha\in \Delta_0^{+}\}\cup \{k\delta+\alpha|k\geq 1,\; \alpha\in \Delta_0\setminus \Delta_0^{+}\}``

.b. The above is rendered correctly by ASCIIMathML.js and LaTeXMathML.js ./b. 
libraries from the standalone Editor.It is rendered correctly with 
ASCIIMathML_with_modified_escapes.js from Molly 
(Testing with LaTeXMathML.js requires wrapping the formulas in dollar signs)


.b. 2. The following long formulas .i. fail on both ./i. ASCII and LaTeX libraries ./b. tested
from the standalone Editor and ASCII_with_modified_escapes from Molly
The number of incorrect renderings is small (1 or 2 elements left unrendered), and
suggests those elemens are simply missing in definitions.


 The idea is to use recurrent relations for anomalous branching
coefficients based on the summation over the special set of vectors 
``\Gamma_{\fr ak{a}\subset \fr ak{g}}``  called ````fan''. We
need to introduce some notations. Let's consider the reduction of the
representation of the affine Lie algebra ``\math \fr ak{g}`` to 
representations of affine Lie algebra ``\math \fr ak{a}``. By
``\pi_{\math \fr ak{a}}`` we denote the projection of the root space
``\fr ak{h}_{\fr ak{g}}^{\ast } to \fr ak{h}_{\fr ak{a}}^{\ast }``. The
set ``\Gamma_{\fr ak{a}\subset \fr ak{g}}``  is introduced as the
combination of projection of positive roots ``\Delta^{+}`` of algebra
``\fr ak{g}`` using formulae:

.b. .i. The above paragraph is OK ./i. ./b.
The following is rendered incompletely:

{eq:7}

 ``\prod_{\alpha \in \left( \pi _{\fr ak{a}}\circ \Delta ^{+}\right) }\left( 1-e^{-\alpha }\right) ^{\mathrm{{mult}\left( \alpha \right) -{mult}}_{\fr ak{a% }}\mathrm{\left( \alpha \right) }}=-\sum_{\gamma \in \Phi _{\fr ak{a}\subset \fr ak{g}}}s\left( \gamma \right) e^{-\gamma }``.  

 {{{5

{eq:18}

 `` \Phi _{\frak{a}\subset \frak{g}}=\left\{ \gamma \in P_{\frak{a}}\mid s\left( \gamma \right) \neq 0\right\} ``;  

 
{eq:19}

 `` \Gamma_{\frak{a}\subset \frak{g}}=\left\{ \xi -\gamma _{0}|\xi \in \Phi _{% \frak{a}\subset \frak{g}}\right\} \setminus \left\{ 0\right\} .`` 

 
{recurrent-relation}

``  k_{\xi }^{\left( \mu \right) }=-\frac{1}{s\left( \gamma _{0}\right) }\left( \sum_{w\in W}\epsilon \left( w\right) \delta _{\xi ,\pi _{\frak{a}}\circ \left( w\circ (\mu +\rho )-\rho \right) +\gamma _{0}}+\sum_{\gamma \in \Gamma _{\frak{a}\subset \frak{g}}}s\left( \gamma +\gamma _{0}\right) k_{\xi +\gamma }^{\left( \mu \right) }\right)   
``
{{{5

Fan doesn't depend on the module, but
is determined by the injection of sub-algebra into the algebra. If 
sub-algebra is Cartan sub-algebra, this relation gives...




.<. hr width=30% align=left .>.



}}}5

}}}4

}}}3

}}}2

}}}1



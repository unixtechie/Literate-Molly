#!/usr/bin/perl

#-------------------------------------
# -------TOC and INDEX behaviour------

# print TOC? 1:0
#$print_toc=1;	# default is to print

# should we keep TOC expanded? "block":"none"
#$toc_expanded="block";	# default is to unfold

# should we keep Chunks Index expanded? "block":"none"
#$ind_expanded="none";	# default is to keep folded


# should we number lines in code sections? 1 : else
#$line_numbering = 1;	# default is to number


#-------------------------------------
#---------MathML options--------------
# should we enable MathML via ASCIIMathML.js or LaTeXMathML.js library? 1:0
#$enable_ASCIIMathML = 0; #default is to disable as it slows Molly down a lot
$enable_ASCIIMathML = 1;

# If yes, what is the full path to the lib? Remember to get the one with proper
# escapes for your work, default or modified (see documenation)
# CAN BE: (a) local "/full/path/from/root/to/ASCIIMathML_with_modified_escapes.js" or 
# (b) in current dir "ASCIIMathML_with_modified_escapes.js" or
# (c) on the web, e.g. the original site of the library (unmodified) is:
#$path_to_ASCIIMathML = "http://www1.chapman.edu/~jipsen/mathml/ASCIIMathML.js";
#$path_to_ASCIIMathML = "ASCIIMathML_with_modified_escapes.js"; # default is current dir


#-------------------------------------
#--------Document Markup lang---------

# how are doc sections marked? "dotHTML":"rawHTML"
 $weave_markup = "dotHTML"; # default is "rawHTML"


#--------------------------------------
#---------File extensions setting------
 
# what is the file extention to weave it? (perms must allow execution!)
# e.g. "scriptname.weave" or "scriptname.cgi" etc.
#$weave_extension = "weave";	# default is "weave"

# what is the file extention to tangle it? (perms must allow execution!)
# e.g. "scriptname.tangle",  "scriptname.pl" etc.
#$tangle_extension = "tangle";	# default is "tangle"

#--------------------------------------
#---------invocation of MOLLY.pl-------
do "MOLLY.pl";
exit;
__DATA__
#-----------------------start of script---------------------------
#-----------------------------------------------------------------
#-----------------------------------------------------------------




.<. center .>. .b. Licensing ./b.
MOLLY is licensed under GNU Public License version 3. .<. /center .>.


#--------------------------------------------------
{{{1 .+h1. MOLLY MODULE ./h1.
#--------------------------------------------------

.b. What is it? ./b.

.i. Answer A: ./i. this is an attempt to combine Literate Programming (as practiced with
    "noweb" tools by Norman Ramsey) and autogenerated document folding/outlining with
    Javascript and HTML -- to escape scalability limitation of pure L.P. and enable a number
    of new source file management techniques.

.i. Answer B: ./i. Technically, this is "MOLLY.pl", a MO-dule for LI-terate programming, a
    small perl script that implements a new type of "weaver" for Literate Programming, which:
    .ul. .li. is HTML-based,
    ./li..li. can produce formatted documents automatically, as a CGI script, as well as in 
    a separate step, as a classical weaver and
    ./li. .li. creates .i.folding./i. documents./li. ./ul.
.b.Why?./b.
    .ul..li. This greatly simplifies markup, ridding it of TeX entanglement and reducing it 
    to basic HTML tagging. Inputting mathematical formulae is still possible with MathML.
    No more one needs to be "writing and debugging two programs in place of one", a
    common complaint about the use of WEB-like lit.prog. tools based strictly on (La)TeX.
    ./li..li. ...while folding, as already stated, allows the programmer to apply a number of code
    management techiniques not possible before with flat Literate Programming source 
    files. ./li../ul.


.b.Below./b. you will find 
(a) an explanation of the concepts involved 
(b) usage information and 
(c) the annotated literate source of the script


.br.
If you are not familiar with concepts behind LIterate Programming, please read an introductory
article, such as the one below or .a. http://en.wikipedia.org/wiki/Literate_Programming ./a.


.br.
#------------------------------------------------------------------
{{{2 .h2. THE CHUNK TO TANGLE BY  DEFAULT ./h2.
#------------------------------------------------------------


<<*>>=
<<MOLLY.pl module>>
@

<<*-dis>>=
<<spacing.pl>>
@
<<*-dis>>=
<<tanglediff.test2.pl>>
@

<<*-dis>>=
<<md5 hashing from perl>>
@

<<*-dis>>=
<<check topo sort>>
@


<<*-dis>>=
<<check strings expansion>>
@

}}}2


#-------------------------------------------------------------------------------------
{{{2 .h2. PART I ----------- History and concepts. "Management of thinking" ------------ ./h2.
#--------------------------------------------------------------

{{{3 .h3. What is Literate Programming? ./h3.

.b. .i. This is a techinique for "management of thinking", which has nothing to do with programming. ./i. ./b.



#---------------------------------------------------------
{{{4 .h4. My example from ru_perl (in Russian) ./h4.
#---------------------------------------------------------

И, наконец, третье объяснение что значит писать 'на ЛП'.
Если бы целью вашей была не программа, а роман или статья-эссе, то "писать на ЛП"
означало бы писать примерно так:


.ul.
    < <quote> >=
    A HISTORICAL CURIOSITY
    this is a < <story> > that was used
    by Emperor Friedrich II when he replied
    to < <ambassadors> > of France, famously:
    "bla-bla-bla.
    < <quote_continued> >"
    @

    < <story> >=
    histoical quote that first surfaced in a lesser-known Austrian publication in 1843
    @

    < <ambassadors> >=
    Earl Marra and Count Swiepolski
    @

    < <quote_continued> >=
    Hrrrrrr mbrruaghhhrch
    awwrraghrtps
    pst pst pst.
    @
./ul.


И на самом деле так можно писать любые тексты, например журналистскую статью, в которой 
есть некая последовательная мысль, а отдельные куски или неизвестные сразу факты 
разрабатываются и добавляются позже.

ЛП - метод организации мыслей и придания тексту структуры на мета-уровне, на основе неких 
фраз, скрывающих за собой любой "оконечный код" или любые подобые абстракции.

Пре-процессор их автоматически подставит и развернет все в нужной последовательности


Кстати как видите в последнем примере ВООБЩЕ НЕТ НИ ОДНОГО КОММЕНТАРИЯ, и вместе с тем это 
"программа на ЛП": она написана на "псевдокоде", т.е. с использованием макро, которые 
становятся точными операторами мета-языка.

Т.е. ЛП в нормальном случае связан с текстом (который объясняет концепции и идеи кода), 
но сама техника введения макро вместо кропотливых кусков чтобы теми кусками заняться в 
их очередь и избавить мозг от нагрузки по ведению учета и контроля тысячи мыслей -- то 
есть для того, чтобы в конечном счете СТАТЬ УМНЕЕ за счет механизма абстрагирования -- 
эта техника возможна и совершенно без комментариев.

Которые почему-то все настаивают есть не заметки в помощь программисту, а некая "документация" 
якобы для посторонних людей.

Нет, запись мыслей ПОМОЖЕТ и будет служить документацией идей, да. Но создается это не для 
васи, а для себя в момент программирования.


.b. ... continued in a next commentary: ./b.

Цитата о "людях, которые умеют хорошо писать" очень глупа потому что ПОХЕРУ хорошо ли 
программист пишет или так себе: он пишет для себя в помощь мыслям.

Чтобы стало понятнее, возьмем последний литературный пример. Он был без комментариев. Если 
теперь "восстановить" те реалистические комментарии, которые там могли бы появиться в процессе,
это выглядело бы примерно так:

.ul.
    Анекдот пойдет в эпиграф третьего раздела (? - или в основной текст?)

    < <quote> >=
    A HISTORICAL CURIOSITY
    this is a < <story> > that was used
    by Emperor Friedrich II when he replied
    to < <ambassadors> > of France, famously:
    "bla-bla-bla.
    < <quote_continued> >"
    @


    Уточнить дату и обстоятельства:
    < <story> >=
    histoical quote that first surfaced in a lesser-known Austrian publication in 1843
    @

    Нужны имена; если нет, выдумать: публика дура и любит "точность"
    < <ambassadors> >=
    Earl Marra and Count Swiepolski
    @

    Кажется цитата была в моих архивах: сделать поиск на хррр? пст?
    Брал её из гугла; вспомнить еще какие-то слова
    < <quote_continued> >=
    Hrrrrrr mbrruaghhhrch
    awwrraghrtps
    pst pst pst.
    @
./ul.

.. ну а заполненные позже куски составят уже полный чистый текст, который НЕ НАДО лазить править 
руками.

То есть в момент написания мы отодвинули массу соображений, которые занимают весьма 
ограниченные ресурсы мозга (всего-то до 7, говорят, элементов в краткосрочной памяти) и 
необходимости решать и увязывать детали.

Мы стали "умнее" за счет того, что убрали, отодвинули куски деятельнопсти, заменив их на 
время фразами-абстракциями.

Вот в чем суть.

}}}4


#-----------------------------------------------------------
{{{4 .h4. Invented example (an urban legend) - unfinished ./h4.
#-----------------------------------------------------------

Let's suppose you are an editor of some local newspaper which wants to kick up sales.
So one day you get an email that says:
.ul. 'Don't know if this is true or not, but I received it from a good friend, so... 
    you never know... 
    Just a small warning of the latest way criminals operate - very inventive!! 
    They dress in black & cover themselves in black refuse bags and wait on the
    pavement. When .s. SAPS ./s. police or the neighbourhood watch drive pass they
    crouch down on the ground to make it look like a full black rubbish bag. .s. SAPS ./s.
    police etc ignore the "black bags" & drive past. The criminals then either wait
    for the home owner to come home ---to hijack them or proceed to break into the
    house.
    Please be aware & beware of "moving" black bags!!! --particularly on rubbish
    removal days.
    PS: The neighbourhood watch member who noticed this wouldn't have known any
    different if one of the bags hadn't moved & if he wasn't vigilant.'
    .i. /* this example of a real urban legend obtained via http://thoselegends.blogspot.com/
    Entry of Thursday 30 October 2008 */ ./i.
./ul.
You call a meeting and say to your stuff:
"Guys, .x. this eeez a bomb!! ./x." - (and read them the e-mail) -  "Get down to it! 
You write your parts, I will edit the whole thing.  Let's see..."

<<Intro>>=


@

Then after collecting the materials  the editor produces a skeleton for the article.

<<Article>>=
<<Intro>>
<<witness: a personal side, splinter 1>>
<<opinions: public and officials' reactions>>
<<witness:  a personal side -- gist of story, splinter 2>>
<<throw in some stats and end on a grand note>>
@


.b. .i. ... unfinished ... ./i. ./b.

}}}4


}}}3


{{{3 .h3. Controlling human attention ./h3.


.br.
.b. LP as "management of thinking" ./b. 

    .b. .i. L.P. is a technique for "management of thinking" that help to unload short-term memory
    and "splits levels" for 'global thinking" and "local changing" ./i. ./b.

    The biggest problem in managing complex texts of any kind - programming simply being the most
    complicated one, where the text is not supposed contain errors at all - is in holding it all
    together in one's mind.

    Human short-term memory is surprisingly tiny, up to 7 to 9 objects simultaneously at any one
    time, psychologists tell us. Therefore, when faced with larger tasks, humans need to use a number
    of "aoivdance techniques" to dance around the limitation.

    First, we constantly switch. E.g. I need to change my program. I remember the general outline of
    it (as no more than several largish chunks), so I use that to figure out where to go. On each
    level I would probably remember details "inside" each of those largish blocks etc.

    In my experience a script or a program longer than, say 1000 to 1200 lines long becomes a major
    problem unless special techniques are used to help one's mind.

    In programming, probably 90% of "chunking", i.e. division into procedures, or "object" or
    "functions" are not needed for the machine. They are done .b. simply for the humans not
    to lose thread. ./b. Things would simply become totally unmanageable otherwise.

    Here comes also the idea of "writing domain-specific languages": humans chunk lower-level
    operations into a new 'unit' or 'abstraction', then manipulate with higher-level abstractions
    over abstractions over abstractions over abstractions..

    "Literate Programming" is not a programming-specific technique that allows us to create arbitrary
    systems of abstractions .i. with phrases in a human language ./i. - "in pseudocode" - while staying
    precise in our specification opf the final product.
    In this L.P. .b. is an alternative to procedures and subroutines in the machine language ./b.

    For example, I can easily write and maintain na LPSource file with

<<logical switch>>=
if (<<condition A>>) {
    <<a thousand-line-long piece of code>>}
else { 
    <<another thousand-line-long piece of code>>}
@

    (and specify all those references elsewhere), while such code written directly would be
    unmaintainable and almost impossible to understand to a human. As a result, a human would
    .i. have to ./i. wrap his code into some subs, with inherent limitations and complications
    on their parameters and return result, built into his programming language.
    The machine would slow down its execution because internally it will maintain environment
    to switch to when returning etc.
    Isnt't it ironic that "hand-made optimisations" include "unrolling" programming constructs
    programmers introduced on the first place? The reason most probably was that otherwise
    a human mind would not be able to keep the thread, they would have lost it without that
    unnecessary for the machine mental chunking.


    So, .ul. .i. .b. Literate Programming is a system of free-form macros in a natural human language
    used as an alternative to programming language procedures used as props to limit load on
    human attention span, and totally unnecessary for machine language in themselves ./b. ./i. ./ul.


.br.
.b. Three problems with L.P. -- unification of L.P. and folding ./b.

    Donald Knuth first was thinking of how to document his code when he created a mish-mash of
    previous attempts at similar management techniques with macros, which he called "WEB" (at
    the time when no "www-web" existed yet).
    Then he proclaimed this is the best way to write programs he knows, and repositioned it
    as "a programming paradigm", in direct competition to the "structural programming",
    introduced in the previous decade.

    Acceptance of this new method of program writing however was disappointing. I believe, there
    were and still are three factors at play, which hurt it, even though the name of L.P. creator
    ensured L.P. never fell into complete obscurity.

    .ul.
	.li. First, L.P. used TeX as a formatting tool, which is a sort of programming language in
	itself. Therefore, the first thing to blame L.P. for became "but I'd need to write - .i. and 
	debug! ./i. - two programs at the same time, in TeX and in my own machine language.

	Today when much, much simpler markup languages abound - "html" or even "markdown html"
	or even "wiki" for the majority of uses that do not require typesetting complicated
	equations or graphs - this problem has long been solved.
	You do not need to "debug" basic HTML markup - any error is displayed in your browser as a
	distortion of the web page, I do not need to "debug" html when writing with my Molly script
	which uses html markup.

	./li. .li. Secondly, the first generation of L.P. tools was language-specific. You could 
	do Pascal, but not Fortran. Later "C" and "Fortran" literate tools were added, but you could
	not do Lisp or Ada etc.

	Today with tools like "noweb" by Norman Ramsey this problem has long been solved. Simplified
	to its core idea Literate Programming is now totally language-independent to the degree that
	you can write books or essays with L.P. tools not even knowing how to program for the computer.

	./li. .li. And the third problem is the flat file structure of Literate Source files and
	(probably that could be listed as the fourth, psychological stumbling block) the insistence
	on "producing clean documentation" or "polished essays" of one's programs other could read
	and enjoy.

	Flat files continue to limit the size of the literate source files: your mind still .i. has to
	keep internally the overall structure of your program ./i. and switch from it to doing concrete
	tasks.
	Technically a Literate Source file can include .i. many ./i. program files ( e.g. project.h,
	project.c, a makefile and a README). In reality the size is limited by your "attention horizon"
    ./li. ./ul.

    .b. I propose to solve ./b. this last problem by combining L.P. with folding or outlining, using html and
    javascript as the simplest and ubiquitous tools.

    The Literate Source file is written in basic HTML, or even in "markdown" or "wiki"-style markup
    notation. The script then automatically creates a document with folds at each heading line
    (i.e. "h1", "h2", ...). The file can be "weaved" from command line or dynamically under a web 
    server as a CGI document.

    Folding must allow opening an arbitrary number of sections from any place in the file to create
    a sub-view of the document, a small document which is relevant to some particular sub-task.
    These sub-views must persist for the time of this particular work, i.e. the user should not
    be forced to reopen his subview over and over again.
    
    Common practice in IDEs and outlining editors, when a programmer is allowed to see only one
    section at a time is the death of the idea of folding.
    
    .i. As an example of totally wrong presentation, ./i. which  fragments perception into poorly
    connected pieces and does not allow a reader to see the forest for the trees and see 
    documentation of GNU libavl .a. http://adtinfo.org/libavl.html/ ./a. 
    It is not humanly possible to follow the train of logic from such a presentation: one has to
    keep an internal mental map of the document BEFORE reading it and inability to see more than
    one snippet puts a stop to perception: once the snippet is left, one has to rely on memory of
    previously read pieces to relate things to each other.
    Nor the split HTML, not the flat file format provide for human-friendly perception of the code
    if it is not a small self-contained piece.
    

    .i. A document that is based on a structure of folding subsections ./i. drastically increases one's
    attention span, allows to manage easily thousands and thousands of lines of text, and makes
    inclusion of many different types of files into what becomes one Literate Source Project file
    "a cinch".

    A number of techniques becomes possible which have not been possible before in a flat file. 
    Snippets testing language constructs, doubling certain "chunks" while keeping a pointer in a
    "dummy chunk" to preserve the previous working version of your program while experimenting
    with a new one (previously one would have to use version control or rename files for that), 
    making collections of loosely related documents and script, each still obtainable, such as
    a collection of system administration policies, readmes, config files and many scripts -- all
    become easy with a folding literate source file.

    And consequently emphasis moves from the creation of usually comparatively compact programs
    exposed as a sort of polished essays (or documented for their logic in the order of thinking)
    -- and to using Literate Source folding files as your "work log" or "a log of thinking" when
    developing a program, like a scientist might keep a log of his experiments.

    Clean version of documentation or program presentation might emerge from it, later, but at the
    moment of conception the most urgent task is to preserve your thinking, however "clever" or
    "stupid" that might be.
    It does become good documentation, it seems, even without further polishing, however.

}}}3


}}}2	    


#------------------------------------------------------------------------------
{{{2 .+h2. PART II ------------ HOW TO USE MOLLY.pl ------------ ./h2.
#-------------------------------------------------------


#--------------------------------------------------------
{{{3 .h3. My workflow - literate programming with Molly ./h3.
#--------------------------------------------------------

 .<. img src=eeerotate.jpg align=right hspace=5 width=200 border=2 .>.
.i. .b. A prerequisite of sorts ./b.
Use a vertically rotated screen (with an external keyboard and mouse on
a notebook) or a large  enough screen to see a vertically positioned A4
sheet of paper to obtain full advantages of outlining and folding 
Psychologically, the more we see, the more "clever" we are. Stop reading
compicated documents through a slit: with mental perception crippled, 
you'll just jump between fragments, and never truly "get" them in whole. ./i. .b. >>> ./b.

Rotation on Linux is done by running .pre. xrandr -o right|left|normal ./pre.
from an X terminal window. Most modern video cards support this.

.b. The Workflow ./b. :
.ol.
    .li. I run a web server on localhost:8000, for myself only. My
    development directory is under the web server - or is linked to
    the web server document tree.

    ./li. .li. I write my Literate Source file in a vim editor. I mark up
    the documentation section (i.e. not code) with most basic HTML tags
    (e.g. <h2>, <b>, <ul> ...). 
    The code sections live between "< < section name > > =" and "@" 
    (in the first position in the line), as is required by "noweb"
    literate programming tools.

    ./li. .li. I view my file in a web browser, and reload the page after editing updates.
    Because I write my Literate Source with help from the MOLLY.pl script (see below how to 
    include it in the file and set it up), every "heading" in HTML (i.e.  h1,  h2  etc. )
    automatically becomes a .b. folding subsection ./b. of the document I see in the browser,
    and every code section is automatically formatted with line numbers and a frame.

    ./li. .li. When I think ("globally"), I look at the formatted, immediately updating document
    in the browser, keeping open only the sections relevant to my thinking.
    When I edit, I refer to the line numbers, and avoid navigating "blindly" in the programming
    editor, stressing my memory. I edit "locally".

    ./li. .li. Automatically created folding documents allow me a number of techniques and
    uses impossible previously with flat "literate programming" files.

    ./li. .li. I tangle the created code either directly with "notangle" tools from "noweb", or
    by running "MyProject.tangle", which is a link to "MyProject.weave", the Literate Source file
    turned into a perl script by inclusion of the MOLLY.pl into it in the first lines of the file.
./ol.

See details about this setup and possible uses of it below.
}}}3

.br.
#-------------------------------------------------------------------
{{{3 .h3. SET UP a Literate Source file and project ./h3.
#--------------------------------------------------------



#--------------------------------------------------------
.h4. Prerequisites: "noweb" tools By Norman Ramsey ./h4.
#--------------------------------------------------------

    The first version of the script uses a "pass-through" tangler, i.e. delegates actual tangling to 
    the "notangle" utility from the "noweb" suite.

    Please obtain and install it. .b. .i. Make sure the tangler is in your path ./i. ./b.
     .a. http://www.cs.tufts.edu/~nr/noweb ./a.

    Any version will do, e.g. the one based on shell and awk. I created the MOLLY script to work with
    the overall markup of the "noweb" tools. It means your project file(s) can be directly processed
    with "noweb" tools. MOLLY is just an alternative weaver which creates folding HTML documents 
    on the fly.


#------------------------------
.h4. Setting up the file ./h4.
#------------------------------


    I aimed at simplifying and eliminating unnecessary steps, and wanted to automate some others.
    Therefore practical work with MOLLY.pl looks like this:

    .ol. .li. .b. .i. Your Literate Source file must be "mollified" ./i. ./b., i.e. you have to add an invocation
    of MOLLY.pl in the first lines of it. Think of it as a template. You will write your Literate Source text
    right after these initial lines.  The minimal template is this:

<<minimal MOLLY template>>=
    #!/full/path/to/perl
    do "/full/path/to/script/MOLLY.pl";
    exit;
    # delete first space(s) in the next line
    __DATA__


    <h1> And here I start My Project </h1>
    Your Literate Source file can be typed here

    <h2> Subsection </h2>
    level 0-9 of subsections are allowed now.

    Each subsection will be automatically created as "folding". Javascript must be
    enabled in your browser to use this functionality
@

    The perl invocaton and the "__DATA__"  line must start .x. at the first position ./x.

    You do not need any extra perl modules  as pre-requsites, the script uses core perl.  

    Full template will also set configuration variables between calling the perl interpreter and
    the inclusion of the MOLLY.pl script, which adjust its behaviour.

    Save this under some name, e.g. MyProject.txt. This turns your Literate Source file into
    a perl script

    ./li. .li. .b. .i. Make it executable. ./i. ./b. 
	.pre. chmod 755 MyProject.txt ./pre.

    ./li. .li.  .b. .i. The script behaves according to its name extension ./i. ./b.
    The script will produce HTML-formatted documentation, if its name ends with "weave" 
    (default - or whatever you selected when setting configuration variables in the "mollification"
    template). Invoked under any different name (default) it will "tangle", i.e. create machine code.
    So,  name or rename your LSFile "MyProject.weave" and link it to "MyProject.tangle" (or whatever):
    .pre.
	mv MyProject.txt MyProject.weave
	ln -s MyProject.weave MyProject.tangle ./pre.

    Now if you run MyProject.weave, it will dump HTML-formatted documentation of your work to STDOUT
	.pre. ./MyProject.weave > MyProject-formatted.foldingdocument.html ./pre.
    It you run MyProject.tangle, it will dump machine code from your Literate Source file to STDOUT.
	.pre. ./MyProject.tangle > MyProject-runnable.script.pl ./pre.
    ( Of course, tangling is independent of the language you program in )

    For example, if you develop in perl, you can run the resulting script like this:
	.pre. ./MyProject.tangle | perl [perl options here] - ./pre.

    Additionally, as the markup is the same as that of "noweb" tools. one can use them directly
    on the My.Project.weave file, with all of their flexibility and extra options.

    However the idea was even to avoid running some of these commands after each change in
    the file and to avoid saving the weaved docs: STDOUT can be picked up by your local web
    server as CGI, and you will have an HTML-formatted and which is more important, .i. folding ./i.
    document in your browser by simply reloading the page (usually with Ctrt+R or a mouse click)

    ./li. .li. Now, .b. .i.  the only other step  is to run a local web server ./i. ./b. 
    (on localhost, any tiny very simple httpd will do), and tell it to treat "*.weave" as valid cgi 
    file extension. (Alternatively, I can set "weaving" to files that end in '*.cgi" or "*.pl" etc. 
    in the configuration part of my MOLLY template)

    One of the simplest WWW servers for such use could be "thttpd", and I will provide you with its
    minimal configuration file below.
    ./li. ./ol.



#------------------------------------------------
.h4. "Mollification" - full configuration template ./h4.
#------------------------------------------------
Should be self-explanatory. May add to this section later.
Uncomment to set, otherwise defaults apply.


<<full MOLLY template>>=
#!/usr/bin/perl

#-------------------------------------
# -------TOC and INDEX behaviour------

# print TOC? 1:0
#$print_toc=1;	# default is to print

# should we keep TOC expanded? "block":"none"
#$toc_expanded="block";	# default is to unfold

# should we keep Chunks Index expanded? "block":"none"
#$ind_expanded="none";	# default is to keep folded


# should we number lines in code sections? 1 : else
#$line_numbering = 1;	# default is to number


#-------------------------------------
#---------MathML options--------------

# should we enable MathML via ASCIIMathML.js or LaTeXMathML.js library? 1:0
#$enable_ASCIIMathML = 0; #default is to disable as it slows Molly down a lot
#$enable_ASCIIMathML = 1;

# If yes, what is the full path to the lib? Remember to get the one with proper
# escapes for your work, default or modified (see documenation)
# CAN BE: (a) local "/full/path/from/root/to/ASCIIMathML_with_modified_escapes.js" or 
# (b) in current dir "ASCIIMathML_with_modified_escapes.js" or
# (c) on the web, e.g. the original site of the library (unmodified) is:
#$path_to_ASCIIMathML = "http://www1.chapman.edu/~jipsen/mathml/ASCIIMathML.js";
#$path_to_ASCIIMathML = "ASCIIMathML_with_modified_escapes.js"; # default is current dir


#-------------------------------------
#--------Document Markup lang---------

# how are doc sections marked? "dotHTML":"rawHTML"
#$weave_markup = "rawHTML"; # default is "rawHTML"


#--------------------------------------
#---------File extensions setting------
 
# what is the file extention to weave it? (perms must allow execution!)
# e.g. "scriptname.weave" or "scriptname.cgi" etc.
#$weave_extension = "weave";	# default is "weave"

# what is the file extention to tangle it? (perms must allow execution!)
# e.g. "scriptname.tangle",  "scriptname.pl" etc.
#$tangle_extension = "tangle";	# default is "tangle"

#--------------------------------------
#---------invocation of MOLLY.pl-------

# make sure to provide correct and full path to the script here
# (default is "current directory"):
do "MOLLY.pl";
exit;

# delete the space before the __DATA__ marker
 __DATA__
#---------------start of script-------------

<h1> MY PROJECT </h1>

The main idea for my new project is ..

<h2> Subsection 1 </h2>

Here I explain things that come first
................................

@

.b. "__DATA__" must start at the first position in its line ./b.




#---------------------------------------------------
.h4. Markup of code and documentation sections ./h4.
#----------------------------------------------------

First, 
    .ul. .li.  code sections begin with "< <name of the section> >="
    in the first position in the line and end with "@"  in the first position
    .i. no spaces between the double angle brackets - I used spaces as escapes here ./i.
    
    ./li. .li. References to other code sections are done with "< <name of the ref sect> >"
    inside the code sections

    ./li. .li. The rest is "documentation chunks" which must be marked up with some formatting
    tags.

     I do not insert examples here, as the file you are reading provides them ad nauseam.
     

    THIS IS THE BASIC MARKUP OF THE LITERATE SOURCE FILE, as used by the 
    "noweb" tools.
    ./ul.


    Secondly, how do we format the documentation sections?

    .ul. .li. In the simplest case, with straight HTML markup (default)

    ./li. .li. If a simple subsection is added to the MOLLY.pl script to process it, in any
    markup lingo of your choice (e.g. "wiki") 
    
    Currently I provide a "dotHTML" formatting subsection as an example. It implements
    a few of the most common HTML tags but with "dots" around them, in place of angle brackets 
    "<" and ">" (which is faster, as one does not need to switch register, so is less prone 
    to typos). See below for more detailed explanations
    ./li. ./ul.
    
    .b. .i. The only difference ./i. ./b. from the truly "raw" HTML is that except in "pre" sections the MOLLY.pl script will 
    add automatic <br> tags at the end of each line of your Literate Source file.



#--------------------------------
.h4. Tangling from LSFile ./h4.
#--------------------------------

    .ol. .li. Usually only one file needs to be tangled constantly, the file the developer
    is working on.  It's easiest to do by using the "default root", which is a code chunk
    called "*". When you run 
    .pre. MyProject.tangle > source.pl ./pre. 
    MOLLY will pass the command to "notangle" from Ramsey's "noweb" tools, and print code
    chunks starting from the one named "*". Therefore, I drag along the default root to
    wherever I am editing now and reassigning to it the chunk I need to tangle currently.
    I usually keep the pointer subsection at the top of the Literate Source file. See 
    "THE CHUNK TO TANGLE BY DEFAULT" in the file you are reading as an example of this
    technique.

    This is the task for which MOLLY quick "pass-through tangling" is designed.

    ./li. .li. If, however, you need to tangle out non-"*" root, you might need to run
    "notangle" directly on your MyProject.weave. This is the most flexible way.

    ./li. .li. If you need to tangle out many source files, then probably the easiest way
    to arrange it is through many invocations of "notangle" in a makefile.
    Include "Makefile" subsection into your Literate Source file and create a target that
    combines several "notangle -R ... " commands in it.
    Assing default root "*" to the Makefile, then run "MyProject.tangle > Makefile" to create
    it and next run "make targetname" to tangle (and compile, run etc) many files included
    into your Literate Source project file.
    ./li. ./ol.

.br.

#------------------------------------------------
.h4. Sample minimal configuration of thttpd ./h4.
#------------------------------------------------

"THTTPD" home is .a. http://www.acme.com/software/thttpd/ ./a. 

From the distro README:
.ul. thttpd is a simple, small, portable, fast, and secure HTTP server. 
.b. Simple: ./b. It handles only the minimum necessary to implement HTTP/1.1. Well, maybe a 
little more than the minimum. 
.b. Small: ./b.  See the comparison chart. It also has a very small run-time size, since it 
does not fork and is very careful about memory allocation. 
.b. Portable: ./b.  It compiles cleanly on most any Unix-like OS, specifically including FreeBSD, 
SunOS 4, Solaris 2, BSD/OS, Linux, OSF. 
.b. Fast:  ./b.  In typical use it's about as fast as the best full-featured servers (Apache, 
NCSA, Netscape). Under extreme load it's much faster. 
.b. Secure: ./b.  It goes to great lengths to protect the web server machine against attacks and 
breakins from other sites. 

It also has one extremely useful feature (URL-traffic-based throttling) that no other server 
currently has. Plus, it supports IPv6 out of the box, no patching required.
./ul.

Its compilation is very quick. Its configuration is simpler than that of Apache. 

Supposing I'd like to point my browser at "http://localhost:8000/path/to/MyProject.weave"
Then the minimal configuration will look something like this:


<<minimal thttpd configuration>>=
#
host=localhost
port=8000
dir=/my/home/00trash/tmp/literate.perl/WORKDIR
data_dir=/my/home/00trash/tmp/literate.perl/WORKDIR
#chroot

# extensions understood as valid "cgi" scripts:
#cgipat=/**.cgi|/**.weave|/**.pl
#cgipat=/**.tangle
cgipat=/**.weave

#logfile=/my/home/00trash/tmp/literate.perl/WWW.server/thttpd.log
logfile=/dev/null

#pidfile=./thttpd.pid
pidfile=/home/vedmed/00trash/tmp/literate.perl/WWW.server/thttpd.pid

# uncomment this to be able to link from anywhere to your web server document dir 
# (unsecure, for local development only)
nosymlink
#
@
.b. NOTE ./b. that "nosymlink" schizophrenically .i. allows ./i. symbolic links in spite of what
thttpd documentation tells you

The script to start thttpd (it will detach and run as a daemon) is something like this:

<<run.thttpd.sh>>=
#!/bin/sh
PROJECT_ADMIN_DIR="/my/home/00trash/tmp/literate.perl/WWW.server";
#./thttpd -p 8000 -h localhost -C ./thttpd.config
#$PROJECT_ADMIN_DIR/thttpd -nos -C $PROJECT_ADMIN_DIR/thttpd.config
$PROJECT_ADMIN_DIR/thttpd -C $PROJECT_ADMIN_DIR/thttpd.config
@

}}}3

#-----------------------------------------------------------------------
{{{3 .h3. CREATE a Literate Source file -- markup of documentation chunks ./h3.
#-------------------------------

#-----------------------
.h4. Markup ./h4. 
#-----------------------

.ol. .li. The default is to use .b. ordinary 'html' markup ./b. in the document sections
The only difference from "true raw" HTML is that MOLLY adds automatic 
<br> linebreaks unless lines are inside the <pre>..</pre> sections
The script also cuts out vim folding marks -- { { { number ... } } } number
-- without spaces  and "#------------" lines.


./li. .li. .b. Any "markdown" or "wiki"-style markup can be added ./b. to MOLLY. Another 
reasonable suggestion could be a simple translator from basic TeX markup etc.
Some of this functionality is unnecessary to reimplement, as "noweb" or third-party 
filters can be run on the document after MOLLY weaving or from inside MOLLY.

./li. .li. As an .b. example of a simple markup ./b. which can be done with regular expressions
I added  "dotHTML", which is several most basic HTML tags inside "dots" instead
of angle brackets.

Dots do not require switcing the keyboard register, and therefore I can speed up
typing and avoid annoying repeating typos.

Please see the "dotHTML" subsection below where the source of MOLLY is listed.

Currently implemented tags are (write them inside "dots", not "<..>"):
.ul. <br> <p>  <s> - </s> <pre> - .. <b> - </b> <i> - .. <ul> - .. <ol> - ..
<li> - ..

Special marks are dot-<-dot and dot->-dot (no dashes, like ". < ." 
without spaces) which are needed if the tag includes some options or
is not among the tags "dotHTML" understands already.
These will be converted to single < and > respectively.
This is clumsy, but for quick sample and to speed up typing I found
it sufficient. So far.


And there are three special, non-HTML marks I introduced for convenience.
(a) dot-x-dot ... dot-/x-dot .i.on one line only ./i. will .x. format the phrase ./x. as spaced
(b) dot-a-dot http://some/URL dot-/a-dot will create a hyperlink .a. http://some/URL ./a. 
(c) dot-sp-dot - creates a space
./ul.

etc. I add them as I go, whenever I need them for my current document.

This formatting also adds <br> linebreaks unless lines are inside the 
<pre>..</pre> sections.
"dotHTML" also cuts out vim folding marks 
.pre. { { { number ... } } } number ./pre.
without spaces, and  comment lines with dashes
.pre. "#------------" ./pre.


./li. ./ol.


#------------------------------
.h4. Markup and Escaping ./h4.
#------------------------------

Escaping in files marked in multiple ways is a big source of all kinds of errors.
Currently Molly should be able to take care of most cases.

Exceptions include:

1.  double angle brackets ("< <" and "> >" without spaces in between) and the "at" sign.
Those confuse the "notangle" tool from Ramsey's "noweb". While Molly treats
double angle brackets and "at" as a switch between documentation and a code chunk .i. only
if those are in the first position in the line ./i., "noweb" stumbles.

If you tangle through Molly (by running "my_project.tangle > source.code"), Molly will
filter these out. If you run "notangle" directly on the project file ("notangle -R'some 
root chunk' my_project.weave > source.code"), it will fail.

Therefore in this file I always .b. use extra white space btw angle brackets as an escape ./b.

2. If you enabled the use of ASCIIMathML.js library to display mathematical exressions in
you document, then .b. double backticks ./b. on both sides of any expression will be 
processed by the library. (It also processes everything between "a m a t h" and
"e n d a m a t h" tags - no spaces btw letters - in you file).
Make sure that your target programming language or any future "markdown" you are going to 
add to Molly does not use these signs at all -- or re-edit the javascript library to
substitute all inclusions of double backticks to sth else.

}}}3

#------------------------------------------------------------------------------
{{{3 .h3. Mathematical Formulae - MathML inside Mollified Literate source files ./h3.
#------------------------------------------------------------------------------

.i. The most common reason users put forward for the continued use of (La)TeX in this day 
is its facility in dealing with mathematical notation. However today much .b. simpler HTML ./b. 
(which is often further reduced to "markdown" level) if .b. used with MathML ./b. can cover 
most of such needs./i.

There are two libraries in JavaScript, ASCIIMathML.js and LaTeXMathML.js (derived from the former)
which do translation "on the fly" in the reader's browser. Those provide almost a drop-in 
functionality and can be used with Molly.

The latest version of the library (2.0.1) includes .b. .i. both ./i. ./b. ASCII and LaTex processing
into its code. 



#----------------------------------------
{{{4 .h4. How to use ASCIIMathML.js in Molly ./h4.
#----------------------------------------

.b. 1 ./b.. To enable MathML one needs to use a compliant browser. Currently MathML is built in
Firefox, or it can be enabled in Internet Explorer with a (free) plugin.

For Opera the support is also built-in, however the library actually checks for the browser type
and then it seems disallows Opera. The Opera browser, however, has another feature to bypass
exactly that and lie about its identity. If "identify as Firefox" is set in your Opera browser,
the MathML output is caught and rendered.
I did not see any difference between Firefox and Opera_pretending_to_be_Firefox in rendering
output of the library.

.b. 2 ./b.. To enable MathML while dynamically creating the folding-html file, I use an LGPLed
Javascript library called "ASCIIMathML.js" from 
.a. http://www1.chapman.edu/~jipsen/mathml/asciimath.html ./a.
(the home page), while only the library itself can be copied from
.a. http://www1.chapman.edu/~jipsen/mathml/ASCIIMathML.js ./a.

.b. 3 ./b.. The use of MathML must be .b. enabled in the "mollifying" template ./b. at the top of your
Literate Project file, and the path to the ASCIIMathML.js added. See the config. 
template subsection above

.b. 4 ./b.. I had to .b. change escape symbols ./b. in the library not to conflict with 
.i. programming symbols ./i. - now it's double backticks instead of single ones -- and 
change config option enabling "preservation of $ and $$"

Therefore a copy of modified library is distributed with the Molly script.
The default location for Molly to work with is in the same directory as the Molly.pl.
Adjust configuration as needed at the top of your script.

If the rest of your file does not conflict with default ASCIIMathML.js escapes, i.e. does not use
$ signs and single backtics, you can point to the original unmodified library and distribute that
one with your work (see detailed explanations below).

.b. 5 ./b.. This javascript library allows a user .b. to type math formulas in simple calculator-
like ASCII notation with LaTeX constants ./b. if needed.

The interpreted parts of the text must be either:

(a) .b. .i. between "a m a t h" ...... "e n d a m a t h" tags (no brackets). ./i. ./b. The script
then tries to differentiate between ordinary text and math expressions and renders the latter
dynamically as MathML - which is then displayed by your browser.

It might get confused etc. (e.g. because you used underscores somewhere); then your math
could be

(b) .i. .b. escaped (the math expressions only) with DOUBLE BACKTICKS around them. ./b. ./i.

}}}4

#----------------------------------
{{{4 .h4. 6 . Some examples and LaTexMathML.js library versions ./h4. 
#----------------------------------


..are quite intuitive:

Let's try some interesting formulas: 
E=m c^2 ---> ``E=m c^2`` and e^(i pi)=-1 ---> ``e^(i pi)=-1``

and AA x in CC (sin^2x+cos^2x=1) ---> ``AA x in CC (sin^2x+cos^2x=1)``
and one more: sum_(i=1)^n i^3=((n(n+1))/2)^2 ---> ``sum_(i=1)^n i^3=((n(n+1))/2)^2``




..and here are .b. more realistic math expressions ./b. taken from a depository of some math 
    student and written in TeX notation. I drop $$ .. $$ wrapping the in-lined expressions 
    though and delimit it with double backticks instead. Here's the test:

    Hover your mouse over the expression to see the ASCII/TeX coding:

Freudental Formula
``mult(\xi)=\frac{2}{(\mu+\rho|\mu+\rho)-(\xi+\rho|\xi+\rho)}\sum_{\alpha\in\Delta^{+}} mult(\alpha) \sum_{k=1}^{\infty}mult(\xi+k\alpha)(\xi+k\alpha|\alpha)``
It includes roots ``\Delta=\left\{k\delta+\alpha|k\in Z,\; \alpha\in \Delta_0\right\}``
positive roots ``\Delta^{+}=\{k\delta+\alpha|k\geq 0,\; \alpha\in \Delta_0^{+}\}\cup \{k\delta+\alpha|k\geq 1,\; \alpha\in \Delta_0\setminus \Delta_0^{+}\}``

.i. NOTE ./i. If you hover with your mouse over some interpreted expression, a baloon
will appear showing the original ASCII markup for the expression. Very nice.

.i. NOTE 2 ./i. the "pre" (preformat) "/pre" HTML tags prevent the library from
rendering the expressions and might even be used as a quick escape tool when you are writing
your page.



.b. Some TeX operators are not understood by ASCIIMathML.js nor by LaTeXMathML.js libs ./b.
(the failing test is in the ADD-ON MAthML subsection of the Source Code section in this document)

The reason is most likely that the lib was never told about those 1 or 2 constants and
operators on which it fails

.b. First ./b. one can explore another version of the library, "LaTexMathML.js" changed to 
interpret  the actual LaTex code:
.a. http://www.maths.nottingham.ac.uk/personal/drw/lm.html ./a.

One more version is here:
.a. http://math.etsu.edu/LaTeXMathML/ ./a.

One more version (related) of LaTexMathML.js is here:
.a. http://pillars.che.pitt.edu/LaTeXMathML/ ./a.
.a. http://pillars.che.pitt.edu/LaTeXMathML/latexmathmlguide.xhtml ./a.

.. and there is even a perl port for that
.a. http://pillars.che.pitt.edu/LaTeXMathML/ ./a.
(which also can potentially be used from MOLLY)


I have not tested those in full, but the use of JavaScript libraries from MOLLY should be
identical (and so it says in the documentation inside the libraries) to that of ASCIIMathML.js
They are directly interchangeable in a standalone HTML-based editor. Just point to a copy of the 
needed lib in the configuration section of your Literate Source file.

.b. Secondly ./b. the home page for the library mentions (at the very bottom) that the library
encoding in its JavaScript source file is straightforward and more translations can be added
as needed.
Here is the URL: .a. http://www1.chapman.edu/~jipsen/mathml/asciimathextend.html ./a.
I will provide a section in the Literater Source of Molly (in the ADD-ON section for MathML) 
to add all necessary definitions. It .b. .i. is ./i. ./b. very easy ;))

.b. Thirdly ./b. the general lesson/answer to the question of using math in your Mollified Literate
Source files is this: 
.ul. .li. I had to adjust the lib (double backticks and preservation of $) because I was concerned
with programming languages. The source code must stay untouched by the math library 
(mis)translations. That is why I provide a copy of the lib with MOLLY.

./li. .li. If one wishes to use MOLLY for writing mathematical notation without conflicting computer\
language code sections, one can always .b. link to an unmodified copy of the same lib ./b.
and distribute that one with your work ( in *.mht files, see below) or even link to an 
address on the web.

./li. .li.The same applies to a version of the lib to interpret TeX rather than ASCII math notation: 
MOLLY inclusion of the library is generic, just point to the correct javascript library.
./li. ./ul.

}}}4

#--------------------------------------------------
{{{4 .h4. 7 .  ASCIIMathML Markup - reference ./h4.
#--------------------------------------------------

The full set of ASCII notation conventions for the library can be found on its
home page.
.a. http://www1.chapman.edu/~jipsen/mathml/asciimathsyntax.html ./a.

There are 2 pages there, the first describes the syntax, and the second one shows allowed 
LaTex escapes.

The easiest way to see the ascii code and to use any interpreted page as a reference is to
hover your mouse over an interpreted math symbol or expression. In about a second a baloon 
appears  with the ascii source in it.

There is an on-line tutorial in the use of ASCII math notation  for the library at
.a. http://www.wjagray.co.uk/maths/ASCIIMathTutorial.html ./a.
and .a. http://www.wjagray.co.uk/maths/ASCIIMathMLinfo.html ./a.

.b. One more URL ./b.
"an on-line ASCIIMathEditor" is here
.a. http://www1.chapman.edu/~jipsen/mathml/asciimatheditor/ ./a.
Works in my case (firefox on Linux) if I save the page ("full page") and use it from
local files. Could immediately see what I am typing, next copy and paste expressions
into my target file.
Useful. Just delete the spy from google, "the urchin tracker" from the page ;)) .

}}}4

#----------------------------------------------------------------
{{{4 .h4. How to distribute your final folding HTML-formatted work ./h4.
#----------------------------------------------------------------

.b. 8 . To distribute your HTML-weaved folding files with MathML notation ./b.
afterwards you'll have to provide a copy of the JavaScript library with the weaved html 
file, as well as any images you might have used there.
This can be done by creating .b. *.mht archives ./b. from them.

(to explain: MHT is a base64-encoded concatenation of elements of a page
    and its images, scripts etc.;
    MAF is a Mozilla zip-comression of page or several with all images etc into one
    archive file).

Note that because I had to modify escapes in the library for it not to clobber single 
backticks and $ symbols, so common in programming, one has to provide a copy of the 
modified lib with your HTML work.  You cannot simply link to any copy ot ASCIIMathML.js 
found on the Net. (You could if you use an unmodified copy though).

Internet Explorer has built-in support for *.mht (as it is a MSoft standard).
For Firefox the problem is solved easily by installing either
"UnMHT" add-on: .a. http://www.unmht.org/unmht/en_index.html ./a.
or "MAF" add-on: .a. http://maf.mozdev.org/ ./a.

Then just open the weaved html file in your browser, and "Save As" *.MHT, it will 
include all images and the library with it.

So: (a) weave an HTML file from Molly
    (b) open it in IE or Firefox with MHT add-on, and 
    (c) save it as one file.

This will allow you to distribute your MathML marked files with included images, plots
etc. in a convenient manner.
If you are strictly Firefox-based, you can also use the open zip-based MAF format.


}}}4

}}}3

#-------------------------------------------------------------------------------
{{{3 .h3. READ and SEARCH inside a Folding Literate Source file ./h3.
#------------------------------------------------------



#----------------------------------------------------------------------
.h4. Opening many relevant subsections together, TOC highlighting ./h4.
#----------------------------------------------------------------------

One advantage of the folding format is that - in contrast to most other tools - it allows
    the programmer to open .i. many ./i. relevant sections from any parts of the file .i. at the 
    same time ./i.

    This can be done by "walking" the Literate Source file, as its sections and subsections are a 
    kind of TOC of themselves.
    This can be done from the TOC section as well. The open sections get a highlighted background,
    and highlighting appears irrespective of whether the section was opened from the TOC or in the
    body of the text.



#--------------------------------------------------------------
.h4. Keeping some sections of the LSFile permanently open ./h4.
#--------------------------------------------------------------

The behaviour of folding sections in the mollified LSFile is as follows:
    .ul. .li. If you click on the .b. "expand all" ./b. link anywhere in the document, all folding 
    sections in the body (not TOC/Index) will open. The limitation is 10000 objects per document,
    hardcoded.
    ./li. .li. If you click on .b. "collapse all" ./b., all folding sections in the body will fold. 
    The limit is 10k objects per document
    ./li. .li. If you .b. reload the document ./b. in your browser ("Ctrl-R" or an icon click), the
    document will be shown with sections open or closed .b. as marked ./b. in the document itself.
    ./li. ./ul.

    The markup is simple: if you'd like a section to stay open upon load/reload,  add a "+" before
    "h" in the opening  heading tag:
    .pre. <+h1>, or <+h2>, ... ./pre.

    This is important when you work on a section or many sections of your LIterate Source file for
    a longer period and could not click them open in teh browser time and time again, after each 
    minor code change when you reload the "project.weave" in your browser to see the updates.

    Such changes - adding or deleting a "+" - can often be done with one command in a programming editor.
    For example, to open the whole subthread in vim, issue a range command, sth like
    .pre. 1024,1150s/<h/<+h/ ./pre. (i.e. substitute between lines 1024 and 1150 of your Literate Source file)

    Another suggestion is, when you, for example, work with several program files inside your LIterate
    Source (project) file, you might keep subthreads marked open, while changing only the topmost 
    heading to show/hide the whole of that file/subthread code and notes.

    Even when you handpick the sections to keep open, I found, this arrangement suits me well, at least
    for medium-sized LSFiles up to several thousand lines long.
    I also use folding inside "vim", and so line ranges are visible at one glance: "z-a" to collapse the
    vim fold, and then see the range and issue the range command.

    .i. Note ./i. 
	.ul. Use of folding inside your programming editor .x. is not a substitute ./x. for reading 
	a well-laid out formatted document in the browser. Vim folding is still "blind" and  navigation
	inside such a file still has to rely on your memory of the full layout. This is a burden one 
	wishes to escape when programming, to be able to dedicate attention to thinking and
	programming while avoiding unnecessary "housekeeping" tasks. Short-term memory of humans
	is very small, and switching between remembering where things are and doing programming
	becomes exhausting when your program exceeds a thousand lines or so.

	MOLLY numbers lines in the code sections by default, making jumps from reading in your browser
	to editing a particular line in your editor painless. I could also put it like this: I view
	the file globally in my browser as a folding document when I am thinking, while editing 
	"locally" in a programming editor, without thinking about the overall layout of the file.

	./ul.

    MOLLY.pl is written to filter out vim folding markups ( {{{number ... }}}number ) and those 
    will not show on your web page.




#------------------------------------
.h4. TOC and Code Chunks Index ./h4.
#------------------------------------

Traditional literate programming tools create extensive indeces of variables and code chunks.

    The approach in this script is as follows:

    Index of all code chunks in your LSFile exists (unless a configuration opton in the 
    template tells MOLLY to skip it) right under TOC. Click on teh line to expand it, and then use
    TOC section numbers to click open the sections which contain or define the chunks you need.

    Remember that .i. all parent sections ./i. above the needed one must be open for you to see 
    the innermost subsection in your browser. This is easy to control through TOC highlighting, and
    as an additional indicator, the slider on your web browser will visibly jerk and shorten when 
    new sections will become visible in the browser window.

    It's also convenient to keep some inner subsections open, but click closed the topmost section to
    quickly hide and unhide larger pieces of code (e.g.complete files which live inside the Literate
    Source File when it is used as a common Project file for many source files, test files, makefile(s)
    etc.



#------------------------------------------------
.h4. Searching for symbols, chunks, phrases ./h4.
#------------------------------------------------

Web browsers "search" functions  will work on open sections only, at least that's the behaviour of
    Opera and Mozilla browsers.
    This means that instead of creating exhaustive indeces of symbols, which clutter program text, 
    especially when they display as HTML links in the output of Weaver tools, one can ensure only the
    interesting subsections are open and then search using the built-in browser function. It usually
    highlights the results and iterates over the found items, which is a nice behaviour.

    To search in the whole of the LSFile, simply click on the "expand all" under any of the subsections,
    and then again use the browser search function.



#--------------------------------------------
.h4. TOC/Index unfolding and collapsing ./h4.
#--------------------------------------------

    The TOC and Index at the top of the document can be kept folded or expanded upon initial load
    depending on the configuration variables in the "mollifying" template you add at the top of 
    your Literate Project file. Please see the subsection titled '"Mollification" - full template' above
    Of course, those subsections can always be opened/closed manually at any time

#--------------------------
.h4. Use for printing ./h4.
#--------------------------

Unfolding only the needed sections also seems to work well with printing from the browser window.
    You can therefore avoid picking certain pages manually from "print preview". You'll print only
    the visible part(s) - i.e. the open sections and the topmost folded section names, which do not
    take place if your document is marked in a sane way, and rather help the reader to orient himself
    while looking at the printout.

    Just remember to check the font size in the "print preview" when preparing to print for the first 
    time.



#--------------------------------------
.h4. Text browsers and JavaScript ./h4.
#--------------------------------------

Web page folding seems to work well with text-only www browsers, such as  "lynx" or 'w3m': they do not 
understand javascript folding, and so display the whole document.

Here's an example invocation with w3m:
.pre.  ./MOLLY.weave | w3m -T text/html  ./pre.
.i. Note ./i.MOLLY does not issue HTTP headers, and this may affect browser behaviour. The web server
 and/or browser may add them or not, or ignore them or not. I might need to correct that.

If JavaScript in your GUI browser is turned off, you'll see only the sections marked in the body
of the Literate Source file as open.


}}}3

#------------------------------------------------------------------------------------------
{{{3 .h3. SUGGESTED USES: Work with Folding LSFiles./h3.
#-----------------------------------------------------------
.i. .b.  section unfinished; an outline of major points for now ./b. ./i.

I do not show examples below, as the document you are reading itself is an example of the
techniques (and that may be the reason it is too bloated and somewhat unorderly ;)) ).

.ol. .li. Literate Programming proper.

    Emphasis on note-taking rather than producing a polished "essay" or "documentation"
	
    Traditional Literate Programming texts place much emphasis on the fact that it is a means of 
    providing .i. documentation ./i. (albeit with source code, and reflecting the thinking rather
    than machine-imposed order).
    Knuth first thought of LP as a documentation tool, then upgraded it to a "programming paradigm",
    but insisted on writing programs "like literary essays".

    However I would like to suggest placing emphasis on NOT documenting and NOT producing 
    polished code or an essay in thinking. The first use of this programming technique is 
    to  .i. keep a full log of your thinking ./i. irrespective of how polished or stupid it is.

    This is most precious. When you first attack a problem, several directions might come to mind,
    but once you began to work out one of then in detail, everything else is lost. This is the
    way human mind works. Keeping even briefest notes is more valuable than attempting to produce
    polished exposition.

    Psychological restrain people feel when they are compelled to prepare something for other people
    is probably the third major hurdle to wide spreading of L.P. (the first two were flat file 
    structure and formatting languages which doubled the effort of programming and debugging).

    My MOLLY Literate Source file is a log of my thinking, trials and experiments. I might later offer
    a cleaned version to other people, but I do not give a damn about them in the beginning.

    Non-folding L.P. source files could not accomodate inclusion of old versions, test files, bad
    versions and skeletons without polutting the file to the degree of becoming unusable.

    Folding version of L.P. source allows one to relegate bad trials into subsections  nicely folded
    out of the way by merely adding a single header line.

    When creating documentation, I could double the content of some sections, by copy-pasting the
    "cleaned" versions, and then save a version with the original snippets bypassed, which is
    easy and mechanical with tools like "gema", "awk" or "perl", just put a code word like
    "scrap" in the beginning and end of those sections you'd like to avoid.

    This ability to bypass marked sections when weaving, by the way, might be incorporated as an
    option into a future version of MOLLY, to produce both 'clean' and 'dirty' versions of the
   formatted Literate Source doc from one file.

./li. .li. Use as a combined Project file
    .ul. .li. to include tests and snippets that implement skeleton functionality to
    be embedded into the main program
    ./li. .li. to include versioning and changes in the way  that does not break what
    has been working so far (there was even a special term for that as a programming 
    principle). Keep the old version, put it into a subsection, and rename the chunk
    to bypass it. The newer version of the piece of code that is being reworked will
    get the old chunk name to be included into the chain to tangle out.
    ./li. .li. To keep a makefile (split, to which I can add lines from many places in
    my Literate Source as I grow it) together with source file(s)
    ./li. .li. To keep several source files related logically in teh same Literate Source file.
    ./li. ./ul.

    .i. Folding meta-files ./i. could be used for larger projects, in which 
    the meta-file, a folding document, would describe teh topmost level layout of the 
    project, and contain ordinary HTML links to partial Folding Literate Sourcefiles, which
    will keep all the junk as described above.

    In any case, the use of Folding Literate Source files would considerably simplify tracking
    of the project files in a version control system.

./li. .li. Use for system administration etc. - as a single file to keep many sysadmin scripts, 
    descriptions of conventions and procedures, bugs and changes in the system .b. .i. in one place ./i. ./b.
    from which any of the included source (or texts, if they are kept in the "source chunks") 
    can be obtained easily with a single command.
    ALSO: combine LIterate Source project file with a makefile as a simple means to keep 
    one-command tangling of multiple targets.

    This Literate Source can live in a central place (e.g. root home) and be under version control.
    The tangled pieces, config files or scripts could be copied to files on one or many machines.

./li. .li. Use for non-programming tasks:
    .ul. .li. as a note-keeper. E.g. I kept job listings and followi-up info in a folding
   MOLLY file and found it quite convenient. 
    ./li. .li. as an outliner for general purpose texts.
    ./li. .li. for keeping documentation, books etc. I keep documentation for a number of
    software tools (e.g. "awk", "newlisp", "monotone") in folding format. It .i. is ./i. helpful.
    ./li. .li. for editorial work on larger texts. The text itself will become "code chunks", 
    and editorial remarks and meta-thinking will remain as "documentation" in a Literate 
    Source file.
    ./li. ./ul.

./li. ./ol.


.h4. scrap ./h4.
(a) //CGI and CL invocations - compared to "noweb"
    // dotHTML tagging; alternative tagging, translations
    // alternative tanglers and pass-through tangler; makefile problem

(b) ideas - how to incorporate tests; how to keep a single project file;
how to set up dummy plugs and alternatives (i.e. to develop without destroying
the old working version)
Maybe: for distribution of a lot of small scripts (admin etc), the  way I used
Makefiles?

(c) It's possible even to do development in smallest chunks -- and later (e.g. for
outside clients or for higher-level documentation, etc.) to consolidate the tiny fractured 
bits and pieces, with plenty of alternatives, dummies, plugs and trials etc. etc.
How? - by tangling those from some certain level and copy-pasting the result into the
Literate Project File.
One could even keep the actual development fractions in a subsection, while retaining
higher-level and cleaner view in higher level sections. I do not care about doubling the
text at all.

.b.suggestion from a Slashdot 2002 discussion ./b.(see ref above) about style or approach:
do not document what the code does (which is redundant, as can be seen from the code itself),
document rather WHY it does it (what's the purpose or the idea).

.b. Also ./b. use this file itself as an example of all illustrated techniques.

Use .b."mollify"./b. as  a technical term (insert MOLLY.pl invocation into the LitProject file)

}}}3

}}}2


#------------------------------------------------------------------
{{{2 .h2. PART III ------------ LITERATE SOURCE OF THE SCRIPT ------------ ./h2.
#-------------------------------------------------------


#----------------------------------------
{{{3 .h3. Local Reference ./h3.
#--------------------------------

.b. VIM regexp to highlight literate code sections only: ./b.
.i. HAD TO spoil it because "notangle" complained about double diamonds 
"in documentation chunk", bastard ./i.
.pre. ^< <.*> >=\_.\{-1,}\n^@/e ./pre.
.. and vice versa, highlight text, leave only code unhighlighted:
.pre. ^@\_.\{-1,}\n^< <.*> >=/e ./pre.





}}}3



#----------------------------------------------
{{{3 .h3. Bugs, status, changes ./h3.
#----------------------------------------------

#-------------------------------
{{{4 .h4. versions - changes - ideas ./h4.
#-------------------------------

Current version:
.ul.
    .li. creates folding documents on the fly..
    ./li..li. ..based on dotHTML or rawHTML markup 
    (i.e. either to create new docs or convert existing HTML into folding format);
    ./li..li. and generates dynamically TOC and code chunks index;
    ./li..li. ties collapsing/expandind of sections with TOC highlighting;
    ./li..li. .. and provides pass-through tangling with "noweb".
    ./li../ul.

    This script is a test of the concept (LitProg+folding+dynamic web formatting)


#--------------------------------
{{{5 .h5. first ideas ./h5.
#--------------------------------
    

    Options for future versions --  3 ideas for now:
    .ul.
    .li. add a built-in tangler (while retaining the possibility to tangle
    through an external tool, such as "notangle" with all its options and filters).

    ./li..li. .x.create a fully self-contained./x. folding web-based .x.weaver./x.
    ("Lilit") (plus possibly a built-in tangler).
    This can be done in newlisp (www.newlisp.org), which has a built-in httpd
    and allows creation of 250k+(size of script) standalone executables on all
    major platforms (unix/linux, windows mac).

    ./li..li. maybe - .x.add "views" (a la Leo views)./x. and maybe editing of single
    subsections (in a pop-up term window with a running editor).
    This - as I see it now - may/will involve storing each subsection in its 
    own little file and dynamically concatenating them both for dynamic weaving
    and for tangling ( keep a third name, some "scriptname.src" for dumping the
    full file to STDOUT?? )
    This can be done dynamically: a huge project file will be displayed fully
    collapsed, and then only the sections marked open will be dumped to the web
    browser dynamically.
    The whole thingy can be kept either as a bunch of section-files in a subdir,
    or (and/or) in a tar file (gzipped or not, indexed or not).

    .b. One possible implementation ./b. is with .a. http://www.wikiwyg.net ./a.
    - the "wikiwyg" library, which can turn any "div" into an editable section.

    The lib as it is distribted does not save (no sub that saves, actually), but
    one can "save in the browser" and next save the page from the browser to a 
    local file

    For a local programming setup ( thttpd on localhost:8000 for example) this
    will do. However one still needs to figure out if there is a possible post-
    processing of the dynamically created (and then saved from the browser) page
    with some script that would strip back the "frameset" decorations and the 
    invocations of folding plus the html head and TOC/chunks index sections.

    I might say, I need the "reverse weaver" (although not as thorough ?)

    .. and, secondly, after post-processing, if there is an invocation op "patch"
    which would apply the diffs back to the Literate SOurce file.

    .ul. .li. Will a "context patch" do? Can I postprocess
    ./li. .li. Can I postprocess the dynamically generated HTML to mimic some
    sort of diff markup (unified? Context? ...)
    ./li. .li. Third, the exact invocation to apply it to an LSF.
    Is manual restoration of this kind possible? Is it poss to run through a GUI
    merge tool? An "apply all left to the right one" automatic tool?
    ./li. .li. This can be presented as buttons on the page (when the wikiwyg
    option is enabled) etc.
    The script then would take another option (your_filename?apply_changes) to
    run this, and fail with a request to do a manual merge if not possible.
    ./li. ./ul.

    Then the question   remains, how practically useful/convenient that is.
    

    .i.How to do it./i.
    /* Basically, to manage sectionfiles I'd have to code as if those are comments
    to a blog entry (and dynamic gathering of them is the same, too. Should be
    rather obvious and possibly quite easy*/
    This 'views_enabled' mode will switch to sect-files in a ./.molly/ and will
    add dynamic links to each section: "edit section" (in an external editor);
    "update Literate Source Project file". And the script will start to check the
    subdir and dynamically reconstruct its HTML output in this mode.
    Same must be true for the "tangler" pre-filter, too - it will reconstruct
    the whole before passing it to the "notangle" utility.

    ./li..li. Is it possible to do .x."promoting/demoting"  of branches??./x.
    Is it possible in the view-enabled weaver?

    ./li..li. .x.add "web tangle mode"./x., in which MOLLY will dump coloured diff
    of the subsections (or the whole file if not too large), of the current version,
    tangled via the browser form versus a file on disk.
    (I do it all the time firing fldiff after each tangle - would be convenient to
    have the functionality before tangling to disk (with file renaming etc), just
    by reloading a page in a browser.
    Will need to allow saving files (or some branch of chunks) from the browser, then.

    Do I underuse .x. Vim ./x. ? - it does have .b. some "diff" mode ./b. for side-to-side
    display. Just open 2 files, current and prev. vers. and toggle btw one-file
    view and edit or side-by-side coloured diff ???

    .i.How to do it./i.
    .. by first (poss) checking that the files are not identical, and then by
    filtering into "diff":
    .pre. MOLLY.tangle|diff -y -w --left-column xxz - |less ./pre.
    Just wrap it into html-body-pre tags and colour if there's something in the 
    right half (not necessary, really)

./li. .li. .b. context diffs and sections editing ./b.   
./li. ./ul.

}}}5



#-----------------------------------
{{{5 .h5. more ideas ./h5.
#-----------------------------------

.b. More ideas: ./b.

.b. 1. Maybe ./b.  have the .x. "composite document" ./x. (or "fragmented document") 
    option for .x. the second-level ./x. meta-management .x. of project files ./x.
    I.e. one project could be split into many file-sections, and MOLLY weaver will 
    assemble them into the doc.
    OR: I maintain logically consistent pieces in medium-size project files, and
    keep a meta-project file with the split option enabled.
    The "edit" links from it will pop up gvim or another editor of choice with
    the full piece in it.
    While viewing will present it all as if one LIterate Source project file.
    I'll need only to mark the pieces in the TOC, possibly, as a separate doc,
    and -- .b. how will I treat TOC compilation then ? ./b.

.b. 2. Maybe ./b. - if I find an ASCII script (ascii art from commands and 
    descriptions), I could automatically generate .x. ascii-art "maps" ./x. 
    of the chunks ??


.b. 3. introduce horizontal/vertical layouts? ./b. 
    I.e. TOC and Chunks Index either on top of the file or on the left of it for
    "wide screens", like those on notebooks ??
    Changes are in  "Print out the resulting page" (currently line 3359)
     - plus options, of course

    Note: will require gluing TOC or the body to stick at the top, not simple table
    cells, which will center and resize depending on relative cell content sizes.
    May require separate scrolling for the two panes?

OR: .b. TOC/Index in a floating window? ./b. -- should be easy, just  name the
    output windows.

.b. 4. Maybe ./b. add ancors to folding section names to be able to 'hyperlink' 
    and refer to them from other parts of the document??
    // no jumps from the TOC? or with a separate 'jump' icon? //
    // no jumps to closed sections will work anyway, then what to do? //

}}}5




#-------------------------------------------
{{{5 .h5.  CONTRACT PROGRAMMING and Molly?? ./h5.
#-------------------------------------------

possibly add conditional tangling to produce a contract-assertion-littereted prog during
development and debugging --
versus a "clean" copy -- ???

.b. OR ./b. just keep an "assertion-full" skeleton  by using a simple "rename" or a 
meta-chunk which is a dispatcher??
.pre. [chunk_to_do_sth]=
 code code code code
 [another_chunk_ref]
 more code more code
 @
./pre.
...NO, I cannot do that without conditional tangling
...or - do it in the target language using a "lazy and" for conditionals:
(and (debug_assert_flag) (block .....with some code.....))

.b. Well, this is what I can do: ./b.
.pre.
< < main code chunk > > =
if ($DEBUG) {
< < pre-chunk assertions and if-checks > >
} # fi DEBUG

# main chunk code goes here

if ($DEBUG) {
< < post-chunk assertions and if-checks >>
} # fi DEBUG
#end of chunk here @
./pre.

Then I'll be able to produce debug code by tangling:
.pre. notangle -R"some root" project.weave ./pre.
and the "clean code" without assertion checks I'll get from it
by simply filtering with
.pre. perl -ne 'print unless m!^if ($DEBUG) {! .. m!^\} # fi DEBUG!' tangled.code \
> clean.distribution.code ./pre.

Should be easy enough ;))

}}}5




#----------------
.h4.Done ./h4.
#----------------

.b. 1. Adding TOC open/collapsed section indication ./b.
Changes must be made in:
"weave me" ==> "JS script functions" && "stylesheet"
// as expl in the ref section below 

AND in
"Accumulate the result" ==> "process section headings"
// the actual invocation "onmousedown"


.b. 2. Synchronize TOC and sections ./b.
I have done highlighting; now two more steps:
    .ul. (a) make body sections run "toggleCombined" rather that directly
    open/close the "div"s/sections - to highlight the TOC at the moment
    of change
    (b) make TOC bg. highlighting recognize the "+" signs in the html headings
    markup.
    ./ul.
This is not difficult, just needs a little attention.

To do (b) NEED to rewrite 
.pre. <div id="$section_num" style="display:$fold_state">  ./pre.
in line appr. 370 to add inline javascript invocation of expandDiv

3. see 8.
Add "pass-through" direct HTML dummy encoder (plus a switch btw rawHTML and dotHTML)
Explain  the user can expand the script in any way he wishes (e.g. with a "wiki" syntax)

(++-)4. I still need to do at least a .b. stub in tangler ./b. to do some pre-filtering before
calling "notangle".
E.g. I might want to reassign the double-< and double-> or other symbols for some esoteric
languages, or filter out escapes from documentation chunks for the notangle not to choke.

NO SWITCH yet to select from pre-tangle filters or built-in tangler.

(++) 8. Weaving -- "dotHTML" versus "rawHTML".
Version MOLLY-0.62-BAD.pl is incorrect. It's "dot" markup is OK, but for "raw" to work 
.i. regexps must be changed ./i. in the main filtering "if - elsif - else", as headers
will too be in angle brackets, not in dots.

.b. May be a good idea to extract those regexps ./b. and assign them to vars, as now
they are coded in, bad.

9. See "accumulate result in a buffer"
Should I make the "----start of script--" line unnecessary (relying on __DAT A__ ) ??
Or =- both? or no "data" (as it throws off editors highlighting) ???
.b. set to react to DATA not "start of script"./b.


.b. Bug with setting default for $print_toc fixed./b. --  must check for "defined", the perl operator
xx?aa:bb checks for 0 or non-0, and so if the var equals 0 it will never set it to 0.
Changed and tested.
Maybe should use "yes" and "no" instead of "1" and "0"?






}}}4


#----------------
{{{4 .h4.Todo -  current./h4.
#----------------

.b.1. Problem of double diamonds in doc chunks ./b.
.ul.
    change the pass-through tangler to isolate the "notangle" from docs sections???
    (will squash the prob of double angle brackets in documentation chunks)

    OR - introduce a sort of escape?? Because sol 1 would clobber correct line numbering??
    But I do not number lines in the default pass-through invocation..
    The standalone will be affected, anyway.

    I could add regex conversion to hexadecimals in the pass-through tangler.
    However it would still break the "notangle" when run standalone.

    I could collect command-line options in case of "scriptname.tangle" invocation
    and pass them to "notangle" - that could be a sort of solution.
./ul.

2. Change logic of "weave-tangle" ("main despatcher"), as it is stupidly convoluted 
and ugly now

3 and 8. (++) rawHTML mode, done

4. (++-) see below in "done"

5. .b. BUG of sorts ./b.
the "lt" and "gt" escapes in the code chunks right above ("tangle me with filtering") are not 
displayed correctly  by the web weaver: the browser displays them as real angle brackets.

6. .s.TMLize the error message in the main despatcher (if "I am a module", print it as
an html file). Otherwise it won't look good in the browser. ./s. 
.b. NOT NEEDED ./b. as "tangling" is done from CL only

7. Add another mode - if file ext is "src" - "scriptname.src" - do not pass to "notangle", but
dump the pre-filtered source to STDOUT.
May be needed in some cases, who knows?? - i.e. to escape special symbols, such as double-<'s 
etc in documentation chunks.
Ordinarily, this is not needed and the file can be processed by "notangle" directly.
This step is needed to tangle some non-default pieces or to use some extra tangling options.

9 (++). DATA or ---start of script-- to filter?? - done

10. Add "expand subthread" ?? - to open only the current branch of the L.T.File?

11. Add auto-href creation (i.e. posting a URL with minimal markup must create a valid
    HTML link with URL as the name of it.

12 (+--). and checking 
qwer qwer .x.spacing./x. of one word and .i..x.of  many  on  the  same line./x../i. asdf asd  
SO: to do word boundaries properly.
DONE although not very cleanly. The tag will break across several lines

13. Add a full set of HTML escapes to "dotHTML" and "rawHTML" ?




}}}4

}}}3



#-------------------------------------------------------------------
{{{3 .h3. PRELIMINARIES: The script layout and idea ./h3.
#-----------------------------------------

.. are very simple.

.b.1. ./b. It is possible to include an invocation of a  perl script with 
.pre. "do script.pl" or "use script.pl"  ./pre.
as the first lines in a Literate Source file.  This turns the source into a standalone perl script. 
If we write the script to process the L.Source file itself ($0 in perl parlance) then the script can do 
weaving and tangling of it. The output, which is formatted documentation (which was "weaved" from L.P.) 
or the sources usable by a computer ("tangled") can be  saved in a file, as with traditional "literate 
programming" tools. But which is more convenient, the formatted documentation can be  picked up by a web  
server, and thus allow us to see work in progress immediately and automatically. 

When I think, I prefer to look at the formatted document, and when I change, I do it "locally" in a good
programming editor (such as "vim"). Even with vim folding the difference in perception is enormous.

.b. 2. ./b.I see three advantages to such an arrangement:  
.ul..li.first, web markup is ubiquitous today, and it is quite sufficient for most publishing needs. 
So Literate Programming with HTML will free us from a tie to TeX which so negatively affected 
perception of L.P. by the masses of programmers. The markup becomes very, very simple. 

This eliminates a source of one major complaint about the traditional L.P. - that the programmer has 
to maintain not one, but two "programming languages" while working with LP, the target one
and the formatting one. This - the complaint goes - becomes a source of errors from an additional layer 
of programming in addition to writing the code itself. It taxes the programmer's mind rather than relieving
it.

In fact, simple HTML is almost self-correcting, as wrong markup becomes immediately obvious in the 
browser. 

./li. .li. secondly, this eliminates "weaving" as a separate step during development, but more
importantly, such an arrangement allows a programmer to think about his program while looking
at a .i.folding./i. document, in which only relevant sections are open.

I perceive .i. folding ./i. as a major advantage

With .i.folding./i. the Literate Source file becomes manageable even for really large texts. This in turn
allows the programmer to keep .i. many files ./i. inside the LPSource, including test snippets, the makefile,
preserve old versions of parts of the source etc. etc.
Literate Source file is painlessely turned into a Project File, one file, from which anything can be
easily generated.
It is this one file that my version control system must track now. For really large projects, we can keep
a meta-file (also in the folding format) with largish partial files as links, corresponding to logical 
pieces of the project, which will open in the browser as automatically weaved Literate Source Files.

I attempted to explain this at length in introductory sections above.
./li../ul.

.b.3. ./b. The script that programs this functionality can assemble all pieces as buffered strings in RAM: today's 
machines routinely contain RAM in Gigabytes, therefore processing in memory a very large source or 
project file  in Megabytes, even in tens of Megabytes is not a problem. 

.b.4. ./b. How the script works overall

After figuring out how it was invoked, the script:
.ul..li. .b.when it is supposed to weave./b., scans into memory the Literate Source file, marked up in "noweb" 
notation (and its document sections marked with raw HTML or in "dotHTML") doing necessary substitutions 
and conversions along the way.
Then the buffered string thus formed and several auxilliary buffers (for document TOC and Index 
sections) are printed out to STDOUT. They can be redirected into files, if LPSource, now also an executable
script itself, is run from command line, or they can be picked up by a local personal web server that is
used by the developer, which  should recognize the LPSource as a valid CGI script

After any changes in the script, the user can reload the page in his web browser and immediately see the
changes.

./li..li. .b.If invoked to tangle./b. the source of the program, this version of the script will refer the 
actual  tangling to the "notangle" utility from "noweb" suite of tools by Ramsey.
./li../ul.
.b.5. ./b. .x. A future version ./x. of the script may be made completely self-contained, i.e. include a mini-web 
server as well as a folding weaver and a tangler.

}}}3


#------------------------------------------------------
{{{3 .h3. MOLLY.pl - top of the script ./h3.
#------------------------------------------------------

<<MOLLY.pl module>>=
#!/usr/bin/perl

#---------------------------------------------------------------------------------    
#
#	This script is licensed under GPL version 3
#
#----------------------Script proper----------------------------------------------


<<general settings>>
<<main despatcher>>
<<tangle me>>
<<weave me>>

# END OF SCRIPT
@


#-------------------------------
{{{4 .h4. general settings ./h4.
#-------------------------------


Some internal script parameters are set here.
E.g. "noweb" tangler gets confused if it finds double angle brackets
anywhere, so sometimes it's possible to fool it by setting a var in the
perl script like this:

<<general settings>>=
  # need to fool the noweb "notangle" utility, switch markup modes etc.
  $lt = "<";
  $gt = ">";
  $lt_esc = "&lt;";
  $gt_esc = "&gt;";
  $dash = "-";
  $dot = "\.";
@

But more importantly:
There are a number of parameters that can be set from the literate source file
at the very top before loading the module with "do MOLLY.pl" (or "use MOLLY.pl").
These are assigned defaults here. You can refer to this portion of the script
to find out what parameters are settable in your document template and expand the
tunings if you modify MOLLY.pl

<<general settings>>=

  # ----- GENERAL settings -----
  
  # am I a module? 1:0
  $i_am_module = 1;

  # print toc? 1:0
  $print_toc = 1 unless defined $print_toc;
    
  # keep TOC expanded on initial load? "block":"none"
  $toc_expanded = $toc_expanded || "block";

  # keep TOC expanded in initial load? "block":"none"
  $ind_expanded = $ind_expanded || "none";
@

The script will behave differently depending on its own name. One "major" name
can be used with others existing as soft links (although an "thttpd" lightweight
web server insisted on a hard link in one case).
The modes are detected by file extensions, which are set here.
'Weaving' = creating a formatted HTML documentation file on STDOUT
'Tangling' = creating the program/script source on STDOUT

<<general settings>>=
  # what is the file extention to weave it? (perms must allow execution!)
  # e.g. "scriptname.weave" or "scriptname.cgi" etc.
  $weave_extension = $weave_extension || "weave";	# default is "weave"

    # what is the file extention to tangle it? (perms must allow execution!)
    # e.g. "scriptname.tangle",  "scriptname.pl" etc.
    $tangle_extension = $tangle_extension || "tangle";	# default is "tangle"



  # tangle? Or run? (perms must allow execution)
  $tangle_me = 1;

      # -- not implemented yet --
      #
      #$run_me = 0;
      # what interpreter to run the tangle output with?
      #$run_me_with="/usr/bin/perl";


# number lines ? 1 : else
$line_numbering = 1;
@

The document sections ("chunks") can be marked with actual HTML tags ("rawHTML") or
with a smaller number of the same tags in "dots" in place of "angle brackets", i.e.
dot-br-dot, not open.angle-br-closing.angle
This is selected here:

<<general settings>>=
# how are doc sections marked? "dotHTML":"rawHTML"
$weave_markup = $weave_markup || "rawHTML"; # default is "rawHTML"

    if ($weave_markup eq "dotHTML") {
	$tag_open_symbol = $dot;	# this will take care of default
	$tag_close_symbol = $dot;	# when no var is set in the Lit Src file
    }
    elsif ($weave_markup eq "rawHTML") { 
	$tag_open_symbol = $lt;
	$tag_close_symbol = $gt;
    } #fi

@


Do we need to enable MathML functionality? If "yes", set the path to the js library
"ASCIIMathML.js" and enable the switch.
This slows down interpretation of the file on reload drastically (from nothing to
3 seconds with 4-5 example formulas), so for sfw development usually this should be off.

<<general settings>>=

# enable MathML interpretation? 1 : 0
$enable_ASCIIMathML = $enable_ASCIIMathML || 0;
# If enabled, set the path; default is local in current dir
$path_to_ASCIIMathML = $path_to_ASCIIMathML || "ASCIIMathML_with_modified_escapes.js";

@


It would make sense to add a few more markups to the program, i.e. some "wiki" many use,
and some TeX basic tags for automatic translation, if the doc is tagged as a TeX file.

In more detail dotHTML is explained in its own section

}}}4



#-------------------------------
{{{4 .h4. main despatcher ./h4.
#-------------------------------

The script figures out how it was invoked and then starts either a tangler
or a weaver, or fails with a usage line.

If the script name ends in "weave" (e.g. script.weave), it will be weaved to STDOUT.
If the name ends in "tangle", the source starting from the default chunk < <*> >
(without spaces) will be dumped to STDOUT:

<<main despatcher>>=
<<main despatcher kludgy>>
@



#-----------------------------------------------
{{{5 .h5. With tanglediffs as an option ./h5.
#-----------------------------------------------

.b.To add "tangled diffs"./b.  through a broser - i.e. output of 
.pre.  MOLLY.tangle | diff -y -w --left-column xxz - |less ./pre.

1. To colour the script must hard-set "width":
.pre. diff -W130 ......... # 130 is the default ./pre.
The separation line runs at < width/2 (e.g. at pos 63 if W=130, at 87 if W=190 etc
So I can recognize "changed" lines to colour if length($line) >= Width/2 ?? (or strictly more)
But figuring out at which pos the separation line runs without hardcoding W is not obvious to me.

Another alternative might be to use an external code colourizer, such as vim ??



2. I'll have to redo the despatcher's logic:
    .ul. check REQUEST_METHOD if it si GET, then weave for "xx.weave" extensions, 
    do tanglediffs for the "scriptname.tangle" extension, and do real tangle if 
    REQUEST_METHOD is not set.
    The tanglediffs will be controlled by cgi query string (i.e. disassemble and
    match QUERY_STRING).
    The tanglediffs will present a form to select a disk file to tanglediff against;
    subsequent views of output can be done by reloading the page in a browser.
    ./ul.

<<main despatcher with tanglediffs>>=
;

@


#-----------------------------------------------------------
{{{6 .h6. a skeleton script to test this snippet ./h6.
#-----------------------------------------------------------

To test: 
    .ol..li.save as test.weave, hard link to test.tangle and test.pl
    ./li..li. and set thttpd.conf to treat x.tangle as cgi
    ./li../ol.

<<tanglediff test 1>>=
#!/usr/bin/perl

if ( $0 =~ m!\.tangle$! ) { 
    if ($ENV{'REQUEST_METHOD'}){ goto TANGLEDIFF_ME }
    else { goto TANGLE_ME; }
}
elsif ( $0 =~ m!\.weave$! ) {
    goto WEAVE_ME
}
else {
    #output error message and usage 
    exit;
}

TANGLE_ME:
    print "I am being tangled\n";
    exit;

TANGLEDIFF_ME:
    #disassemble and check the query string here
    #and accordingly do a primitive protocol:
	# output file selection form of none
	# show the diff if selected, e.g. 
	#   "script.tangle?filename_on_disk_to_tanglediff_against"
    
    #debug:
    print "I am in a tanglediffer\n";
    exit;

WEAVE_ME:
    print "I am in a weaver\n";
    exit;

@

.b.also./b. where there were "weaver" and "tangler" before, I'll have one more "tanglediff"
subsection below to set the "diff" invocation and dumping its output.

.i.Question for the tanglediffe./i.r - should I have an option to directly dump the result 
of tangling into a browser, or is it unnecessary?

.i. NOTE ./i. the tanglediffer and tangler may share some pre-processing part needed for
clean tangling. Then the separation will be different:
the tangle-tanglediff switch will live inside TANGLE_ME

.b..i.NOTE 2./i../b. Should I simplify it even more? -- rather than making distinction by the name
extension and forcing the user to create hard links and reconfigure the web server (imposs.
if it is not a local server, but say an html-served subdir in his home dir) -- why don't I
.i.start the mode from a hyperlink./i. ??
The mode will be identified from the QUERY_STRING (or CL options), and the code providing
it is of course still inside MOLLY.pl.

}}}6


#------------------------------------------------
{{{6 .h6. With wavediff and tanglediff?? ./h6.
#------------------------------------------------

I could also do "weavediff" and "tanglediff" for ease of checking in the browser.

.ul.    .x.weavediff./x. - checked, looks bad: huge and not well-readable after a few changes.
    Main prob: executing "weave" produces HTML, so I'll need to execute the other file on
    disk too, or save HTMLs, both are cumbersome options
    SO: no "weavediff"
./ul.

In that case the despatcher will be different:

<<tanglediff.test2.pl>>=
#!/usr/bin/perl

$weave_extension = "weave";
$tangle_extension = "tangle";


# -- a call for the weaver --
if ( $0 =~ m!\.$weave_extension$! ) {

    # --- a call from CGI ---
    if ($ENV{'REQUEST_METHOD'}){

	print "\nFIRST OF ALL, THIS IS A CALL TO WEAVER\n";

	#pull and process QUERY_STRING to weave or tanglediff
	
	if ( $ENV{'QUERY_STRING'} eq "" ) {

	    print "<html><body>\n";
	    print "a CGI call for weaving<br>\n";
	    print "</body></html";
	}


	elsif ( $ENV{'QUERY_STRING'} eq "diff") {
	    print "here I should output the file selection form for tangle-diff\n"
	}
	elsif ($ENV{'QUERY_STRING'} =~ m!^diff&(.*)$! ) {

	    # check the supposed filename is an allowed alphanumeric:
	    # convert spaces into underscores and check for match to "\w+"
	    print "a call from CGI for a diff with some file.. going to check if it exists..\n";

	    # for the test - just get the file
	    # /if the file with such a name exists, of course/
	    if (-f $1) {

		# then run the piped command like
		# scriptname.tangle | diff -y -w --left-column xxz -
		print "here tanglediff pipe will be with the given file\n"

	    } # fi rung the tanglediff pipe
	} # fi this is CGI GET args for tanglediffing
	else {
	    print "a call from CGI to the weaver -- with unknown arguments<br>\n";
	}

    } # this was a call from CGI

    # --- a call from CL ---
    else {
	#process command-line args
	# to weave or weavediff or tanglediff
	print "this is a call from CL\n";
	print " arg1 is $ARGV[0] -- arg2 is $ARGV[1]\n";
	print "The same 3 options will apply: weave, ask for selection and tanglediff\n";
    } # esle, fi -- this was a call from command line
}

# -- a call for the tangler -- 
elsif ( $0 =~ m!\.$tangle_extension$! ) {

    # do direct tangling
    # will not execute in the browser, as the web server
    # does not allow it?? -- or filter on REQUEST_METHOD, too?
    print "a CL call for tangling\n";

}

# -- a call for other extensions --
else {
    #print usage
    print "a call with an unknown extension or a call to 'tangle' from under CGI\n";
    print "Not allowed, printing usage..\n";
}

@


.b. So ./b. this one seems to be Ok, although I still dislike its cludginess. I'd like a
better options processing skeleton script.

}}}6

}}}5



#-------------------------------------------------------------------------
{{{5 .h5. "Main despatcher kludgy" - first version - no tanglediffs ./h5.
#-------------------------------------------------------------------------


.i. To add here: ./i.
command line options parsing??
Error/usage message should be html-ized too??

<<main despatcher kludgy>>=
  # -- MAIN DESPATCHER ----

  # check if $i_am_module and set filenames to $0 - or 
  # process CL options otherwise

  # (temp) - 2 options, to weave and to tangle in module mode:
  #
  if ( $0 =~ m!\w+\.$weave_extension$! ) { goto WEAVE_ME }
  elsif ( $tangle_me) {goto TANGLE_ME}
  else {
  print <<end_of_print;

	USAGE:
	Not set to tangle.
	Set variables at the beginning of the script properly.  

end_of_print
  }
@

}}}5

}}}4

}}}3


#---------------------------------
{{{3 .h3. TANGLER ./h3.
#---------------------------------

    This version of the script does not include a built-in tangler, and therefore
    if you set "$tangle_me" to 1 in the settings, the script will pass ithe request through
    the "notangle" utility of the "noweb" Literate Programming tool to tangle starting with 
    .i.the default chunk < <*> >./i.   and without other options passed. I only set "notangle" 
    below to preserve the tabs in case you are tangling Makefiles.

    So, when the script is invoked as "script.tangle" (which can be a link or a soft
    link to something like "script.weave", it's "real" name), it will dump the source
    to STDOUT, very convenient for development.

    I usually move the root chunk < <*> > along inside the LIterate Source project
    file and assign it to the test script or the part I am working on. The Literate Source
    project file includes several actual source files usually. By the way, it's quite
    nice to be able to keep all partial tests that you do before including those into
    the target program all in one place, your common project file.

    To tangle with more specific options, run "notangle" directly on your "mollified"
    literate source file, e.g.
    .pre.notangle -R my_root_chunk -L script.weave ./pre.

    Later other modes of operation may be incorporated here.




#---------------------------------------
{{{4 .h4. pass-through tangler ./h4.
#---------------------------------------

    Passes the request to "notangle" from the "noweb" literate tools suite.

<<tangle me>>=
<<tangle me with filtering>>
@


<<tangle me straight>>=


TANGLE_ME:

	open TANGLE_PIPE, "| notangle -t4 -";

	open MYSELF, "<$0";
	while  (<MYSELF>) {
	    # filter here
	    # filter here and
	print TANGLE_PIPE $_;
	}

	close TANGLE_PIPE;
	close MYSELF;
exit;

@


    Pre-filtering might need to bo done. E.g. "notangle" gets confused by double angle brackets
    even when those are inside the document chunks.
    Therefore I could escape those before passing them to the tangler.

    This of course is kind of stupid, as running 'notangle' without this pre-filter will still
    break it, e.g.
    if I want to do it from command-line with some special options or for a non-root chunk,

    This is not a full solution in itself. Consider it as a template for pre-filtering, sort of.


<<tangle me with filtering>>=


TANGLE_ME:

	open TANGLE_PIPE, "| notangle -t4 -";

	open MYSELF, "<$0";
	while  (<MYSELF>) {

	    if ( m!^(goto)?<\<(.*)>\>=! ... m!^@\s*$! ) { # -- CODE CHUNKS -- 
		print TANGLE_PIPE $_;
	    }
	    else {  # -- DOC CHUNKS /and beginning of file, irrelevant / --

		# filter double angle brackets that confuse "notangle"
		s/<</$lt_esc$lt_esc/g;
		s/>>/$gt_esc$gt_esc/g;
		print TANGLE_PIPE $_;
	    }

	} # elihw

	close TANGLE_PIPE;
	close MYSELF;
exit;

@


    .b. BUG of sorts ./b.
    the "lt" and "gt" escapes in the code chunks right above ("tangle me with filtering") are not 
    displayed correctly  by the web weaver: the browser displays them as real angle brackets.
    .s.I could avoid this  by using $lt and $gt perl vars defined in "general settings" for exactly
    cases like this../s.
    I .i.cannot./i. avoid this without setting another couple of perl vars: $gt_esc = "& gt;" etc. ...

    I do have lines with the same problem in the "dotHTML formatter" chunk as well.



    .b. Immediate execution of the script ./b.
    It did not work exactly, but then I did not try it for real -- if it is needed and if your
    language supports taking input from STDIN, it may be possible also to immediately run your
    script skipping the stage of "tangling-into-a-file" before running.
    To be added (possibly).

}}}4




#-----------------------------------------------------------
{{{4 .h4. Built-in tangler ./h4.
#-----------------------------------------------------------


#------------------------------------------------------
.h5. tangler around "tsort" and string expansion ./h5.
#------------------------------------------------------



#-------------------------------------
{{{6 .h6. Main tangler framework ./h6.
#-------------------------------------

{{{7 .h7. Generalities ./h7.

This version is line-by-line, not "strings in memory" (another option/version
to test next, possibly)

Need to test 3 things:
    .ol. .li. name of a chunk equal to a multiword string -- DONE
    ./li. .li. need to eval the strings -- DONE
    ./li. .li. regexp to pick up pieces of a line cleanly -- START with ONE ref per line
    ./li. .li. \n during line-by-line appending needed??
    ./li. ./ol.

.b. OK, philosophy ./b.
    Perl allows one to have multi-word strings with "line noise" symbols .i. as variable names ./i.
    and as the names of the keys of a hash.
    Therefore, I am not going to rename the code chunks at all: I'll keep the literal text of the
    chunk as the value of a var, whose name is its title (a free-flowing phrase, too).
    I'll keep a hash like that, too.
    I will next interpolate the literal text of the code chunk interspersed with 
    .pre. "'some code text' . $name_of_another_chunk . 'some more text'" ./pre.
    with "eval" when printing the chunk finally out - and that will give me the sought outcome,
    the properly re-arranged text of the whole program.

    Now, for this interpolation to happen, perl must know values/definitions of all included vars
    before it attempts the final "eval".
    That will be done with the "topological sort" thingy, which will help me to form another
    string, of the raw splinters without any refs in them.

    The final output then will be
    .pre. eval($raw_splinters);
    print eval($name_of_my_root_chunk); ./pre.

    .i. It is quite possible ./i. to do tangling with a half dozen other methods, but I think this
    monstrocity will save me some coding: I relegate all unravelling and interpolation to the
    language interpreter. 
    Let the box work, and me relax. Laziness is the supreme virtue ;))))


.b. .i. Memory usage ./i. ./b. will be equal to the size of all program chunks in a given Literate
Source project file (plus whatever perl adds on its own internally) -- maybe double of that because
of interpolation, but with single project files in 10MiB are a rarity, while computer RAM is now
routinely comes to 1-2 GiB, this is not a problem at all

}}}7


{{{7 .h7. Results of tests ./h7.

.b. First impression ./b. - even manually the "eval prebuilt string" does not seem
to work. Either the approach is not valid (what I missed in my primitive tests), or
I think of it in an overcomplicated way, and in fact it's much simpler...

.i. Looks like ./i. "eval"-ed code does not come to the current "namespace" or sth:
it evals and remains there. I.e. eval'ed vars are not available later from the calling
namespace.


.b. Second look and impression ./b.
My third version (not '..-ONE' or '..-TWO') drops accumulation of strings and just
creates a direct, unquoted value in %code_chunk_splinters_raw
This all works fine - substituting .b. one level only ./b. of the variables.
Second level vars are broken, even when all values are inside the hash assembled in full.

.i. .b. this is wrong ./b. ./i. as the following test shows:

<<perl auto-expansion of embedded vars>>=

$hash{'a'} = "hehehe";
$hash{'b'} = "hihihi" . $hash{'a'} . '-end_b-';
$hash{'c'} = "hahaha" . $hash{'b'} . '-end_c-';
$hash{'d'} = "ohhoho" . $hash{'c'} . '-end_d-';


print "$hash{'d'}\n";

@

It produces the expected output:
.pre. ohhohohahahahihihihehehe-end_b--end_c--end_d- ./pre.

}}}7




{{{7 .h7. Main, outline ./h7.


The standalone test tangler script

.b. (1) Pass 1: collect the info ./b.


<<check strings expansion>>=
#!/usr/bin/perl 

    $default_target = '*';
    #$default_target = 'chunk 1';
    #$default_target = 'MOLLY.pl module';
    <<tsort sub in perl>>

    open LITSOURCE, "< $ARGV[0]" || die "could not open the file to tangle\n";

    $chunk_beg_pattern = q(^<\<(.*)>\>=);
    $chunk_end_pattern = q(^@\s*$);
    $chunk_ref_pattern = q(<\<(.*?)>\>[^=]); # can be used several times in a line


    $beg_ref_quote = q(\n . ${');
    $end_ref_quote = q('} . \n);

    #%code_chunks_buf = (); # accumulating chunks bodies
    #%code_chunks_index = (); # like "goto" stack per chunk

    %code_chunk_splinters_raw = ();
    @parents_list = ();

    $line_num = 0;

  while (<LITSOURCE>) {

    $line_num++;

    if ( m!$chunk_beg_pattern! .. m!$chunk_end_pattern! ) { # -- CODE CHUNKS -- 

	if ( $_ =~ m!$chunk_beg_pattern! ) {
	    <<process chunk title - tangler>>
	}
	elsif ( $_ =~ m!$chunk_end_pattern! )  {
	    <<process end of code chunk - tangler>>
	    }
	elsif ( $_ =~ m!$chunk_ref_pattern! ) {
	    <<process chunk ref - tangler>>
	}
	else { # chunk body: accumulate
	    <<process chunk body - tangler>>
	    }
    } #fi


  } #eliwh

@


...next, after we've collected the string, let's .b. 
(2) topo-sort them and print out ./b.

    /* debug: just print out, first of all */
    /* debug2: print out hte topo-sorted sequence */
    /* debug3: eval all toposorted until Target; print out the Target */


<<check strings expansion>>=

    #for $i (keys %code_chunk_splinters_raw){
    #
    #    #debug: - print chunks content --  seems OK
    #    print "for key $i the content is\n", $code_chunk_splinters_raw{$i}, "\n-----------\n";
    #
    #}


# debug: print topo-sorted chunk names -- seems OK
for my $i (topological_sort( @parents_list )){ 
  print "\n-------CHUNK IS [ $i ] --------\n";
  print $code_chunk_splinters_raw{$i}, "\n------- end of chunk --------\n\n";
};


    # debug: this does not work now
    # Complains the "eval" in else is on an empty string
    #for my $i (topological_sort( @parents_list )){ 
    #    
    #    print "\n---- [$i] -----\n";
	#$output_line .= eval ( $code_chunk_splinters_raw{$i} );
	#$code_chunk_splinters_raw{$i}
    #   $out =  $code_chunk_splinters_raw{$i}; 
    #    print "..and output line now is..\n$out\n......\n\n";
    #}

    #print "\n\n$output_line\n\n";

    #$output_line .= q(print $code_chunk_splinters_raw{'*'};);
    #eval $output_line;

@

Seems Perl can do (corectly) only one level of embedded vars expansion.
Let's try to cheat it this way - by doing exactly one level at each step,
in the topo-sort order:

<<check strings expansion>>=
%out_expanded_chunks = ();
for my $i (topological_sort( @parents_list )){ 
    $out_expanded_chunks{$i} = $code_chunk_splinters_raw{$i};
}    
    
#print $code_chunk_splinters_raw{$default_target}, "\n";
print $out_expanded_chunks{$default_target}, "\n";
@

This is very wasteful, and may take several times the size of the tangled
code in memory for the %out_expanded_chunks buffer.


}}}7



{{{7 .h7. Processing particular sections ./h7.

.b. We got the first line of a chunk, its title ./b.
    # form the name and push into the hash-stack
    # ..after checking it's not a continuation of an already def-d chunk
    #   $current_chunk_title_ref = ${$1};

    ?? - what happens in the "else" when I do not hit the "unless" clause ??
    !! - .b. logical ERROR ./b. - a continued chunk (another 'installment') requires 
    separate treatment

.b. Version two - rewrite ./b. 
.s. Nothing needs t be done with the first line, can keep it as a NOP, actually. ./s.



<<process chunk title - tangler>>=

    $current_chunk_name = $1;
    $code_chunk_splinters_raw{$current_chunk_name} .= " ";

@


<<process chunk title - tangler - TWO>>=

    $current_chunk_name = $1;
    $code_chunk_splinters_raw{$current_chunk_name} .= "" . " q( " ;

@


<<process chunk title - tangler - ONE>>=
    # placeholder
    $current_chunk_name = $1;
    unless (defined $code_chunk_splinters_raw{$current_chunk_name} ) {
	$code_chunk_splinters_raw{$current_chunk_name} =  "\n" . q(  $output_text{') . 
	$current_chunk_name . q('} ) . "= q( "
    };


@

.b. Secondly, if the chunk ended ./b.

    ..then append the closing symbols of the quoted string, poss. reset some vars.

<<process end of code chunk - tangler>>=

    $code_chunk_splinters_raw{$current_chunk_name} .= " ";
@




<<process end of code chunk - tangler - TWO>>=

    $code_chunk_splinters_raw{$current_chunk_name} .= ' );' . "\n";
@

<<process end of code chunk - tangler - ONE>>=
    # placeholder
    $code_chunk_splinters_raw{$current_chunk_name} .= ' );' . "\n";


@


.b. If it is raw code ./b.
 
    no refs to other chunks - i.e. if it's a pure code body line,
    then just append it

    (a) mm.. do I need to quote and append??? Or is it OK already??
    (b) I did not "chomp" the line, so the "\n" should be present

<<process chunk body - tangler>>=

    $code_chunk_splinters_raw{$current_chunk_name} .=  $_;

@

<<process chunk body - tangler - ONE>>=

$code_chunk_splinters_raw{$current_chunk_name} .= $_;

@



.b. Now: if we got a chunk ref ./b.
    # 1. (a) append the pre-ref string to the curr_chunk_namevar
    #   (b) .. concat the ref_chunk_namevar to it
    #   (c) .. and concat the rest of the line
    # 2. ...and make sure the $ref_chunk_namevar string is defined before
    #   this chunk is processed -- for the strings based subst. and expansion.
    #   - i.e. (a) push (parent, child) pair into a list to be topo-sorted later.
    #   and (b) append to ..

    Ok, here's a small hitch: I'd better keep bare string defs, without refs, in a
    separate string buffer, and the composite ones in a second one.

    So I'd need to generate consequtive names current_chunk-1, current_chunk-2 etc. 
    and keep their defs in buffer_string_1, while the composite name like
    .pre. $current_chunk =  $current_chunk-1 . $chunk_ref . $current_chunk_2 ./pre. 
    in buffer_string_2

<<process chunk ref - tangler>>=

    $chunk_ref_name = $1;
    $code_chunk_splinters_raw{$current_chunk_name} .= " " . 
	$code_chunk_splinters_raw{$chunk_ref_name} . " ";

    unshift @parents_list, ($current_chunk_name, $chunk_ref_name);

@

.b. This does not seem to be correct ./b. as there is no .i. interpolation ./i. if I simply
insert the reference in the main text.
OK that I generate the parents list, but .i. interpolation ./i. must happen
   

------------------------------------

<<process chunk ref - tangler - TWO>>=

    $chunk_ref_name = $1;
    $code_chunk_splinters_raw{$current_chunk_name} .= q( \) . ) . "\n" . 
	q( . $code_chunk_splinters_raw{') . $chunk_ref_name . q('} . ) . "\n q(" ;

    unshift @parents_list, ($current_chunk_name, $chunk_ref_name);


@


<<process chunk ref - tangler - ONE>>=
    # placeholder
    $chunk_ref_name = $1;

    #$code_chunk_splinters_raw{$current_chunk_name} .= "\n" . q( . ${') . $chunk_ref_name . 
    #   q('} . ) . "\n";

    $code_chunk_splinters_raw{$current_chunk_name} .= q(\) . ) . "\n" . 
	q( . $code_chunk_splinters_raw{') . $chunk_ref_name . q('} . ) . "\n q(";

    unshift @parents_list, ($current_chunk_name, $chunk_ref_name);
@


}}}7

}}}6

#------------------------------
{{{6 .h6. Topological Sort ./h6.
#------------------------------


takes a list of (flattened) pairs ( (node_1, depends_on_1), (node_1, depends_on_2), ....)
-- and produces a list of ordered precursors: ( depends_on_2 , depends_on_1, node_1, .....)
for the whole tree of nodes and their dependencies.

If I do "strings interpolation" tanger, I will need it to define the inned simple strings
.i. before ./i.  the complex ones which represent chunks, so they get interpolated without
perl complaining about unknown strings.


I will modify in-place this sub yanked from "tcsort.txt", a perl implementation of
the unix "tsort" utility (originally from a Knuth algorithm) by Jeffrey S. Haemer in
his project that reimplements unix utils in pure perl.
.a. http://cpansearch.perl.org/src/CWEST/ppt-0.14/README ./a.


<<tsort sub in perl>>=

#use strict;

sub topological_sort {

    my %pairs;	# all pairs ($l, $r)
    my %npred;	# number of predecessors
    my %succ;	# list of successors
    my $opt_b = 0;

    my @topo_list_out = '';

    while ( @_ ) {
	my $l = shift @_;
	my $r = shift @_;
	my @l = ($l, $r);
	#my ($l, $r) = my @l = split;
	next unless @l == 2;
	next if defined $pairs{$l}{$r};
	$pairs{$l}{$r}++;
	$npred {$l} += 0;
	++$npred{$r};
	push @{$succ{$l}}, $r;
    }

    # create a list of nodes without predecessors
    my @list = grep {!$npred{$_}} keys %npred;

    while (@list) {
	$_ = pop @list;
	unshift @topo_list_out, $_;
	#print "$_\n";
	foreach my $child (@{$succ{$_}}) {
	    if ($opt_b) {	# breadth-first
		unshift @list, $child unless --$npred{$child};
	    } else {	# depth-first (default)
		push @list, $child unless --$npred{$child};
	    }

	}
    }

    warn "cycle detected\n" if grep {$npred{$_}} keys %npred;

    return @topo_list_out;
}

@

<<check topo sort>>=

<<tsort sub in perl>>

# let's check if it works now -- this should print it

my @parents_list = ( ("a",  "b"),  ("a",  "d"),  ("a",  "c"),  ("b",  "c"),  ("d",  "e") );

for my $i (topological_sort( @parents_list )){ print "$i\n";};

@

}}}6

#-----------------------------------------------------------------------------
{{{6 .h6. Strange var and hash key names plus string interpolation ./h6.
#-----------------------------------------------------------------------------

    For reference for the main tangler script below. This script has been tested and
    it works as intended.

<<test names and deref>>=
# 1. Dereferencing and using long bad strings as varnames and keys in hashes

$hash{q(a long $strange #tring wi# symbols)} = q(another long string @$%^ with strange symbols);

while (($a, $b) = each %hash) {
	print qq(key is -- $a -- and value is -- $b --\n);
	}

${q(a long $strange #tring wi# symbols)} = "hehehe";
print "AND NEXT IS ${q(a long $strange #tring wi# symbols)} \n";

$$c = "a am a string whose name is a bad string";
print "dereffing: $$c\n";



# 2.  Interpolation.
${q(A chunk with a long name?!)} = q('some string @#$%^ with noise');
${q(A chunk with a long name?!)} .= q( . " ||| " . $hash{q(a long $strange #tring wi# symbols)} );

print "\nFIRST, the string as I keep it in my buffer:\n\t${q(A chunk with a long name?!)}\n";
print "NOW THE TRICK::\n\t", eval(${q(A chunk with a long name?!)}), "\n";


# 3. Picking up chunk name from a regexp
#   .. no refs are needed at all, actually, the vars do it anyway, it seems.

$line1_test3 = q(<<ch*nk n@me wh&ch q(i$$ a p#r@se)>>=);
$line2_test3 = q(some text from the chunk body);
$line3_test3 = q(second line of the same chunk body);
$chunk_beg_pattern_test3 = "^<\<(.*)>\>=";
%chunks_hash_test3 = ();

if ( $line1_test3 =~ $chunk_beg_pattern_test3 ) {

  $chunk_name = $1;
  print "\n\n............\n$line1_test3\n\n";
  print "HHHHHHHHHHH $chunk_name HHHHHHHHHHHH\n";
  print "$chunk_name\n";
  $chunks_hash_test3{$chunk_name} .= $line2_test3 . "\n";
  $chunks_hash_test3{$chunk_name} .= $line3_test3;

}
else {print "\n
    \n===========\ncould not match it\n"};

  print "\n----------\n$chunks_hash_test3{$chunk_name}\n-------------\n";




#---end---

@

Script output (from 1,2):
-------------------------------------
    .pre.
    bash-3.1$ perl xxx
    key is -- a long $strange #tring wi# symbols -- and value is -- another long string @$%^ with strange symbols --
    AND NEXT IS hehehe
    dereffing: a am a string whose name is a bad string

    FIRST, the string as I keep it in my buffer:
	    'some string @#$%^ with noise' . " ||| " . $hash{q(a long $strange #tring wi# symbols)}
    NOW THE TRICK::
	    some string @#$%^ with noise ||| another long string @$%^ with strange symbols
    bash-3.1$ 
    ./pre.
-------------------------------------

}}}6

}}}5


#--------------------------------------------
{{{5 .h5. Scrap pieces for tangler ./h5.
#--------------------------------------------


#--------------------------------------------------------
{{{6 .h6. 1. Use MD5 for chunk titles? ./h6.
#------------------------------------------

    Chunk names are free phrases in a human lang. I need poss. to make a hash of contents with
    the title as  the key. A phrase is not good for that, so could I use MD5 hashes of the titles
    instead??

    PErl will require a module then:


<<md5 hashing from perl>>=
#!/usr/bin/perl
# Functional style
 use Digest::MD5 qw(md5 md5_hex md5_base64);

 #$digest = md5($data);
 #$digest = md5_hex($data);
 #$digest = md5_base64($data);

 # my test:
 $digest1 = md5_base64("md5 hashing from perl");
 $digest2 = md5_base64("Chunk names are free phrases in a human lang. I need poss. to make a hash 
    of contents with the title as  the key. A phrase is not good for that, so could I use MD5 
    hashes of the title");
 print "$digest1\n$digest2\n";
@

.b. Nope, it's much simpler ./b.
.b. 1. ./b. In fact, perl can digest "chunk names made of whole phrases" as hash keys - one just 
needs to quote them. There may be limitations on the special symbols inside the chunk titles, I
do not know. 
Seen in Conway's book, first chapters recapitulating main point of perl

.b. 2. ./b. A more restrictive option can be left as settable in the "mollifying" part of the
script -- use_chunk_names_of_alphanumerics_only with underscores in place of spaces.
Then I could programmatically match for alphanumeric chars during a first tangle pass and
complain if chunk names mismatch. 

So .b. no MD5 is needed after all, it seems ./b.

}}}6


#-------------------------------------------------------------
{{{6 .h6. 2. ver 1 -- skeleton for tangling ./h6.
#------------------------------------------------


    .i.Cut out code chunks; 
    create hash; 
    ..concatting parts of the same chunk. ./i.

    I will get here if I am "scriptname.tangle" and $builtin_tangler = 1


<<built-in tangler skeleton>>=
#!/usr/bin/perl
    use Digest::MD5 qw(md5_base64);

    $use_builtin_tangler = 1;
    unless ($use_builtin_tangler) {print "not set to tangle in the options\n"; exit}

    <<first pass of tangling - accumulate in RAM>>
    <<second pass of tangling - print out>>
@


    .b. .i. note 1 ./i. ./b.
    The following works with implicit understanting of the correct sequencing of the symbols in the
    Literate SOurce file. If those are mangled, results are not guaranteed. 
    I mean, no check is done to complain in case "< <  blabla > >=" and "@" do not follow each other
    or if those nest etc.

    .b. .i. note 2 ./i. ./b.
    Besides accumulating code, I also need to do indeces (also hashes)?
    One idea is to have immediate access to "parent roots", because I foresee 3 modes of tangling:
    .ul. .li.the default chunk "*"
    ./li..li.the specified chunk
    ./li..li.and "all root chunks" to kind of "check out the whole project" from the Literate Source
    ./li../ul.
    If I do not maintain the 3 modes and tangle from the "*" specified in the LitSource file, I won't
    need the indeces, I think.


<<first pass of tangling - accumulate in RAM>>=
    open LITSOURCE, "< $ARGV[$1]" || die "could not open the file to tangle\n";

    $chunk_beg_pattern = "^<\<(.*)>\>=";
    $chunk_end_pattern = "^@\s*$";
    $chunk_ref_pattern = "<\<(.*?)>\>[^=]"; # can be used several times in a line

    %code_chunks_buf = (); # accumulating chunks bodies
    %code_chunks_index = (); # like "goto" stack per chunk

  while (<LITSOURCE>) {

    if ( m!$chunk_beg_pattern! .. m!$chunk_end_pattern! ) { # -- CODE CHUNKS -- 

	if ( $_ =~ m!$chunk_beg_pattern! ) {
	    # form md5 and push into the hash-stack
	    $title_hash = md5_base64($1);
	    }
	elsif ( $_ =~ m!$chunk_end_pattern! )  {
	    # end of code chunk
	    }
	elsif ( $_ =~ m!$chunk_ref_pattern! ) {
	    # 1. form and push "goto" and "cont" into the hash-stack
	    #	.. which are a concatenation of strings
	    # 2. ...and make sure the $ref_chunkname string is defined before
	    # this chunk is processed -- for the strings based subst. and expansion.
	    }
	else { # chunk body: accumulate
	    $code_chunks_buf{$title_hash} .= $_;
	    }
    } #fi


  } #eliwh
@


    Now all code chunks, concatenated if they have the same name, are in RAM (inside %title_hash), 
    I can do the second pass and unravel them.




.b. 3. Second pass of tangling ./b.
#-----------------------------------

    Let's do tangling  from "*" only in this skeleton version

    The chunks now are in RAM as a string; I need to match < < chunk refs > > and continue right
    after processing them.
    Seems it can be done with a regexp which marks the place of its last match.

    err.. multiline matching; only-once + continuation -- the regexp options needed -- ??

    Secondly, it creates a recursive function.

<<second pass of tangling - print out>>=
 # second pass - tangling from %code_chunks_buf using %code_chunks_index for directions

 $default_root = md5_base64("*");

    # bullshit
    #$code_chunks_buf{$default_root} =~ m!!;

@

    .b. ...STOP... ./b.

    .b. Basically, if we use the strings expansion/subst, the call to print out is just
    "print $firstchunkname;" - the rest will work out automatically???
    Or do I  need to "eval" the formed re-ordered strings first??  ./b.

    .b. ALSO: ./b. "tsort" in pure perl implementing a Don Knuth's algorithm:
    .a. http://cpansearch.perl.org/src/CWEST/ppt-0.14/html/commands/tsort/index.html ./a.
    It's part of "Perl Power Tools" project, reimplementing Unix tools in perl:
    (or, rather a "Unix Reconstruction Project"):
    .a. http://cpansearch.perl.org/src/CWEST/ppt-0.14/README ./a.

    Actually, I downloaded the whole bundle, 3.9MiB compressed.

}}}6


#--------------------------------------------------------
{{{6 .h6. 4. Another idea for tangling ./h6.
#--------------------------------------

    Basically, I should create more chunks in $code_chunks_buf than the number of those 
    existing in reality.

    The idea is to split them at each < <  chunk ref > > to print out without parsing 
    the string at all.
    Then all I need is a parent-child index, that's all??

    The parent-child index must be able to keep multiple offspring then (in case some 
    chunk is reused, say if it is a func used in several contexts.

    .b. and for .i. srings substutution ./i. which is done with lazy regexp thingy below
    the first pass is just ........ ./b.

.b. 5. One more idea ./b. 
#---------------------------
    if I cannot iterate strings lazily, why not iterate over the file twice?
    Operators which work on the files are by their nature lazy both in perl and in newlisp.
    I.e. first pass - get offsets, form the "goto-index" hash, second pass - unravel.

}}}6


#--------------------------------------------------------------------------
{{{6 .h6. 6. Lazy iteration over strings in a memory buf ./h6.
#--------------------------------------------------------

    ..seems possible after all, check 
    .a.http://localhost:8000/perl.docs/perlretut-perldoc.perl.org.weave ./a.
    as a cumbersome combination of "g" option, "pos()" function and \G ancor
    see "global matching" subsection in the above doc (under "using regexp in Perl")


    HEre's a snippet that seems to work:

<<matchstring2.pl>>=
#!/usr/bin/perl

#------JUST a string to test the regexps on ------------
$string = <<end_of_string;
bla-bla-bla /leaving it out/
end_of_string

#---------------end of string--------------

=head
# first test, bad:
# match-prematch work, but on the WHOLE string. BAD:
  while ( $string =~ m!<\<(.*?)>\>[^=]!gc) {
    print "\n\n---PREMATCH---\n$`\n\n";
    print "MATCH\n$1\n\n";
    }
=cut


# --HERE'S ANOTHER IDEA--
# the use of \G ancor and poss the pos() function
#pos($string) = 0;
while ( $string =~ m!\G(.*?)<\<(.*?)>\>!gs) {
  
  $off = length($2);
  $position = pos($string);
  #pos($string) = $position + $off;
  print "\n\t---title---\n$2 of length $off at $position \n\t----after----\n$1\n========\n";

}

@

     ONE PROBLEM:
     last piece, post-chunk ?? OR not a prob when reading from a file??

     Looks like this can solve the prob of parsing a code chunk with included < <references> >
    when hitting a match:
    .ul.		- append $1 to the chunk buffer
		    - get md5, push it into the index
		    - form an md5 for the continuation and start that new chunk
		    - .. and push "goto" this continuation into the prev chunk index
    ./ul.
     Do this linearly on all cut out code chunks of the Literate Source file (appending those 
     with the same names)
     and print out from memory on pass 2 according to the goto index.

     Should preserve all offsets as well.

}}}6


}}}5

}}}4


}}}3



#--------------------------------
{{{3 .h3. WEAVER ./h3.
#--------------------------------


The idea of the weaver is simple, again.

<<weave me>>=


WEAVE_ME:

#1. Set formatting strings for weaver
<<set formatting strings for weaver>>

#2. accumulate result in a buffer
<<accumulate result in a buffer>>

#3. print out the TOC, the Chunks Index, the output buffer and close the page.
<<print out>>
@


#---------------------------------------------------------------
{{{4 .h4. How formatting is done in the weaver ./h4.
#-------------------------------------------------------------

.b.1 The first formatting element ./b.  that is  part of the .i. function ./i. of the script
rather than formatting decorations is the
.pre. frameset - legend - /legend - /frameset ./pre.
which create the distinctive look of the documents generated by MOLLY. I do not wish to
change them (although strictly speaking they are not obligatory).

What can be changed is the Stylesheet (a part of the script, it has its own subsection), so
other people could play with fonts and colors and margins and such by throwing in a simple
switch and copying their alternative stylesheet into the script.

I do not wish to use external files for any configuration, as the whole idea of MOLLY is to
be a single self-contained script, which does not require any "installation" of many files to
many places.

.b.2  Secondly,./b. the "actual working test.html" subsection below probably explains best how
.b. text folding and background highlighting ./b. which is tied to it (i.e. a TOC click will open the 
section + highlight; and click on the section in the body of the doc will toggle it + highlight 
the TOC line ) work.

Actual implementation is spread between several subsections - they are
coded in in the hard way, as I do not expect them to change ever, they are a functional element
not a changeable "skin" or decoration.
.ul..li. vars, JS and styles are set in the weaver "set formatting strings for weaver" subsections;
./li..li. invocations can be seen in "accumulate the result", esp in the "section headings"
./li..li. and more are applied in the "print out the result"
./li../ul.

Some of the vars are set to pieces of formatting strings in the beginning, and later variables
in them are interpolated with "executable" regexs ( the "e" flag at the end of the regex) - see 
"process section headings"


#---------------------------------------
{{{5 .h5. actual working test.html ./h5. 
#---------------------------------------

Here's the actual script that was used to test the JS folding and
tying of folding to the TOC section highlighting:


<<test.html>>=

<html>
<head>


<style type="text/css">


.unhilited {background-color:white}
.hilited {background-color:yellow; text-decoration:underline}
</style>


<script type="text/javascript">

    function setHilite(evt) {
	evt = (evt) ? evt : ((window.event) ? window.event : null);
	if (evt) {
	    var elem = (evt.srcElement) ? evt.srcElement : evt.target;
	    elem.className = "hilited";
	}
    }


function setUnHilite(evt) {
    evt = (evt) ? evt : ((window.event) ? window.event : null);
	if (evt) {
    	    var elem = (evt.srcElement) ? evt.srcElement : evt.target;
    	    elem.className = "unhilited";
	}
}

function toggleDiv(divid) {
var el = document.getElementById(divid);
el.style.display = (el.style.display == 'block') ? 'none' : 'block';
}

function toggleCombined(divid){
    if(document.getElementById(divid).style.display == 'none'){
      document.getElementById(divid).style.display = 'block';
	document.getElementById("toc"+divid).className="hilited";
    }
    
    else{
      document.getElementById(divid).style.display = 'none';
	document.getElementById("toc"+divid).className="unhilited";
    }
}


function expandDiv(divid){
	document.getElementById("toc"+divid).className="hilited";
}



</script>
</head>

<body >
<h2>Here's the tested element</h2>
Here is some ordinary text<br>
<span class="unhilited" onmouseover="setHilite(event)" 
    onmouseout="setUnHilite(event)"> 
    <a href="javascript:;" onmousedown="toggleDiv(15);"><b> process section headings </b></a><br>
    and this is some potentially hot spot text.</span>

<div id=15>
    .. and this is the text<br>
    that should be hidden/collapsed

</div>


<h2>Here's the tested element 0</h2>
HHHHere is some ordinary text<br>
<a href="javascript:;" onmousedown="toggleCombined(13);" id="toc13">
    <b> process section headings </b></a><br>

<div id=13 ><script language=javascript> document.getElementById("toc"+13).className='hilited';</script>
    .. and this is the text<br>
    that should be hidden/collapsed

</div>




<h2>Here's the tested element 1</h2>
HHHHere is some ordinary text<br>
<a href="javascript:;" onmousedown="toggleCombined(14);" id="toc14">
    <script language=javascript> document.getElementById("toc"+14).className='hilited';</script>
    <b> process section headings </b></a><br>

<div id=14 >
    .. and this is the text<br>
    that should be hidden/collapsed

</div>


<h2>Here's the tested element 2</h2>
HHHHere is some ordinary text<br>
<span  id="toc16"> 
    <a href="javascript:;" onmousedown="toggleCombined(16);"><b> process section headings </b></a><br>
    and this is some potentially hot spot text.</span>

<div id=16>
    .. and this is the text<br>
    that should be hidden/collapsed

</div>



</body>
</html>

@

}}}5


#----------------------------------------------------------------
{{{5 .h5. changing text style - the basic JS recipy ./h5.
#-----------------------------------------------------------------

I used this snippet for a start then reworked it into the "working test script" below.

.ul. .pre.
11.8.2 Solution
First, define two style sheet rules, each with a different class selector. Then design 
an event handler for the element to change the element's className property to the desired 
class selector's identifier: 

		<style type="text/css">
		.unhilited {background-color:white}
		.hilited {background-color:yellow; text-decoration:underline}
		</style>
		...
		<script type="text/javascript">
		function setHilite(evt) {
			evt = (evt) ? evt : ((window.event) ? window.event : null);
			if (evt) {
				var elem = (evt.srcElement) ? evt.srcElement : evt.target;
				elem.className = "hilited";
			}
		}
		function setUnHilite(evt) {
			evt = (evt) ? evt : ((window.event) ? window.event : null);
			if (evt) {
				var elem = (evt.srcElement) ? evt.srcElement : evt.target;
				elem.className = "unhilited";
			}
		}
		...
		<span class="unhilited" onmouseover="setHilite(event)" 
			onmouseout="setUnHilite(event)">Some potentially hot spot text.</span>

Adjusting the className property of an element as shown here is a more stable approach 
for early versions of Netscape 6 instead of manipulating styleSheet objects and their 
properties. It is perhaps the most widely used and supported way to implement dynamic styles. 
./pre. ./ul.

If I enclose one "onmousedown" inside another, JScript will most probably not pass it into the inner one.
So I should add:
(a) the TOC line IDs ?? Like "toc.1", "toc.2" etc
(b) keep a separate func, not "toggleDiv", but something else like "toggleTOCandDIV", and run 2 things
from there ??

.b. So, 2 tests: enclosing and if not, then rewriting the collapsing JS func ./b.

}}}5

#--------------------------------------------------
 .h5. Reference - Javascript and DOM ./h5.
#--------------------------------------------------


I'll need some javascript and DOM reference for further work;

a/ http://w3schools.com/htmldom/dom_reference.asp  -- ref from W3C
b/ http://w3schools.com/htmldom/default.asp -- might also be useful
c/ http://www.howtocreate.co.uk/tutorials/javascript/domcss --javascript tutorial (not necessarily best) 
d/ http://www.pageresource.com/dhtml/ryan/part4-1.html - another tutorial


}}}4


#------------------------------------------------------------
{{{4 .h4. set formatting strings for weaver ./h4.
#------------------------------------------------------------

<<set formatting strings for weaver>>=

  #----SETTING FORMATTING STRINGS-----------
  
$html_head = <<head_end_1;  

<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" /> 

head_end_1

#switch on ASCIIMathML.js library if enabled in template options:
if ($enable_ASCIIMathML) {
$html_head .= "\n" . qq(<script type="text/javascript" src="$path_to_ASCIIMathML"></script>) . "\n";
    }

$html_head .= <<head_end;

<<JS script functions>>
<<stylesheet>>

</head>
head_end

$html_body_table = "<center><table class='outertable'><tr><td>";
$html_body_table_end = "\n</td></tr></table></center></body></html>\n";


	

$folding_section_start1_str = <<'fold_sect_start_1_xxx';
	<fieldset><legend><a href="javascript:;" onmousedown="toggleCombined('$section_num');">
fold_sect_start_1_xxx


$folding_section_start2_str = <<'fold_sect_start_2_xxx';
</a></legend></fieldset>
<p>
<div id="$section_num" style="display:$fold_state"> $highlight_state  
<ul>

fold_sect_start_2_xxx


$folding_section_end_str = <<'folding_section_end_xxx';
</ul>
<p>
<br>
<i><font size=-1>
<a href="javascript:;"onmousedown="toggleCombined('$section_num_prev');">
Close the subsection</a></font>
</i> -- <i><font size=-1>
<a href="javascript:;" onmousedown="showAll();">
expand all</a> -- 
<a href="javascript:;" onmousedown="hideAll();">
collapse all</a>
</font></i>

<p>
</div>

folding_section_end_xxx


$code_frameset_start_pre = "<pre><fieldset class='codefieldset'><legend class='codelegend'>";
$code_frameset_start_post = "=</legend>";
$code_frameset_end = "</fieldset></pre>\n";




@

#----------------------------------------
{{{5 .h5. JS functions ./h5.
#----------------------------------------

In my attempts to insert ASCIIMathML.js, I have tried some variations of
math sections markup (with "a m a t h" -- "e n d a m a t h" words and
with backquotes) -- but the stinking lib insists on garbling my file, as
sth triggers it on earlier.

So a next step is to change regexps inside the Javascript lib and forse it
to sane markups. Probably by adding ancoring the key word to the beginning
of the line and/or insisting that it is there alone.

<<JS script functions>>=

<script language="javascript">

function toggleDiv(divid) {
var el = document.getElementById(divid);
el.style.display = (el.style.display == 'block') ? 'none' : 'block';
}


function toggleCombined(divid){
    if(document.getElementById(divid).style.display == 'none'){
      document.getElementById(divid).style.display = 'block';
	document.getElementById("toc"+divid).className="hilited";
    }
    else{
      document.getElementById(divid).style.display = 'none';
	document.getElementById("toc"+divid).className="unhilited";
    }
}


function showAll(){
for(i=1; i <= 10000; i++){
    document.getElementById(i).style.display = 'block';
    document.getElementById("toc"+i).className="hilited";
    };
}

function hideAll(){
for(i=1; i <= 10000; i++){
    document.getElementById(i).style.display = 'none';
    document.getElementById("toc"+i).className="unhilited";
    };
}

</script>
@

}}}5

#--------------------------------------
{{{5 .h5. Stylesheet ./h5.
#--------------------------------------

<<stylesheet>>=
<style type="text/css" media="screen">


BODY {
	FONT-SIZE: 10pt;
	<!--FONT-FAMILY: sans-serif -->
	background: #f0f0f0;
	}
FIELDSET {
	BORDER-RIGHT: #000000 1px solid; 
	BORDER-TOP: #000000 1px solid; 
	BORDER-LEFT: #000000 1px solid; 
	BORDER-BOTTOM: #000000 1px solid; 
	PADDING-RIGHT: 5px; 
	PADDING-LEFT: 5px; 
	PADDING-BOTTOM: 2px; 
	PADDING-TOP: 5px;
	MARGIN-BOTTOM: 1px; 
	background: #f5f5f5; 
	color: #000000;
	}
LEGEND {
	BORDER-RIGHT: #a9a9a9 1px solid; 
	BORDER-BOTTOM: #a9a9a9 1px solid;
	BORDER-TOP: #a9a9a9 1px solid; 
	BORDER-LEFT: #a9a9a9 1px solid; 
	PADDING-RIGHT: 20px; 
	PADDING-LEFT: 20px; 
	PADDING-BOTTOM: 5px; 
	PADDING-TOP: 5px; 
	FONT-WEIGHT: bold;  
	BACKGROUND: #fdfdfd; 
	color: #000000;
	}
PRE	{
        PADDING-LEFT: 20px; 
        PADDING-RIGHT: 5px; 
        padding-top: 0px; 
        padding-bottom: 6px;
        MARGIN-BOTTOM: 1px; 
        BORDER-TOP: #a9a9a9 0px solid;
        BORDER-RIGHT: #a9a9a9 0px solid; 
        BORDER-LEFT: #a9a9a9 0px solid;
        BORDER-BOTTOM: #a9a9a9 0px solid;        
	background: #fefefe;
	}


.tocfieldset {
	background: #ffffff; 
	color: #000000;
	}

.codefieldset {
	BORDER-RIGHT: #000 1px solid; 
	BORDER-TOP: #000 1px solid; 
	BORDER-LEFT: #000 1px solid; 
	BORDER-BOTTOM: #000 1px solid; 
	background: #ffffff; 
	color: #000;
	MARGIN-BOTTOM: 1px; 
	PADDING-LEFT: 15px; 
	PADDING-RIGHT: 5px; 
	PADDING-BOTTOM: 10px; 
	PADDING-TOP: 1px;
	}
.codelegend {
	BORDER-RIGHT: #777 1px solid; 
	BORDER-TOP: #777 1px solid; 
	BORDER-LEFT: #777 1px solid; 
	BORDER-BOTTOM: #777 1px solid
	PADDING-RIGHT: 10px; 
	PADDING-LEFT: 10px; 
	PADDING-TOP: 2px; 
	PADDING-BOTTOM: 2px; 
	background: #ffffff; 
	color: #00b;
	FONT-WEIGHT: bold;  
	/font-variant: small-caps;
	/font-style: italic;
	}



.chunkref {
        color: #00b;	
        background: #f6f6f6;
        /font-style: italic;
        font-weight: bold;
        /font-variant: small-caps;
	}


.outertable {
	width: 99%; 
	cellpadding: 25; 
	background: #ffffff; 
	border: 1px solid;
	}

.hl	{
	 ;
        PADDING-LEFT: 5px; PADDING-RIGHT: 5px; 
        padding-top: 5px; padding-bottom: 5px;
        MARGIN-BOTTOM: 1px; 
        BORDER-TOP: #a9a9a9 0px solid;
        BORDER-RIGHT: #a9a9a9 0px solid; 
        BORDER-LEFT: #a9a9a9 0px solid;
        BORDER-BOTTOM: #a9a9a9 0px solid;        
        background: #f5f5f5;	
        width: 70%;
	}

.hl-wide {
	 ;
        PADDING-LEFT: 5px; 
        PADDING-RIGHT: 5px; 
        padding-top: 15px; 
        padding-bottom: 15px;
        MARGIN-BOTTOM: 1px; 
        BORDER-TOP: #a9a9a9 0px solid;
        BORDER-RIGHT: #a9a9a9 0px solid; 
        BORDER-LEFT: #a9a9a9 0px solid;
        BORDER-BOTTOM: #a9a9a9 0px solid;        
        background: #fbfbfb;	
	}

.lnum {

	color: #a0a0a0;
	/background: #fbfbfb;
	}

.unhilited {background-color:white}
.hilited {background-color:#c0c0ff}


</STYLE>
@

}}}5


}}}4


#------------------------------------------------
{{{4 .h4. Accumulate the result ./h4.
#------------------------------------------------

Some of the vars may be unused later (run perl -wc to check?)

<<accumulate result in a buffer>>=
#2. accumulate result in a buffer


# vars for the main loop over lines of the target file

 $chunkbuf = ''; # collects whole formatted project file in memory
 $tocbuf = "";	# will accumulate TOC contents, i.e. small
 @indbuf = ();  # accumulates index of code chunks, small
 #%indbuf = ();
 @headings = ();	# the stack for nested subsections numbers/ids

 $section_num = 0;
 $section_num_prev = 0;
 $section_level = 0;
 $prev_section_level = $section_level;
 $line_counter = 0;
 $in_pre_tag = 0;
@


The logic is this: (a) all project files, unless they are machine-generated code, are
much below the sizes of RAM on modern machines. So I accumulate in memoru (in a string
$chunkbuf) a copy of the whole file, with necessary transformations and formatting.

Only 3 distinctions need to be made while iterating over hte lines of the Literate Source
file, between section headings, chunks of code and the lines from the body of documentation
chunks.

<<accumulate result in a buffer>>=

open FF, "< $0";


while (<FF>) {

   $line_counter++;

    # cut out the MOLLY.pl invocation itself, the top of the Lit src file
    #if ( m%^#-+\s*?start of script% ... m%^xxxxxxxxxxxx% ) {  
    if ( m%^__DATA__% ... m%^xxxxxxxxxxxx% ) {
    s!^__DATA__\s*$!!;



<<process code chunks>>
<<process section headings>>
<<body HTML formatters>>


	# debug
	#print "---- $_";

   } # fi "start of script"

} #elihw over the whole input file

	


 foreach (@headings)  {

	($section_level, $section_num_prev) = split /-/, $_;
	$folding_section_end = $folding_section_end_str;
	$folding_section_end =~ s!(\$section_num_prev)!$1!ee;
	$chunkbuf .= $folding_section_end; 

	};

@





#-----------------------------------------------
{{{5 .h5. process code chunks ./h5.
#-----------------------------------------------

"goto" is from an old version of this script, with perl-specific options, I'll delete it
later.

I use perl range operator to cut out the code section between < < chunkname > > and the
closing "at" symbol, as is required in "noweb".
This is a use of the "range" operator inside another "while" loop over each line of the
Lit Source file, and they work together, the range just flips some status var ("in" - "out")
while the outside loop continues over the lines.

Once the section name is extracted with a regexp, the index buffer (indbuf) is formed and
updated.
Then "fieldset" formatting is written around the code chunk and line numbering (if set
in an option var) is written too

<<process code chunks>>=

	if ( m!^(goto)?<\<(.*)>\>=! ... m!^@\s*$! ) { # -- CODE CHUNKS -- 
		$chunk_title = $2;

		s/&/&amp;/g;	# escape &
		s/</&lt;/g;	# escape <
		s/>/&gt;/g;	# escape >

		if (m!(&lt;&lt;(.+?)&gt;&gt);(=)?!) 
		  {
		  $reference = $1;
		  $ind_str = "&lt;&lt;$2&gt;&gt; $section_num";
		  if (defined $3) {$ind_str .= "<sub>def</sub>"}
		  else { s!$reference!<font class='chunkref'>$reference</font>! }

		  unshift @indbuf, $ind_str;

		} # fi - chunks index accumulation

		# simple fieldset frames around code snippets
		s!^(goto)?&lt;&lt;(.+)&gt;&gt;=!$code_frameset_start_pre$1&lt;&lt;$2&gt;&gt;$code_frameset_start_post!;
		s!^@\s*$!$code_frameset_end!;

		if ( $line_numbering ) { 
		$chunkbuf .= "<font class='lnum'>" . $line_counter . "</font>   " . $_;
		}
		else{
		$chunkbuf .= $_;
		}

	} # fi code chunks
@

}}}5


#----------------------------------------------------
{{{5 .h5. process section headings ./h5.
#----------------------------------------------------

This is where folding sectons are created.
The more complicated logic is needed to .i.close./i. the sections properly, when subsections
are included (i.e. creating a step and forming the "close subsection" at the end in the correct
place.

1. Several formats were possible for collapsing sections, I chose the one you can observe while
reading the weaved document: subsections are completely enclosed by their supersections;
once a child subsection is initiated, the parent subsection cannot continue its body after
the end of the child.
I.e. once you started 12.2.1 inside your 12.2, you cannot write into 12.2 after 12.2.1 is finished, 
but you can add 12.2.2, 12.2.3, 12.2.2.1 - etc. - inside the enclosing section.

The logic was tested first in an external skeleton script.

2. I may need to disassemble this code to create "view mode" for my script - see "versions - 
CHANGES" subsection


<<process section headings>>=

	# -- SECTION HEADINGS 
   #elsif ( m!\.(\+)?h(\d)\.(.*?)\./h\d\.! ) {	# old version, no "rawHTML" enabled yet
   elsif ( m!$tag_open_symbol(\+)?h(\d)$tag_close_symbol(.*?)$tag_open_symbol/h\d$tag_close_symbol! ) {	



	# -- using split vars for substitution to avoid
	#	regexps and need to keep old state --	

	$section_num_prev = $section_num;
	$section_num = $section_num + 1;


		#default for fold state in "settings" ??
		if ($1 eq "+") {
		    $fold_state="block";
		    $highlight_state = qq!  <script language=javascript> 
		    document.getElementById("toc"+ $section_num).className='hilited';
		    </script> !;
		} 
		else {
		    $fold_state="none";
		    $highlight_state = "";
		};
		$section_level = $2;
		$section_title = $3;


	

	

	$folding_section_start1 = $folding_section_start1_str;
	$folding_section_start2 = $folding_section_start2_str;
	$folding_section_end = $folding_section_end_str;


	$folding_section_start1 =~ s!(\$section_num)!$1!ee;
	$folding_section_start2 =~ s!(\$section_num)!$1!ee;
	$folding_section_start2 =~ s!(\$fold_state)!$1!ee;
	$folding_section_start2 =~ s!(\$highlight_state)!$1!ee;
	$folding_section_end =~ s!(\$section_num_prev)!$1!ee;


	$section_id = $section_level . '-' . $section_num;


	# finish previous subsection if not the first section in the file
	# ..and deal with nesting of sections according to their "depth level"

	# this is NOT the first section:
	if ( exists $headings[0] ){

		($prev_section_level, $prev_section_num)  = split /-/, $headings[0];

		if ($section_level == $prev_section_level){

		# close prev, start new
		$chunkbuf .= $folding_section_end;
		shift @headings;
		
		}

		elsif($section_level < $prev_section_level){
		
		  # close a bunch of them, in a loop -- THEN start a new one.
		  do  {
			($prev_section_level, $section_num_prev) = split /-/, shift @headings;
			
			$folding_section_end = $folding_section_end_str;
			$folding_section_end =~ s!(\$section_num_prev)!$1!ee;
			$chunkbuf .= $folding_section_end;

		   } while ( $section_level < $prev_section_level );
		}
	} # fi not the first section


	# common operations		
	unshift @headings, $section_id ;
	$chunkbuf .= $folding_section_start1;
	$chunkbuf .= "<font class='lnum'><i>(" . $section_num . ")</i></font>" . "&nbsp;" . $section_title .
	    "</a>&nbsp;<a><font class='lnum' size=-1><sub><i>(line " .
	    $line_counter . ")</i></sub></font>"; 
	$chunkbuf .= $folding_section_start2;

	#$chunkbuf .= "\n" . "<font class='lnum'><i>------ line " . $line_counter . 
	#	    " ------</i></font><br>\n";


	$toc_indent = "&nbsp;" x ($section_level * 7);
	#$toc_indent = "&nbsp;" x (($section_level-1) * 7 );
	#$tocbuf .= "\n<p>\n" if ( $section_level == 1 ); 
	$tocbuf .= $toc_indent . 
		"<i>" . $section_num . "</i>" .
		qq/&nbsp;<a href="javascript:;" onmousedown="toggleCombined(/ .  
		$section_num . 
		qq/);" id="toc/ . $section_num .
		qq/"><b>/ .
		$section_title . "</a>&nbsp;<a><font class='lnum' size=-1><i>(line " .
		    $line_counter . ")</i></font>" .
		    "</b></a><br>\n";

   } #; fisle: end elif headings

	

@

}}}5

#---------------------------------------------------------
{{{5 .h5. dotHTML formatter and rawHTML ./h5.
#---------------------------------------------------------

It is primitive, and I add needed markup "on the fly", as and when I need it.
The idea is to eliminate angle brackets in html tags, which I cannot type without errors
when typing fast, and substitute those with simple "dots", which do not requre switching
keyboard registers.

.s. This formatting also has problems with escapes.

Whether it's the fault of HTML standards or their implementation, web browsers continue to
react to html formatting .b.even inside the "pre" tags./b., which is obviously insane.
Therefore if your code chunks contain any HTML tags (e.g. processed by your code), you'll
need to escape them to display correctly.
And if you use sth like "& g t ;" in your code, the web page will also lie to you.
This is insane, and there is no good quick solution, one would have to use lengthy escape
tables etc. etc. ./s.

.ul. /* OFFTOPIC, ALSO: add < > and & escapes to the weaved code chunks -- for proper display */
    --- DONE ---
    These escapes exist in two places in the Weaver code:
    "process code sections"  and "body HTML formatters"
./ul.

.br.
This prototype script fails in some (unimportant to me)  cases.
dotHTML markup would also fail if your programming language uses dot-symbol-dot sequences
Mine do not.

The formatter is pretty straightforward, but sequencing of regexps is important.
One also needs to remember that once escaped, angle brackets are non-existent any more, 
and so the subsequent regexps must match on "& l t ;" not on the angle bracket in some
cases.


<<body HTML formatters>>=

	elsif( $weave_markup eq "dotHTML" ) {	# dotHTML formatter here

	      s/^=begin.*$//;	# - eliminate perl escaping, start
	      s/^=cut.*$//;		# - eliminate perl escaping, end
   	      #s/^{{{\d+(.*)$/$1/;	# - eliminate vim folding markup, start 
					# - dummy, as it is killed in "headings" processing 
	      s/^}}}\d+//;	# - eliminate vim folding markup, end

		s/&/&amp;/g;	# escape &
		s/</&lt;/g;	# escape <
		s/>/&gt;/g;	# escape >


	      # Paragraphs and line breaks are automatic now:
	      # ... unless we are dealing with the "preformat" tag
		#--note! that ranges do not work here
		$in_pre_tag = 1 if (m!\.pre\.!);
		$in_pre_tag = 0 if (m!\./pre\.!);;

		s/\.(\/?)pre\./<$1pre>/g;

	    unless ($in_pre_tag) {
	    (m/^\s*$/) and s/$_/<p>\n/
	    or s/\n/<br>\n/;
	    }
@

Now the regexps to cut out "#--------" lines and substitute "dot-notation" with angle brackets:

<<body HTML formatters>>=
	      # originally I separated header from the body with such a line
	      #s/^#-----.*/starting the table here/;
	      s/^#-----.*//;


		# add more here

		s/\.(\/?)b\./<$1b>/g;
		s/\.(\/?)i\./<$1i>/g;
		s/\.(\/?)ul\./<$1ul>/g;
		s/\.(\/?)li\./<$1li>/g;
		s/\.(\/?)ol\./<$1ol>/g;
		s/\.(\/?)s\./<$1s>/g;
		s/\.(\/?)div\./<$1div>/g;
		s/\.br\./<br>/g;
		s/\.p\./<p>/g;
		s/\.sp\./&nbsp;/g;

		s/\.(\/?)tab\./<$1ul>/g;	# "tabbing" with "ul"


		# this is some bullshit ???
		s/\.hr\./<hr /g;
		s/\.\/hr\./>/g;

		s!\.a\.(.+?)\.\/a\.!<a href=$1>$1</a>!g;

		# rudimentary &nbsp; s p a c i n g &nbsp (one word only)
		#s!\.x\.(.+?)\./x\.!join " ","&nbsp;&nbsp;",(split //, $1),"&nbsp;&nbsp;"!eg;

		# slightly better spacing (phrases, too):
		# although redundant  with more work than is needed
		if ( m!(\.x\.)(.+?)(\./x\.)!g) {
		    s!(\.x\.)(.+?)(\./x\.)!join " _ ", $1, (split / /, $2), $3!eg;
		    s!\.x\.(.+?)\./x\.!join " ", (split //, $1)!eg;
		    s!  _  ! &nbsp; !g;
		}
@

.b. BUG! ./b. This URL breaks my "ancor" dot-tags: 
     .pre. http://www.cs.tufts.edu/~nr/noweb ./pre.
.b. Got it ./b. The substitutions above must explicitly use "slash" for the closing HTML tag
in the regexps - otherwise they match stuff like ".cs." inside URLs

If an HTML tag is not in the above chunk, either add it or write with the two following generic
tags (slow and not nice on your fingers, though). You might need to use them also when your HTML
tag conntains some options, and so is not of generic simple type.

<<body HTML formatters>>=


		# generic for all tags with options
		s!\.&lt;\. !<!g;
		s! \.&gt;\.!>!g;


		$chunkbuf .= $_;

	}
@


.b. rawHTML formatter./b.
Raw HTML formatting can be done - either because it is non-restricted, compared to the stripped-down
"dotHTML" of my invention, or because it allows one to convert existing HTML documentation into the
folding format.
I.e. if you have a longish manual in which section headings are marked with HTML h1, h2, h3, ... tags,
you can convert it in 3 simple steps:
.ul. .li. delete opening and closing "html" and "head" "body" tags at the very top and bottom of your 
document
./li. .li. put perl invocation as the first line
./li. .li. set up markup mode in a variable: "$weave_markup = "rawHTML";" and "mollify" the document,
putting  "do MOLLY.pl" and DATA marker
./li. ./ul.
and if there are no interfering div section etc. - no complicated markup inside the headings, you'll get
an automatically generated folding HTML document.

If you do, it is sometimes easy to clean headings with a few regexps in a good editor like Vim

It is very convenient and I keep large manuals as folding HTML documents.


<<body HTML formatters>>=
	elsif( $weave_markup eq "rawHTML" ) {	# if the doc chunks marked up with real HTML
		s!^#-----.*!!;

	      #s/^{{{\d+(.*)$/$1/;	# - eliminate vim folding markup, start 
					# - dummy, as it's killed in "headings" processing 
	      s/^}}}\d+//;	# - eliminate vim folding markup, end


	      # Paragraphs and line breaks are automatic now:
	      # ... unless we are dealing with the "preformat" tag
		#--note! that ranges do not work here
		$in_pre_tag = 1 if (m!<pre>!);
		$in_pre_tag = 0 if (m!</pre>!);;


		unless ($in_pre_tag) {
		(m/^\s*$/) and s/$_/<p>\n/
		or s/\n/<br>\n/;
		}


		$chunkbuf .= $_;
	} # esle -- for rest of the body



@

{{{6 .h6. test of &nbsp;&nbsp; s p a c i n g &nbsp;&nbsp; regexp ./h6.

1. Hell, the thing is multiple sp /sp markups on one line. I need to iterate over
each separately and then put them in their right places, hedging with "nbsp"-ces each word.

2. The invocation is OK for $str_sp, but for boundaries of the string and word boundaries, 
they must be hedged too

3. Could subst spaces-betwen-words to sth like _ (space-underscore-space) as placeholders,
then subst them into nbspx2 in a following regexp

4. This tagging can be done cleanly and span severl lines if I do it in a different place - 
not while still reading the Literate Source file line by line, .x.but later./x. when
$chunkbuf is completely formed in RAM.


<<spacing.pl>>=
#!/usr/bin/perl
#
$str = $ARGV[0];
$str_sp = $ARGV[0];
#print "string is $str\n";

    # "sp" dot-markup to intersperse spaces: the basic formula
    #$spaced_str =~ s!(asdf)!join " ", (split //, $1)!eg;
    #
    
    # -- idea 3 from above: this works but is cumbersome --
    #$str_sp =~ s!(\.x\.)(.+?)(\./x\.)!join " _ ", $1, (split / /, $2), $3!eg;
    #$str_sp =~ s!\.x\.(.+?)\./x\.!join " ", (split //, $1)!eg;
    #$str_sp =~ s! _ ! &nbsp;&nbsp; !g;

    # -- first get the matching string in "if", then massage it:
    if ($str_sp =~ m!(\.x\.)(.+?)(\./x\.)!g) {
	$str_sp =~ s!(\.x\.)(.+?)(\./x\.)!join " _ ", $1, (split / /, $2), $3!eg;
        $str_sp =~ s!\.x\.(.+?)\./x\.!join " ", (split //, $1)!eg;
	$str_sp =~ s!  _  ! &nbsp; !g;
    }

    #print "\nthe string is $str\n";
    print "\nthe str_sp is $str_sp\n\n";
@

}}}6	    

}}}5

}}}4


#-------------------------------------------------------
{{{4 .h4. Print out the resulting page ./h4.
#-------------------------------------------------------

Page and the outer formatting table:

<<print out>>=

  # begin the page:
  #print '<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">', "\n";
  print "<html>\n  $html_head\n <body>  $html_body_table \n";

  # print out the TOC, the Chunks Index, the output buffer and close the page.

@

Next print the short instructions section (collapsible) at the top:

<<print out>>=

print <<end_of_print;
<p><fieldset class='tocfieldset'><legend><b>TABLE OF CONTENTS: outline of the document structure</b></legend>

<ul>
<p>
<br>
<div class='hl' align=center>
<a href="javascript:;" onmousedown="toggleDiv('tochowto');">
<b>HOW TO USE THE FOLDING DOCUMENT [expand/collapse]</b></a>
</div>
<div id='tochowto' style='display:none' style='background:#ffffff'> 
<p>
<ul>
<li><b>Collapsing is necessary when</b> you work on some code and must exclude 
<br>irrelevant sections of the rest of the literate project file. This 
<br>greatly helps to clear thinking by eliminating a general feeling of 
<br>being in a maze of code and unnecessary "housekeeping" tasks.
<br>One can say that there is a limited "buffer capacity" in the human
<br>mind, and relieving it of the need to remember where things are in a 
<br>larger file, at which other points one must fill in values or adjust
<br>invocation etc. <i>immediately makes the user "more intelligent"</i>
</li><li><b>To toggle</b> a section open/closed, click on the corresponding link
<br>Remember to open <i>all sections above it</i> for it to become visible.
</li><li><b>To restore the default view</b> reload the page in the browser.
</li><li>
<b>To keep some sections open</b> upon each reload - 
<br>e.g. you work on the code, update it constantly and cannot reopen it 
<br>again and again - mark their sections in the source file with a plus, 
<br>i.e. write the opening tag (only)  as +h2, +h3 (in &lt; &gt;  or in dots
<br>for dotHTML). Again, all sections above must be marked open too. 
<p><b>Note that</b> "expand all" and "collapse all" disregard these settings.
<br>Reload the page after using those options to again view the text according 
<br>to your preferences.
</li><li>
<b> To use the Index </b>, click on the numbered sections in the TOC above
<br>(opening them; use highlighting as a guide; when sections are visible,
<br>the slider on your browser window  will shorten too), or "expand all", 
<br>and then use your browser's Find function to highlight all chunk name 
<br>instances in the visible text
</li><li>
<b>To search for variables etc.</b>, "expand all" text - or manually 
<br>expand needed sections - and then use your browser's Find function to 
<br>highlight all and jump between the found items.
<p></li>

</div> 
<p>
<br>
<p>
<div class='hl' align=center>
<!--i><font size=-3> expand all -- collapse all</font></i-->
<a href="javascript:;" onmousedown="toggleDiv('tocmain');">
<b>TABLE OF CONTENTS [expand/collapse]</b></a>
</div>

<div id='tocmain' style='display:$toc_expanded' style='background:#ffffff'> 
<p>
<br>
<p>
end_of_print

@

Table of Contents from the formed "tocbuf":

<<print out>>=

 print "$tocbuf" if $print_toc;
 #print "$tocbuf";

print "</div>\n";

@

Start the "Index of code chunks", collapsible:

<<print out>>=

print <<end_of_print;
<p>
<br>
<p>
<!--fieldset><legend-->
<div class='hl' align=center>
<a href="javascript:;" onmousedown="toggleDiv('indbuf');">
<b>INDEX of Code Chunks [expand/collapse]</b></a>
</div>
<!--/legend></fieldset-->
<p>
<div id='indbuf' style='display:$ind_expanded' style='background:#ffffff'> 
<ul>
<p>
<b>"Def" subscript</b> means the chunk is defined, while a bare number means 
<br>the chunk is being used in the given section.
<p>
end_of_print

@


Index of code chunks; calculated in this snippet:

<<print out>>=

	 $ind_outbuf = '';
	 $prev_ch_name = '';

	 #for (sort @indbuf){ print $_, "<br>";}

	 for (sort @indbuf){

	   ($ch_name, $closing_bracket, $ref_num) = split /&gt;/, $_; 
		#/ - for editor colouring bug

	    if ( $ch_name eq $prev_ch_name ){ 
	      $ind_outbuf .= " <b>" . $ref_num . "</b> ";
	    }
	    else{
	      print  $ind_outbuf, "<br>\n"; 
	      $ch_namestr = $ch_name;
	      $ch_namestr =~ s!&lt;&lt;!!;
	      $ind_outbuf = 
	      	"<b>&lt;&lt;</b><font class='chunkref'>" . 
	      	$ch_namestr . 
	      	"</font><b>&gt;&gt;</b> -- <b>" . 
	      	$ref_num . 
	      	"</b> ";
	    }
	    $prev_ch_name = $ch_name;

	 }; # rof - forming the code chunks index

	print $ind_outbuf, "<br>\n";

@


"expand all" and "collapse all" at the end of the TOC/Chunk Index section 
at the top of the page:

<<print out>>=

  # The "expand all" "collapse all" control

print <<end_of_print;
</div>\n<p>
<br>
<p><div class='hl' align=center><i>
<a href="javascript:;" onmousedown="showAll();">
expand all</a> -- 
<a href="javascript:;" onmousedown="hideAll();">
collapse all</a>
</i></div><p>
end_of_print


 print "</ul></fieldset><p>\n<br>";

@



..and the document itself, formed earlier in the "chunkbuf" string in memory:

<<print out>>=

# The FULL OUTPUT, the file body:
 	print $chunkbuf;

@

Close the HTML formatting tags at the end of the page:

<<print out>>=

# close the page
	print $html_body_table_end;
	
exit;

#--- END OF SCRIPT ---

@

End of the project file

}}}4

}}}3



#-------------------------------------------------------------
{{{3 .h3. ADD-ON: example of additional markup - dotHTML - change unfinished./h3.
#-------------------------------------------------------------

.i. This subsection is a good example of the "out-of-order" processing that is
enabled in Literate Programming. Pieces for this subsection come from different
parts of the script and are laid out logically rather than in the order imposed
by the machine ./i.

.b. .i. Notes ./i. ./b.
.ul.
Implementation of a simple "dotHTML" markup  in which angle brackets are substituted
with dots for some of the commonest HTML tags (to speed up typing and eliminate typos).

To add your own markup, such as "wiki" or one of the "markdowns", copy this section
and adjust contents. The idea is that MOLLY iterates over documentation sections
line by line, so your filter can use regular expressions for a line-by-line processing
of the documentation chunk text.

Make sure your new "markdown" does not interfere with the 3 major escapes used in 
the "mollified" Literate Source file: the double angle brackets and the "at" symbol
(imposed by "noweb" tools markup) and the double backticks ( MathML interpretation
if you enable it) plus words "a m a t h" and "e n d a m a t h" without spaces btw letters.
./ul.


.b. .i. ...unfinished... ./i. ./b.

}}}3


#-------------------------------------------------------------
{{{3 .h3. ADD-ON: ASCIIMathML and LaTeXMathML inside Molly  ./h3.
#-------------------------------------------------------------

.b. 1 ./b. .i. STATUS ./i. - Ok, but may be brittle if escapes (double backticks)
get in conflict with the target prog language or some "markdown" 
introduced later into Molly.

Also - may have lost LaTex functionality because of my need to
preserve $ for programming language use.

.b. WILL NEED TO DISTRIBUTE THE MODIFIED LIBRARY NOW with Molly ./b.

.b. 2  Implementation ./b.
.. was straightforward: I simply cut in an invocation of ASCIIMathML.js into the header of 
my generated output folding-HTML file. That's it.

Then I tested the lib and found that it reacts to backticks and $ signs in my code sections etc.
Then I made a customized copy.

If some symbols are missing, you can customize it by simply adding a line to teh MOLLY.weave
source code and re-tangling the MOLLY.pl

Here is how:

{{{4 .h4. Extending the lib with missing LaTeX or HTML symbols ./h4.

Documentation to the library explains how to add lines in JavaScript to your html file which will
extend the list of symbols known to the library.
.a. http://www1.chapman.edu/~jipsen/mathml/asciimathextend.html  ./a.
A copy of the page:
.ul.
.b.ASCIIMathML.js: Extending the symbol table./b.

The standard symbol table of ASCIIMathML.js does not contain many symbols. 
It can be extended by adding additional symbols on any webpage that requires
them. This is done by adding a few lines of JavaScript code.

.b. 1. For example ./b. , suppose we want to add symbols for "not less or equal"
    and "not greater or equal".

.ul. .li. We first have to find the four-digit hexadecimal Unicode value for these symbols
by looking them up at, say, 
.a. http://www.w3.org/TR/MathML2/chapter6.html#chars.entity.tables ./a.

./li. .li. Next we have to decide what input strings we want to associate with these
symbols, say "!<=" and "!>=".

./li. .li. Finally we add the following lines to the head or body of our HTML file:
.pre.
<script type="text/javascript">
define("!<=","\u2270")
define("!>=","\u2271")
</script>
./pre.
./li. ./ul.

Here we test the modified symbol table: a !<= b !>= c produces ``a !<= b !>= c``

.b. 2. To add a symbol to the LaTeX commands ./b., use the following alternate syntax:

.pre.
<script type="text/javascript">
newcommand("\\nle","\u2270")
newcommand("\\nge","\u2271")
</script>
./pre.

Now \$a \nle b \nge c\$ produces $a \nle b \nge c$.


.b. 3. If you know the numeric entity reference ./b.  of the symbol you want 
to use on an ASCIIMathML webpage, you can also refer to the symbol .b. directly ./b. 
by using that reference. 

E.g &#x2270; produces  ``&#x2270;`` . If a symbol is only used occasionally, this is certainly 
the simplest way to include it. 
./ul.

.i. /error/ My copy of the page in MOLLY does not let ampersand invocations through 
ALSO: my copy of the lib, in which I mechanically changed single backticks to double backticks
may have clobbered something, too.
CHECK IT. ./i.

Therefore, .b. to extend it in MOLLY ./b., just continue this chunk here (the "script .." --- "/script"
tags are already provided in the code, do NOT retype them, input only the contents):

<<HTML head section javascript add-ons>>=

//type in commands to extend ASCIIMathML.js here;
// no "script" "/script" wrappers needed
// ....NOT FUNCTIONAL YET.....

@

}}}4

#--------------------------------------------------------------------------
{{{4 .h4. MathML and Molly -- inclusion of ASCIIMathML.js -- testing - OK partially ./h4.
#--------------------------------------------------------------------------

#--------------------------------------
{{{5 .h5. test one - simple ./h5.
#--------------------------------------

Let's test if it works by adding some formulae here:
.b. I changed the ASCIIMathML.js to use .i. double backticks ./i. as escapes ./b.
So strings wrapped in double-backticks or chunks of text with formulae inside
"a m a t h" .... "e n d a m a t h" are the only ones that should be interpreted.

NOTE: they appear in blue, so errors, if the math lib picks up other parts of 
your LitProg file unnecessarily and mangles them, one could see it with
"expand all" and checking for blue insertions.

NOTE 2: the math lib stops working between the "pre" - "/pre" tags

NOTE 3: Rolling the mouse over the interpreted formula will display
a baloon with the ascii coding of the expression (very convenient)

.ul.
Let's try some interesting formulas: ``E=m c^2``
and ``e^(i pi)=-1`` 
and ``AA x in CC (sin^2x+cos^2x=1)`` 
and one more: ``sum_(i=1)^n i^3=((n(n+1))/2)^2``

(add your own -- note that text-tokens are only recognized if separated by spaces)
./ul.
OK, here we are - in between 2 math sections

.ul.

amath
Example: Solving the quadratic equation.
Suppose a x^2+b x+c=0 and a!=0. We first divide by \a to get x^2+b/a x+c/a=0. 

Then we complete the square and obtain x^2+b/a x+(b/(2a))^2-(b/(2a))^2+c/a=0. 
The first three terms factor to give (x+b/(2a))^2=(b^2)/(4a^2)-c/a.
Now we take square roots on both sides and get x+b/(2a)=+-sqrt((b^2)/(4a^2)-c/a).

Finally we move the b/(2a) to the right and simplify to get 
the two solutions: x_(1,2)=(-b+-sqrt(b^2-4a c))/(2a) 
endamath

./ul.

..and now let's check some LaTeX constants:
.ul.
.pre. \int .sp. \oint .sp. \partial .sp. \nabla ./pre. 
``\int`` .sp. ``\oint`` .sp. ``\partial`` .sp. ``\nabla``
.pre. \pm .sp. \emptyset .sp. \infty .sp. \aleph ./pre.
``\pm`` .sp. ``\emptyset`` .sp. ``\infty`` .sp. ``\aleph`` 
.pre. |\ldots| .sp. |\cdots| ./pre.
``|\ldots|`` .sp. ``|\cdots|`` 
.pre. |\ | .sp. |\quad| .sp. \diamond ./pre.
.sp. ``|\ |`` .sp. ``|\quad|`` .sp. ``\diamond`` 
./ul. 

.i. .b. end of math test ./b. ./i.

}}}5

#----------------------------------------------------------------------
{{{5 .h5. test two - from realistic paper, partially failing  ./h5.
#----------------------------------------------------------------------

.<. hr width=30% align=left .>.

.b. ..MORE from some paper: ./b.

.b. 1. Freudental Formula ./b.
``mult(\xi)=\frac{2}{(\mu+\rho|\mu+\rho)-(\xi+\rho|\xi+\rho)}\sum_{\alpha\in\Delta^{+}} mult(\alpha) \sum_{k=1}^{\infty}mult(\xi+k\alpha)(\xi+k\alpha|\alpha)``
It includes roots ``\Delta=\left\{k\delta+\alpha|k\in Z,\; \alpha\in \Delta_0\right\}``
positive roots ``\Delta^{+}=\{k\delta+\alpha|k\geq 0,\; \alpha\in \Delta_0^{+}\}\cup \{k\delta+\alpha|k\geq 1,\; \alpha\in \Delta_0\setminus \Delta_0^{+}\}``

.b. The above is rendered correctly by ASCIIMathML.js and LaTeXMathML.js ./b. 
libraries from the standalone Editor.It is rendered correctly with 
ASCIIMathML_with_modified_escapes.js from Molly 
(Testing with LaTeXMathML.js requires wrapping the formulas in dollar signs)


.b. 2. The following long formulas .i. fail on both ./i. ASCII and LaTeX libraries ./b. tested
from the standalone Editor and ASCII_with_modified_escapes from Molly
The number of incorrect renderings is small (1 or 2 elements left unrendered), and
suggests those elemens are simply missing in definitions.


 The idea is to use recurrent relations for anomalous branching
coefficients based on the summation over the special set of vectors 
``\Gamma_{\frak{a}\subset \frak{g}}``  called ````fan''. We
need to introduce some notations. Let's consider the reduction of the
representation of the affine Lie algebra ``\mathfrak{g}`` to 
representations of affine Lie algebra ``\mathfrak{a}``. By
``\pi_{\mathfrak{a}}`` we denote the projection of the root space
``\frak{h}_{\frak{g}}^{\ast } to \frak{h}_{\frak{a}}^{\ast }``. The
set ``\Gamma_{\frak{a}\subset \frak{g}}``  is introduced as the
combination of projection of positive roots ``\Delta^{+}`` of algebra
``\frak{g}`` using formulae:

.b. .i. The above paragraph is OK ./i. ./b.
The following is rendered incompletely:

{eq:7}

 ``\prod_{\alpha \in \left( \pi _{\frak{a}}\circ \Delta ^{+}\right) }\left( 1-e^{-\alpha }\right) ^{\mathrm{{mult}\left( \alpha \right) -{mult}}_{\frak{a% }}\mathrm{\left( \alpha \right) }}=-\sum_{\gamma \in \Phi _{\frak{a}\subset \frak{g}}}s\left( \gamma \right) e^{-\gamma }``.  

 {{{5

{eq:18}

 `` \Phi _{\frak{a}\subset \frak{g}}=\left\{ \gamma \in P_{\frak{a}}\mid s\left( \gamma \right) \neq 0\right\} ``;  

 
{eq:19}

 `` \Gamma_{\frak{a}\subset \frak{g}}=\left\{ \xi -\gamma _{0}|\xi \in \Phi _{% \frak{a}\subset \frak{g}}\right\} \setminus \left\{ 0\right\} .`` 

 
{recurrent-relation}

``  k_{\xi }^{\left( \mu \right) }=-\frac{1}{s\left( \gamma _{0}\right) }\left( \sum_{w\in W}\epsilon \left( w\right) \delta _{\xi ,\pi _{\frak{a}}\circ \left( w\circ (\mu +\rho )-\rho \right) +\gamma _{0}}+\sum_{\gamma \in \Gamma _{\frak{a}\subset \frak{g}}}s\left( \gamma +\gamma _{0}\right) k_{\xi +\gamma }^{\left( \mu \right) }\right)   
``
{{{5

Fan doesn't depend on the module, but
is determined by the injection of sub-algebra into the algebra. If 
sub-algebra is Cartan sub-algebra, this relation gives...




.<. hr width=30% align=left .>.



}}}5

}}}4

#------------------------------------
{{{4 .h4. Two problems - solved ./h4.
#------------------------------------

.s. .b. 1.  A BIG PROBLEM ./b. is that the rest of the file IS STILL PROCESSED
by the stupid script (!!)
So it garbles code sections etc. creating pseudo subscripts
The "automatic math" recognition is not there 
POSSIBLE SOLUTION:
(a) fall back on "backticks" or (b) filter and feed only math subsections
to the stupid library?? Is it possible? - it's happening on the client side.
So, not.

.b. Moved the math section down ./b. - still the whole file is garbled, and
all underscores converted into subscripts etc.
./s. ---- sort of solved for now

.b. 2. a bug? ./b.. I wrote:
.ul. NOTE also that once pages have been rendered dynamically they can be saved
as HTML from your browser and then distributed - no library is needed any more.
The created page remains self-sufficient HTML, and if your browser knows how to display
MathML, the formatting will be preserved. If not, the browser will fall back to what
you typed in ASCII, (which is also often readable, but..).
./ul.

.b. Seems like a bug in my Firefox ./b. - it cannot see any previously rendered pages
after saving-reopening them, js library or no library.

.b. Tried ./b. to embed the lib into MOLLY.pl - succeeded after cleaning out all
C-style comments (/* ....*/) 
The generated html file loaded -- in 8-10-.. seconds -- and rendered MathML inside
Firefox.
However saving caused THE SAME RESULT - it was not reloadable, readable after saving
from Firefox.
A bug with Firefox, it looks like ;(((((

..Undid all changes now, should be as before, the lib is external.

.b. Checked agains a "torture page" from mozilla ./b.
.a. http://www.mozilla.org/projects/mathml/demo/texvsmml.xhtml ./a.
saves and displays OK. Is it the library then??!

.i. one more page about installing math fonts  on Linux etc (oldish) ./i.
.a. http://groups.csail.mit.edu/mac/projects/intelligent-book/mathml/ ./a.

.b. ANYWAY when the HTML doc is saved from "MOLLY.weave" and is accompanied with
a copy of the library, it all works OK in Firefox, however ./b.
Just do not mix the "single-backquoted" default copies of the ASCIIMathML.js library
and our customized ones. Use the correct version for your markup.

.b. note on lib versions and distribution./b. 
correct it in the template. Referring to the copy of the lib on its
home site will get WRONG lib for my "double-backticks" markup. It will work OK for 
a m a t h tags though. But will garble any included code with $'s (such as shell or
perl or php or ........)
Make available your own copy of the lib, that is the idea.

"Opera" browser when it creates an *.mht archive out of the weaved HTML doc does
correctly include a base64-encode copy of the custom lib from the same dir.
So my hope that one could distribute the stuff in one piece seems justified.
I cannot view *.mht on Linux (as Opera fails MathML, and Firefox ignores the format),
but I can distribute it as such for IExplorers with a MathML player plugin installed,
hopefully.

Q. Does Firefox on Windows understand *..mht ??
A. Check .a. http://www.unmht.org/unmht/en_index.html ./a.
.b. .i. Problem solved by installing UnMHT firefox add-on ./i. ./b.
.a. http://www.unmht.org/unmht/en_index.html ./a.
Now it can open weaved MathML files + custom library, save them as one "multipart
file", reopen correctly, and also reopen the *.mht created blindly by Opera.

So this is how it can/should be used for now.

.b. P.S. ./b. One more relevant Mozilla add-on is MAF ("Mozilla Archive files, zipped archives
of pages and their elements)
.a. http://maf.mozdev.org/ ./a.
}}}4

}}}3


#---------------------------------------------------------------------------------------
{{{3 .h3. ADD-ON: Context diffs and sections editing -- not implemented ./h3.
#------------------------------------------------------


.h4. Outline of the idea ./h4.

.ol. .li. Context diffs an be applied by "patch -c" even .i. without their header ./i.
./li. .li. Secondly, I can ancor them with line numbers from the original "project.weave"
./li. .li. I have to remember that the file the section from which  I edit in-browser 
(or in  an external editor) is NOT the original LIterate Source, but an "html-ified"
Literate Source file.
./li. ./ol. 

Therefore, I can save a section edit saved under a unique name, like "line1234.patch"
and the general outline of processing will be:
    .ul. .li. (a) add line number references/ancors to the html-ified output of "molly.weave"
    indicating lines in the Literate Source (modify the existing weaver)
    ./li. .li. (b) edit sections 
	.ol. .li. in a Javascript in=-browser editor, like "tinyMCE" etc.
	which is applied to "div"s 
	./li. .li. or in an external editor, to which I cat the piece from
	a subsection heading to the next subsection title; the editor is called with the default
	name of the future patch ./li. ./ol.
    ./li. .li. (c) Next, when processing/applying the patches (which should be incorporated into
    a new routine/section of MOLLY.pl) I do the following
    .ol. .li.  add the "****************" line needed to start a context diff without
    a header
    ./li. .li. substitute teh context diff line numbers for the target file with the beginning
    line number picked from the patch ancor ./li. ./ol.
    ./li. .li. apply "patch -c" to MOLLY
    ./li. .li. I should probably add the timestamp into the patch name (or use file mtime) to 
    apply only the new patches to the Literate Source, and/or clean the old ones (might keep some
    as a sort of version control for undoing ??? Does "patch" know how to revert itself ???)
    ./li. ./ul.


.h4. Editing - javascript versus external editor ./h4.

JS editors (wikiwyg, tinyMCE) are not OK: 
tinyMCE requires "textarea" tags;
wikiwyg requires writing a save routine that would reverse the wikiwyg-ification.

Therefore, I could do external editor calls (in an xterm or the GUI version, like
"gvim", 'jedit', or 'bluefish'.

Then my script - receiving a CGI call - should 
    .ul. .li. cat the section identified by the beginning line## (supplied during
    MOLLY.weave html file generation) -- using a hyperlink (created by molly.weave).
    ./li. .li. and next cat the portion of Literate Source into an external editor,
    called with the correct "patch-line##-timestamp" name.
    ./li. .li. The user edits the text and saves it (not "save as") - then 
    EITHER addressing the mollified LitSrc with a new CGI argument, 
    OR continuing the first CGI processing - after getting a return from the 
    external editor invocation
    ./li. ./ul.


.h4. Patch details and probs ./h4.

.i. If the entire diff is indented by a constant amount of white space, `patch' automatically
ignores the indentation. ./i.

... and this is good:
.i.    For context diffs, and to a lesser extent normal diffs, `patch' can
detect when the line numbers mentioned in the patch are incorrect, and
it attempts to find the correct place to apply each hunk of the patch.
As a first guess, it takes the line number mentioned in the hunk, plus
or minus any offset used in applying the previous hunk.  If that is not
the correct place, `patch' scans both forward and backward for a set of
lines matching the context given in the hunk.
./i.

.. there is an option "-F 3" or "--fuzz=3" setting "fuzz lines" for context & unified diffs

.. "reject files" -- check them for failed hunks.
    and another possibility is the "--dry-run" option to check before applying.

    and another possibility is the "--dry-run" option to check before applying.

.b. Appending patch trunks ./b. If I collect edits as "context patches", I do not need
to keep them in many separate files. All edits before an application can be appended to
the same file, the most recent collection of patch "trunks". After application to the
Literate Source it can be renamed (for "undo"s or deleted.

Actually, the same is true even for overwriting of sections, not patching.

Patching may be more complicated and relying on external progs, but in some sense 
more "intelligent" and "undoable", while overwriting is not unless I keep the old
versions explicitly.

.i. Am I reinventing Knuth's 'change files' functionality ?? ;)))))) ./i.


.h4. Implementation steps ./h4.

(a) add line numbers to docs subsections. --- DONE---


(b) This editing "from_the_browser" can be done:
    .ul. .li. by addressing "MOLLY.update" - by extension
    ./li. .li. via a CL option -- or via CGI "?update=patch-lineno_ref-datestamp"
    ./li. .li. in a separate script (at least for the time of development and testing)
    ./li. ./ul.

(c) So, step 1: add "edit" hyperlinks to each subsection.

(d) Modify Despatcher to redirect to the "update" subsection (will be here)
    ?? another extension? OR just args to "*.weave" ?


(e) Make the script dump the subsection whose linenum was passed as CGI arguments

(f) apply it either overwriting or using the diff/patch approach


}}}3

}}}2

}}}1


